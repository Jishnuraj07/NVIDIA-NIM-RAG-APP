{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "905c6786-1884-474f-afc2-f18ff46f0794",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3403750767.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[36], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    zip -r example.zip original_folder\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    " !\n",
    "zip -r example.zip original_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19dd6c53-ea64-42d7-b526-a084527b2d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your NVIDIA API key:  ········\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "if not os.environ.get(\"NVIDIA_API_KEY\", \"\").startswith(\"nvapi-\"):\n",
    "    nvapi_key = getpass.getpass(\"Enter your NVIDIA API key: \")\n",
    "    assert nvapi_key.startswith(\"nvapi-\"), f\"{nvapi_key[:5]}... is not a valid key\"\n",
    "    os.environ[\"NVIDIA_API_KEY\"] = nvapi_key\n",
    "    os.environ[\"NGC_API_KEY\"] = nvapi_key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f297978e-8694-46e6-a5b4-0bb60d53ebbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.chains import ConversationalRetrievalChain, LLMChain\n",
    "from langchain.chains.conversational_retrieval.prompts import CONDENSE_QUESTION_PROMPT, QA_PROMPT\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "from langchain_nvidia_ai_endpoints import NVIDIAEmbeddings\n",
    "from pydantic.v1 import BaseModel\n",
    "from langchain_nvidia_ai_endpoints._statics import Model, register_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61e9b299-3005-4e5b-b32f-aab903e60e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab9c760c-58a7-4a2f-b4b1-a7f46e00620d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Model(id='adept/fuyu-8b', model_type='vlm', client='ChatNVIDIA', endpoint='https://ai.api.nvidia.com/v1/vlm/adept/fuyu-8b', aliases=['ai-fuyu-8b', 'playground_fuyu_8b', 'fuyu_8b'], supports_tools=False, base_model=None),\n",
       " Model(id='google/gemma-7b', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=['ai-gemma-7b', 'playground_gemma_7b', 'gemma_7b'], supports_tools=False, base_model=None),\n",
       " Model(id='nvidia/llama3-chatqa-1.5-8b', model_type='qa', client='ChatNVIDIA', endpoint=None, aliases=['ai-chatqa-1.5-8b'], supports_tools=False, base_model=None),\n",
       " Model(id='01-ai/yi-large', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=['ai-yi-large'], supports_tools=False, base_model=None),\n",
       " Model(id='nvidia/llama3-chatqa-1.5-70b', model_type='qa', client='ChatNVIDIA', endpoint=None, aliases=['ai-chatqa-1.5-70b'], supports_tools=False, base_model=None),\n",
       " Model(id='databricks/dbrx-instruct', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=['ai-dbrx-instruct'], supports_tools=False, base_model=None),\n",
       " Model(id='microsoft/phi-3-vision-128k-instruct', model_type='vlm', client='ChatNVIDIA', endpoint='https://ai.api.nvidia.com/v1/vlm/microsoft/phi-3-vision-128k-instruct', aliases=['ai-phi-3-vision-128k-instruct'], supports_tools=False, base_model=None),\n",
       " Model(id='nvidia/nemotron-4-340b-instruct', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=['qa-nemotron-4-340b-instruct'], supports_tools=False, base_model=None),\n",
       " Model(id='meta/llama-3.1-70b-instruct', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=None, supports_tools=True, base_model=None),\n",
       " Model(id='ibm/granite-34b-code-instruct', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=['ai-granite-34b-code-instruct'], supports_tools=False, base_model=None),\n",
       " Model(id='microsoft/kosmos-2', model_type='vlm', client='ChatNVIDIA', endpoint='https://ai.api.nvidia.com/v1/vlm/microsoft/kosmos-2', aliases=['ai-microsoft-kosmos-2', 'playground_kosmos_2', 'kosmos_2'], supports_tools=False, base_model=None),\n",
       " Model(id='microsoft/phi-3-small-128k-instruct', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=['ai-phi-3-small-128k-instruct'], supports_tools=False, base_model=None),\n",
       " Model(id='snowflake/arctic', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=['ai-arctic'], supports_tools=False, base_model=None),\n",
       " Model(id='meta/llama2-70b', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=['ai-llama2-70b', 'playground_llama2_70b', 'llama2_70b', 'playground_llama2_13b', 'llama2_13b'], supports_tools=False, base_model=None),\n",
       " Model(id='meta/codellama-70b', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=['ai-codellama-70b', 'playground_llama2_code_70b', 'llama2_code_70b', 'playground_llama2_code_34b', 'llama2_code_34b', 'playground_llama2_code_13b', 'llama2_code_13b'], supports_tools=False, base_model=None),\n",
       " Model(id='mistralai/mixtral-8x7b-instruct-v0.1', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=['ai-mixtral-8x7b-instruct', 'playground_mixtral_8x7b', 'mixtral_8x7b'], supports_tools=False, base_model=None),\n",
       " Model(id='aisingapore/sea-lion-7b-instruct', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=['ai-sea-lion-7b-instruct'], supports_tools=False, base_model=None),\n",
       " Model(id='google/codegemma-1.1-7b', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=['ai-codegemma-1.1-7b'], supports_tools=False, base_model=None),\n",
       " Model(id='meta/llama-3.1-405b-instruct', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=None, supports_tools=True, base_model=None),\n",
       " Model(id='mistralai/mixtral-8x22b-instruct-v0.1', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=['ai-mixtral-8x22b-instruct'], supports_tools=False, base_model=None),\n",
       " Model(id='google/codegemma-7b', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=['ai-codegemma-7b'], supports_tools=False, base_model=None),\n",
       " Model(id='meta/llama3-70b-instruct', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=['ai-llama3-70b'], supports_tools=False, base_model=None),\n",
       " Model(id='microsoft/phi-3-mini-128k-instruct', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=['ai-phi-3-mini'], supports_tools=False, base_model=None),\n",
       " Model(id='mistralai/mistral-7b-instruct-v0.3', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=['ai-mistral-7b-instruct-v03'], supports_tools=False, base_model=None),\n",
       " Model(id='seallms/seallm-7b-v2.5', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=['ai-seallm-7b'], supports_tools=False, base_model=None),\n",
       " Model(id='microsoft/phi-3-small-8k-instruct', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=['ai-phi-3-small-8k-instruct'], supports_tools=False, base_model=None),\n",
       " Model(id='mistralai/mistral-7b-instruct-v0.2', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=['ai-mistral-7b-instruct-v2', 'playground_mistral_7b', 'mistral_7b'], supports_tools=False, base_model=None),\n",
       " Model(id='liuhaotian/llava-v1.6-mistral-7b', model_type='vlm', client='ChatNVIDIA', endpoint='https://ai.api.nvidia.com/v1/stg/vlm/community/llava16-mistral-7b', aliases=['ai-llava16-mistral-7b', 'community/llava16-mistral-7b', 'liuhaotian/llava16-mistral-7b'], supports_tools=False, base_model=None),\n",
       " Model(id='meta/llama-3.1-8b-instruct', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=None, supports_tools=True, base_model=None),\n",
       " Model(id='nv-mistralai/mistral-nemo-12b-instruct', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=None, supports_tools=False, base_model=None),\n",
       " Model(id='nvidia/neva-22b', model_type='vlm', client='ChatNVIDIA', endpoint='https://ai.api.nvidia.com/v1/vlm/nvidia/neva-22b', aliases=['ai-neva-22b', 'playground_neva_22b', 'neva_22b'], supports_tools=False, base_model=None),\n",
       " Model(id='upstage/solar-10.7b-instruct', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=['ai-solar-10_7b-instruct'], supports_tools=False, base_model=None),\n",
       " Model(id='google/gemma-2-27b-it', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=['ai-gemma-2-27b-it'], supports_tools=False, base_model=None),\n",
       " Model(id='google/gemma-2-9b-it', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=['ai-gemma-2-9b-it'], supports_tools=False, base_model=None),\n",
       " Model(id='google/recurrentgemma-2b', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=['ai-recurrentgemma-2b'], supports_tools=False, base_model=None),\n",
       " Model(id='mistralai/codestral-22b-instruct-v0.1', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=['ai-codestral-22b-instruct-v01'], supports_tools=False, base_model=None),\n",
       " Model(id='deepseek-ai/deepseek-coder-6.7b-instruct', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=['ai-deepseek-coder-6_7b-instruct'], supports_tools=False, base_model=None),\n",
       " Model(id='microsoft/phi-3-medium-128k-instruct', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=['ai-phi-3-medium-128k-instruct'], supports_tools=False, base_model=None),\n",
       " Model(id='liuhaotian/llava-v1.6-34b', model_type='vlm', client='ChatNVIDIA', endpoint='https://ai.api.nvidia.com/v1/stg/vlm/community/llava16-34b', aliases=['ai-llava16-34b', 'community/llava16-34b', 'liuhaotian/llava16-34b'], supports_tools=False, base_model=None),\n",
       " Model(id='mistralai/mistral-large', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=['ai-mistral-large'], supports_tools=False, base_model=None),\n",
       " Model(id='mediatek/breeze-7b-instruct', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=['ai-breeze-7b-instruct'], supports_tools=False, base_model=None),\n",
       " Model(id='microsoft/phi-3-medium-4k-instruct', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=['ai-phi-3-medium-4k-instruct'], supports_tools=False, base_model=None),\n",
       " Model(id='google/paligemma', model_type='vlm', client='ChatNVIDIA', endpoint='https://ai.api.nvidia.com/v1/vlm/google/paligemma', aliases=['ai-google-paligemma'], supports_tools=False, base_model=None),\n",
       " Model(id='writer/palmyra-med-70b-32k', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=['ai-palmyra-med-70b-32k'], supports_tools=False, base_model=None),\n",
       " Model(id='meta/llama3-8b-instruct', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=['ai-llama3-8b'], supports_tools=False, base_model=None),\n",
       " Model(id='google/gemma-2b', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=['ai-gemma-2b', 'playground_gemma_2b', 'gemma_2b'], supports_tools=False, base_model=None),\n",
       " Model(id='ibm/granite-8b-code-instruct', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=['ai-granite-8b-code-instruct'], supports_tools=False, base_model=None),\n",
       " Model(id='microsoft/phi-3-mini-4k-instruct', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=['ai-phi-3-mini-4k', 'playground_phi2', 'phi2'], supports_tools=False, base_model=None),\n",
       " Model(id='writer/palmyra-med-70b', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=['ai-palmyra-med-70b'], supports_tools=False, base_model=None),\n",
       " Model(id='google/deplot', model_type='vlm', client='ChatNVIDIA', endpoint='https://ai.api.nvidia.com/v1/vlm/google/deplot', aliases=['ai-google-deplot', 'playground_deplot', 'deplot'], supports_tools=False, base_model=None)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ChatNVIDIA.get_available_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86200f9e-9a86-464d-9219-779d98c6a3b5",
   "metadata": {},
   "source": [
    "<h3>\n",
    " Hands-on section    \n",
    "</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32723aa7-9b68-4cfb-997f-430de0268cdc",
   "metadata": {},
   "source": [
    "<h3>Initialising \"meta / llama-3.1-8b-instruct\" LLM model to the cluster</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9b4043c-0e60-4753-9ec5-c31fce3da00f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES\n"
     ]
    }
   ],
   "source": [
    "! docker ps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1815bcb-9f15-49fb-bef3-3fbdb5483176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING! Your password will be stored unencrypted in /home/gsh-3atzc7/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n"
     ]
    }
   ],
   "source": [
    "! echo -e \"$NGC_API_KEY\" | docker login nvcr.io --username '$oauthtoken' --password-stdin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9293a4b9-1fc7-463e-8d91-be72f784caec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.2: Pulling from nim/meta/llama-3.1-8b-instruct\n",
      "Digest: sha256:c53ac18b1161899e3b7006e4cb24737c218f90c320ca2552a5d75e75d9fc4931\n",
      "Status: Image is up to date for nvcr.io/nim/meta/llama-3.1-8b-instruct:1.1.2\n",
      "nvcr.io/nim/meta/llama-3.1-8b-instruct:1.1.2\n"
     ]
    }
   ],
   "source": [
    "! docker pull nvcr.io/nim/meta/llama-3.1-8b-instruct:1.1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "75ab5731-7bc0-4856-a830-6bc52f7042fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPOSITORY                                     TAG       IMAGE ID                                                                  CREATED        SIZE\n",
      "nvcr.io/nim/meta/llama-3.1-8b-instruct         1.1.2     sha256:c9102c3e95f3acae5b41fdafd7aefd3389bdaf33cf0b3458041e45046bf6bb1d   2 months ago   12.9GB\n",
      "nvcr.io/nim/nvidia/nv-rerankqa-mistral-4b-v3   1.0.2     sha256:47df3d3998eb2f8fcf3da6c8aa55297b34c4789234ea0f2cbf54b4bcd411b37d   2 months ago   15.5GB\n",
      "nvcr.io/nim/nvidia/nv-embedqa-e5-v5            1.0.1     sha256:fa5c1fc5ccb39cd6d9910ac04fb8bda7ea46e6f82de8d05c2972d1071d5a62c7   2 months ago   15.7GB\n"
     ]
    }
   ],
   "source": [
    "! docker image ls -a --no-trunc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "130e6259-70d2-4d82-8f96-e9d7fce5f562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/gsh-3atzc7/.cache/nim\n"
     ]
    }
   ],
   "source": [
    "from os.path import expanduser\n",
    "home = expanduser(\"~\")\n",
    "os.environ['LOCAL_NIM_CACHE']=f\"{home}/.cache/nim\"\n",
    "!echo $LOCAL_NIM_CACHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86505154-8d5d-426b-9f80-e0ef09920446",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p \"$LOCAL_NIM_CACHE\"\n",
    "!chmod 777 \"$LOCAL_NIM_CACHE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad59c68-c289-4a98-aaf0-4783fd46dd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import socket\n",
    "\n",
    "def find_available_port(start=11000, end=11999):\n",
    "    while True:\n",
    "        # Randomly select a port between start and end range\n",
    "        port = random.randint(start, end)\n",
    "        \n",
    "        # Try to create a socket and bind to the port\n",
    "        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as sock:\n",
    "            try:\n",
    "                sock.bind((\"localhost\", port))\n",
    "                # If binding is successful, the port is free\n",
    "                return port\n",
    "            except OSError:\n",
    "                # If binding fails, the port is in use, continue to the next iteration\n",
    "                continue\n",
    "\n",
    "# Find and print an available port\n",
    "os.environ['CONTAINER_PORT'] = str(find_available_port())\n",
    "print(f\"Your have been alloted the available port: {os.environ['CONTAINER_PORT']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "547e681b-5964-4a90-9287-12b86c951f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9f0158ebdf3f4a37959de1a5da17285c25f3a02eb462dad502b9b146a955627a\n"
     ]
    }
   ],
   "source": [
    "! docker run -it -d --rm \\\n",
    "--gpus '\"device=1,2\"' \\\n",
    "--name=llm_nim \\\n",
    "--shm-size=32GB \\\n",
    "-e NGC_API_KEY \\\n",
    "-e NIM_MODEL_PROFILE=\"7ea3369b85d7aee24e0739df829da8832b6873803d5f5aca490edad7360830c8\" \\\n",
    "-v $LOCAL_NIM_CACHE:/opt/nim/.cache \\\n",
    "-u $(id -u) \\\n",
    "-p 8000:8000 \\\n",
    "nvcr.io/nim/meta/llama-3.1-8b-instruct:1.1.2\n",
    "\n",
    "# In order to ensure, the local NIM container is completely loaded and doesn't remain in pending stage, we instantiate a wait interval\n",
    "! sleep 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c747b6a9-1605-4511-87a5-2202aa55a7b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "\n",
    "llm = ChatNVIDIA(base_url= \"http://0.0.0.0:8000/v1\", model=\"meta/llama-3.1-8b-instruct\", temperature=0.1, max_tokens=1000, top_p=1.0)\n",
    "\n",
    "result = llm.invoke(\"What is the capital of France?\")\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "64430479-7f01-4671-b029-30ea265d9d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"id\":\"cmpl-841c3b6fea2d4ec8a3db6ae681e1c24a\",\"object\":\"text_completion\",\"created\":1728051640,\"model\":\"meta/llama-3.1-8b-instruct\",\"choices\":[{\"index\":0,\"text\":\" [Answer]\\nThe capital of France is Paris.\\nLooking for somewhere to eat in Paris?\\nWhy the Eiffel Tower is a must visit.\\nPractical information about visiting France. [Answer]\\nLanguage : French\\nCurrency: Euro\\nVisa requirements: Check with your home country's government on the current visa requirements\\n\",\"logprobs\":null,\"finish_reason\":\"length\",\"stop_reason\":null}],\"usage\":{\"prompt_tokens\":8,\"total_tokens\":72,\"completion_tokens\":64}}"
     ]
    }
   ],
   "source": [
    "!curl -X 'POST' \\\n",
    "    \"http://0.0.0.0:8000/v1/completions\" \\\n",
    "    -H \"accept: application/json\" \\\n",
    "    -H \"Content-Type: application/json\" \\\n",
    "    -d '{\"model\": \"meta/llama-3.1-8b-instruct\", \"prompt\": \"What is the capital of France?\", \"max_tokens\": 64}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30ecb50b-7608-4a78-8fd9-d759201f97f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID   IMAGE                                                COMMAND                  CREATED              STATUS              PORTS                                         NAMES\n",
      "9f0158ebdf3f   nvcr.io/nim/meta/llama-3.1-8b-instruct:1.1.2         \"/opt/nvidia/nvidia_…\"   About a minute ago   Up About a minute   0.0.0.0:8000->8000/tcp, :::8000->8000/tcp     llm_nim\n",
      "9f6e021a042b   nvcr.io/nim/nvidia/nv-rerankqa-mistral-4b-v3:1.0.2   \"/opt/nvidia/nvidia_…\"   24 hours ago         Up 24 hours         0.0.0.0:11737->8000/tcp, :::11737->8000/tcp   rerank_nim\n",
      "6c869ca42d4d   nvcr.io/nim/nvidia/nv-embedqa-e5-v5:1.0.1            \"/opt/nvidia/nvidia_…\"   24 hours ago         Up 24 hours         0.0.0.0:11022->8000/tcp, :::11022->8000/tcp   embed_nim\n"
     ]
    }
   ],
   "source": [
    "! docker ps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c664115a-fbc0-469d-b20d-e9b029fcd716",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      3\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94905de9-aedc-47a9-a3ec-8044f9a8889a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm_nim\n"
     ]
    }
   ],
   "source": [
    "!docker container stop llm_nim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffef4fa5-4b81-4bb5-a516-c2c2b9b53820",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker container stop embed_nim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7d2c9b6c-cad3-42e4-9ba5-93a9bc9bba8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===========================================\n",
      "== NVIDIA Inference Microservice LLM NIM ==\n",
      "===========================================\n",
      "\n",
      "NVIDIA Inference Microservice LLM NIM Version 1.1.2\n",
      "Model: nim/meta/llama-3.1-8b-instruct\n",
      "\n",
      "Container image Copyright (c) 2016-2024, NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n",
      "\n",
      "The use of this model is governed by the NVIDIA AI Foundation Models Community License Agreement (found at https://www.nvidia.com/en-us/agreements/enterprise-software/nvidia-ai-foundation-models-community-license-agreement/#:~:text=This%20license%20agreement%20(%E2%80%9CAgreement%E2%80%9D,algorithms%2C%20parameters%2C%20configuration%20files%2C).\n",
      "\n",
      "ADDITIONAL INFORMATION: Llama 3.1 Community License Agreement, Built with Llama.\n",
      "\n",
      "WARNING: The NVIDIA Driver was not detected.  GPU functionality will not be available.\n",
      "   Use the NVIDIA Container Toolkit to start this container with GPU support; see\n",
      "   https://docs.nvidia.com/datacenter/cloud-native/ .\n",
      "\n",
      "INFO 10-16 13:10:43.826 info.py:23] Unable to get hardware specifications, retrieving every profile's info.\n",
      "0494aafce0df9eeaea49bbca6b25fc3013d0e8a752ebcf191a2ddeaab19481ee: tensorrt_llm-l40s-bf16-tp2-latency\n",
      "0bc4cc784e55d0a88277f5d1aeab9f6ecb756b9049dd07c1835035211fcfe77e: tensorrt_llm-h100-fp8-tp2-latency\n",
      "2959f7f0dfeb14631352967402c282e904ff33e1d1fa015f603d9890cf92ca0f: tensorrt_llm-h100-fp8-tp1-throughput\n",
      "3807be802a8ab1d999bf280c96dcd8cf77ac44c0a4d72edb9083f0abb89b6a19: tensorrt_llm-l40s-bf16-tp1-throughput\n",
      "3bb4e8fe78e5037b05dd618cebb1053347325ad6a1e709e0eb18bb8558362ac5: vllm-fp16-tp1\n",
      "40543df47628989c7ef5b16b33bd1f55165dddeb608bf3ccb56cdbb496ba31b0: tensorrt_llm-h100-bf16-tp1-throughput-lora\n",
      "407c6c5d1e29be9929f41b9a2e3193359b8ebfa512353de88cefbf1e0f0b194e: vllm-fp16-tp4\n",
      "4829bb6204dd994f8448ae7fb2cec9d4c6933c382f84463176a5b5cd76cb73c8: tensorrt_llm-a100-fp16-tp2-latency\n",
      "678e6dbe53dd6fe7dc508d22eb0672743ba0b7e735007cfd0b0d2a9e05911fb9: vllm-fp16-tp4-lora\n",
      "6a3ba475d3215ca28f1a8c8886ab4a56b5626d1c98adbfe751025e8ff3d9886d: vllm-fp16-tp2\n",
      "6b89dc22ba60a07df3051451b7dc4ef418d205e52e19cb0845366dc18dd61bd6: tensorrt_llm-l40s-bf16-tp2-throughput-lora\n",
      "7ea3369b85d7aee24e0739df829da8832b6873803d5f5aca490edad7360830c8: tensorrt_llm-a100-bf16-tp1-throughput\n",
      "7f98797c334a8b7205d4cbf986558a2b8a181570b46abed9401f7da6d236955e: tensorrt_llm-h100-bf16-tp2-latency\n",
      "9cff0915527166b2e93c08907afd4f74e168562992034a51db00df802e86518c: tensorrt_llm-h100-bf16-tp1-throughput\n",
      "a506c5bed39ba002797d472eb619ef79b1ffdf8fb96bb54e2ff24d5fc421e196: tensorrt_llm-a100-bf16-tp1-throughput-lora\n",
      "a534b0f5e885d747e819fa8b1ad7dc1396f935425a6e0539cb29b0e0ecf1e669: tensorrt_llm-l40s-bf16-tp2-throughput\n",
      "a95e5c7221dae587b4fc32448df265320ce79064a970297649d97a84eb9dc3ba: vllm-fp16-tp2-lora\n",
      "ba515cc44a34ae4db8fe375bd7e5ad30e9a760bd032230827d8a54835a69c409: tensorrt_llm-a10g-bf16-tp2-throughput\n",
      "d3711d1ebdbe7798834c684c01c10b1091ebef28d1e609b971ecbe6b8c02e05a: vllm-fp16-tp8-lora\n",
      "dfd9bee71abb7582246f7fb8c2aedd9119909b9639e1b4b0260ef6865545ede7: vllm-fp16-tp1-lora\n",
      "e45b4b991bbc51d0df3ce53e87060fc3a7f76555406ed534a8479c6faa706987: tensorrt_llm-a10g-bf16-tp4-latency\n",
      "ec13a06451be8a6e1d8aa4e7a6010f970e0d150a44ce6e6012149c9e60ae3529: vllm-fp16-tp8\n",
      "fcfdd389299632ae51e5560b3368d18c4774441ef620aa1abf80d7077b2ced2b: tensorrt_llm-a10g-bf16-tp4-throughput-lora\n"
     ]
    }
   ],
   "source": [
    "!docker run nvcr.io/nim/meta/llama-3.1-8b-instruct:1.1.2 list-model-profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17cd868-7784-478e-a429-fa9dc63f6882",
   "metadata": {},
   "outputs": [],
   "source": [
    "! docker ps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba6f5f5-c4e7-4549-9c74-58ff7d7edd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "! docker ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1622810f-e7bc-4c9b-9430-7a8737c15f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import expanduser\n",
    "home = expanduser(\"~\")\n",
    "os.environ['LOCAL_NIM_CACHE']=f\"{home}/.cache/nim\"\n",
    "!echo $LOCAL_NIM_CACHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7a9314-f2be-4346-bbd5-8a326e9bae56",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p \"$LOCAL_NIM_CACHE\"\n",
    "# !chmod 777 \"$LOCAL_NIM_CACHE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abeeaf7-00a5-40e7-876d-e95ba01d6f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import socket\n",
    "\n",
    "def find_available_port(start=11000, end=11999):\n",
    "    while True:\n",
    "        # Randomly select a port between start and end range\n",
    "        port = random.randint(start, end)\n",
    "        \n",
    "        # Try to create a socket and bind to the port\n",
    "        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as sock:\n",
    "            try:\n",
    "                sock.bind((\"localhost\", port))\n",
    "                # If binding is successful, the port is free\n",
    "                return port\n",
    "            except OSError:\n",
    "                # If binding fails, the port is in use, continue to the next iteration\n",
    "                continue\n",
    "\n",
    "# Find and print an available port\n",
    "os.environ['CONTAINER_PORT'] = str(find_available_port())\n",
    "print(f\"Your have been alloted the available port: {os.environ['CONTAINER_PORT']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e413e25b-a989-49e4-8b5f-331ed29db701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6c869ca42d4d914c99ced69bd17e7e8d69c5d16ae5436af2b0f910e1c5f82e68\n"
     ]
    }
   ],
   "source": [
    "! docker run -it -d --rm \\\n",
    "--gpus device=2 \\\n",
    "--name=embed_nim \\\n",
    "--shm-size=16GB  \\\n",
    "-e NGC_API_KEY \\\n",
    "-v $LOCAL_NIM_CACHE:/opt/nim/.cache \\\n",
    "-u $(id -u) \\\n",
    "-p 11022:8000 \\\n",
    "nvcr.io/nim/nvidia/nv-embedqa-e5-v5:1.0.1\n",
    "\n",
    "# In order to ensure, the local NIM container is completely loaded and doesn't remain in pending stage, we instantiate a wait interval\n",
    "! sleep 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2b17f422-2e52-468d-8bcb-79849f015188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID   IMAGE                                          COMMAND                  CREATED              STATUS              PORTS                                         NAMES\n",
      "5fee8a1afdc8   nvcr.io/nim/nvidia/nv-embedqa-e5-v5:1.0.1      \"/opt/nvidia/nvidia_…\"   About a minute ago   Up About a minute   0.0.0.0:11022->8000/tcp, :::11022->8000/tcp   embed_nim\n",
      "78bbd2d69c09   nvcr.io/nim/meta/llama-3.1-8b-instruct:1.1.2   \"/opt/nvidia/nvidia_…\"   8 minutes ago        Up 8 minutes        0.0.0.0:8000->8000/tcp, :::8000->8000/tcp     llm_nim\n"
     ]
    }
   ],
   "source": [
    "!docker ps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251f350a-3834-4960-bc47-c63f7d1fada6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker container stop embed_nim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747c9c85-a684-48e2-a74a-e9d861172130",
   "metadata": {},
   "source": [
    "<h3>Deploying embedding and retriever models locally</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2761dcac-fdea-4475-98f9-623c494ed308",
   "metadata": {},
   "outputs": [],
   "source": [
    "! docker pull nvcr.io/nim/nvidia/nv-rerankqa-mistral-4b-v3:1.0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0681212-435d-432b-81bd-ffc0db7f0978",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpath\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m expanduser\n\u001b[1;32m      2\u001b[0m home \u001b[38;5;241m=\u001b[39m expanduser(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m~\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLOCAL_NIM_CACHE\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhome\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/.cache/nim\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mecho $LOCAL_NIM_CACHE\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "from os.path import expanduser\n",
    "home = expanduser(\"~\")\n",
    "os.environ['LOCAL_NIM_CACHE']=f\"{home}/.cache/nim\"\n",
    "!echo $LOCAL_NIM_CACHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdc598e-a070-47cb-b03d-9c5f63705779",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p \"$LOCAL_NIM_CACHE\"\n",
    "# !chmod 777 \"$LOCAL_NIM_CACHE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6576e7a2-c496-44ed-b085-e1fbd3f6ea00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import socket\n",
    "\n",
    "def find_available_port(start=11000, end=11999):\n",
    "    while True:\n",
    "        # Randomly select a port between start and end range\n",
    "        port = random.randint(start, end)\n",
    "        \n",
    "        # Try to create a socket and bind to the port\n",
    "        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as sock:\n",
    "            try:\n",
    "                sock.bind((\"localhost\", port))\n",
    "                # If binding is successful, the port is free\n",
    "                return port\n",
    "            except OSError:\n",
    "                # If binding fails, the port is in use, continue to the next iteration\n",
    "                continue\n",
    "\n",
    "# Find and print an available port\n",
    "os.environ['CONTAINER_PORT'] = str(find_available_port())\n",
    "print(f\"Your have been alloted the available port: {os.environ['CONTAINER_PORT']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4ad5936-904e-49f3-b7f6-ff2a61d7152d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9f6e021a042b54291fcc9b160a33dc5e99f3aef1e8ca22bc5e8c8310d38fe6aa\n"
     ]
    }
   ],
   "source": [
    "! docker run -it -d --rm \\\n",
    "--gpus device=0  \\\n",
    "--name=rerank_nim \\\n",
    "--shm-size=16GB  \\\n",
    "-e NGC_API_KEY \\\n",
    "-v $LOCAL_NIM_CACHE:/opt/nim/.cache \\\n",
    "-u $(id -u) \\\n",
    "-p 11737:8000 \\\n",
    "nvcr.io/nim/nvidia/nv-rerankqa-mistral-4b-v3:1.0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "544a8cb7-8404-46a5-80e8-d5e381dc1962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID   IMAGE                                                COMMAND                  CREATED          STATUS          PORTS                                         NAMES\n",
      "9f6e021a042b   nvcr.io/nim/nvidia/nv-rerankqa-mistral-4b-v3:1.0.2   \"/opt/nvidia/nvidia_…\"   56 seconds ago   Up 54 seconds   0.0.0.0:11737->8000/tcp, :::11737->8000/tcp   rerank_nim\n",
      "6c869ca42d4d   nvcr.io/nim/nvidia/nv-embedqa-e5-v5:1.0.1            \"/opt/nvidia/nvidia_…\"   2 minutes ago    Up 2 minutes    0.0.0.0:11022->8000/tcp, :::11022->8000/tcp   embed_nim\n",
      "dad2c034c5d2   nvcr.io/nim/meta/llama-3.1-8b-instruct:1.1.2         \"/opt/nvidia/nvidia_…\"   11 minutes ago   Up 11 minutes   0.0.0.0:8000->8000/tcp, :::8000->8000/tcp     llm_nim\n"
     ]
    }
   ],
   "source": [
    "!docker ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e699f6-8510-4096-8e2d-156e3e36e0a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "03bd7195-f2c5-45e1-8913-deb3d0292a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\"https://www.nvidia.com/en-in/glossary/retrieval-augmented-generation/\",\n",
    "       \"https://en.wikipedia.org/wiki/Retrieval-augmented_generation\",\n",
    "        \"https://docs.nvidia.com/cuda/\",\n",
    "        \"https://github.com/NVIDIA/cuda-samples\"\n",
    "        \"https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html\"\n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "111d5f1e-c91e-4b27-98f9-2965b26e84d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from typing import List, Union\n",
    "\n",
    "def html_document_loader(url: Union[str, bytes]) -> str:\n",
    "    \"\"\"\n",
    "    Loads the HTML content of a document from a given URL and return it's content.\n",
    "\n",
    "    Args:\n",
    "        url: The URL of the document.\n",
    "\n",
    "    Returns:\n",
    "        The content of the document.\n",
    "\n",
    "    Raises:\n",
    "        Exception: If there is an error while making the HTTP request.\n",
    "\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        html_content = response.text\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load {url} due to exception {e}\")\n",
    "        return \"\"\n",
    "\n",
    "    try:\n",
    "        # Create a Beautiful Soup object to parse html\n",
    "        soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "\n",
    "        # Remove script and style tags\n",
    "        for script in soup([\"script\", \"style\"]):\n",
    "            script.extract()\n",
    "\n",
    "        # Get the plain text from the HTML document\n",
    "        text = soup.get_text()\n",
    "\n",
    "        # Remove excess whitespace and newlines\n",
    "        text = re.sub(\"\\s+\", \" \", text).strip()\n",
    "\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(f\"Exception {e} while loading document\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2be7e048-fa6e-4b95-97dc-a745c53732e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings(embeddings_model,embedding_path: str = \"./embed\"):\n",
    "\n",
    "    embedding_path = \"./embed\"\n",
    "    print(f\"Storing embeddings to {embedding_path}\")\n",
    "\n",
    "    documents = []\n",
    "    for url in urls:\n",
    "        document = html_document_loader(url)\n",
    "        documents.append(document)\n",
    "\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500,\n",
    "        chunk_overlap=0,\n",
    "        length_function=len,\n",
    "    )\n",
    "    print(\"Total documents:\",len(documents))\n",
    "    texts = text_splitter.create_documents(documents)\n",
    "    print(\"Total texts:\",len(texts))\n",
    "    index_docs(embeddings_model,url, text_splitter, texts, embedding_path,)\n",
    "    print(\"Generated embedding successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bed5925f-718d-481c-9374-749d3b4dcfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_model = NVIDIAEmbeddings(base_url=\"http://0.0.0.0:11022/v1\", model='nvidia/nv-embedqa-e5-v5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7ecfac-ff25-4758-8e97-222330d2bb97",
   "metadata": {},
   "source": [
    "<h3>Faiss vector store through langchain</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7924a57b-b174-4855-81ec-b6482e242788",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Union\n",
    "import os\n",
    "from langchain.vectorstores import FAISS\n",
    "# model_kwargs = {\"device\": \"cuda\"}\n",
    "\n",
    "def index_docs(embeddings_model, url: Union[str, bytes], splitter, documents: List[str], dest_embed_dir: str) -> None:\n",
    "    \"\"\"\n",
    "    Split the documents into chunks and create embeddings for them.\n",
    "    \n",
    "    Args:\n",
    "        embeddings_model: Model used for creating embeddings.\n",
    "        url: Source url for the documents.\n",
    "        splitter: Splitter used to split the documents.\n",
    "        documents: List of documents whose embeddings need to be created.\n",
    "        dest_embed_dir: Destination directory for embeddings.\n",
    "    \"\"\"\n",
    "    texts = []\n",
    "    metadatas = []\n",
    "\n",
    "    for document in documents:\n",
    "        chunk_texts = splitter.split_text(document.page_content)\n",
    "        texts.extend(chunk_texts)\n",
    "        metadatas.extend([document.metadata] * len(chunk_texts))\n",
    "\n",
    "    if os.path.exists(dest_embed_dir):\n",
    "        docsearch = FAISS.load_local(\n",
    "            folder_path=dest_embed_dir, \n",
    "            embeddings=embeddings_model, \n",
    "            allow_dangerous_deserialization=True\n",
    "        )\n",
    "        docsearch.add_texts(texts, metadatas=metadatas)\n",
    "    else:\n",
    "        docsearch = FAISS.from_texts(texts, embedding=embeddings_model, metadatas=metadatas,)\n",
    "\n",
    "    docsearch.save_local(folder_path=dest_embed_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6104b9eb-9f0c-4c69-83e2-acdaac4eb3e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storing embeddings to ./embed\n",
      "Processing PDF: CUDA_C_Programming_Guide.pdf\n",
      "Total documents: 6\n",
      "Total texts: 3026\n",
      "Generated embedding successfully\n",
      "CPU times: user 2.67 s, sys: 181 ms, total: 2.85 s\n",
      "Wall time: 10.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "create_embeddings(embeddings_model=embeddings_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "13cdc771-0683-471b-9c9a-903516a273a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "print(faiss.get_num_gpus())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "44f15b99-8603-4a79-b0be-2a61cff972d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load Embed documents\n",
    "embedding_path = \"./embed/\"\n",
    "docsearch = FAISS.load_local(folder_path=embedding_path, embeddings=embeddings_model, allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d12210-4d9c-4c10-8316-a2fe51b57c9c",
   "metadata": {},
   "source": [
    "<h3>HTML and pdf embedding </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b25004cc-d029-44a8-a06c-40313a62ee4c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\"NVIDIAEmbeddings\" object has no field \"embed_query\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 334\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membed_documents must return a list or a NumPy array.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    333\u001b[0m \u001b[38;5;66;03m# Replace the methods in embeddings_model with the wrapped ones\u001b[39;00m\n\u001b[0;32m--> 334\u001b[0m \u001b[43membeddings_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_query\u001b[49m \u001b[38;5;241m=\u001b[39m embed_query_np\n\u001b[1;32m    335\u001b[0m embeddings_model\u001b[38;5;241m.\u001b[39membed_documents \u001b[38;5;241m=\u001b[39m embed_documents_np\n\u001b[1;32m    337\u001b[0m \u001b[38;5;66;03m# Create embeddings\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/nim_env/lib/python3.9/site-packages/pydantic/v1/main.py:357\u001b[0m, in \u001b[0;36mBaseModel.__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m object_setattr(\u001b[38;5;28mself\u001b[39m, name, value)\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__config__\u001b[38;5;241m.\u001b[39mextra \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Extra\u001b[38;5;241m.\u001b[39mallow \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__fields__:\n\u001b[0;32m--> 357\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m object has no field \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__config__\u001b[38;5;241m.\u001b[39mallow_mutation \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__config__\u001b[38;5;241m.\u001b[39mfrozen:\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is immutable and does not support item assignment\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: \"NVIDIAEmbeddings\" object has no field \"embed_query\""
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import requests\n",
    "import pymupdf  # Explicitly using pymupdf instead of fitz\n",
    "from bs4 import BeautifulSoup\n",
    "from typing import List, Union\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "  # Replace with your actual embeddings model\n",
    "import faiss\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# List of URLs\n",
    "urls = [\n",
    "    \"https://www.nvidia.com/en-in/glossary/retrieval-augmented-generation/\",\n",
    "    \"https://en.wikipedia.org/wiki/Retrieval-augmented_generation\",\n",
    "    \"https://docs.nvidia.com/cuda/\",\n",
    "    \"https://github.com/NVIDIA/cuda-samples\",\n",
    "    \"https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html\",\n",
    "    \"https://developer.nvidia.com/blog/efficient-cuda-debugging-using-compute-sanitizer-with-nvtx-and-creating-custom-tools/\",\n",
    "    \"https://developer.nvidia.com/blog/debugging-cuda-more-efficiently-with-nvidia-compute-sanitizer/\",\n",
    "    \"https://developer.nvidia.com/blog/multi-gpu-programming-with-standard-parallel-c-part-1/\",\n",
    "    \"https://developer.nvidia.com/blog/multi-gpu-programming-with-standard-parallel-c-part-2\",\n",
    "    \"https://developer.nvidia.com/blog/efficient-cuda-debugging-memory-initialization-and-thread-synchronization-with-nvidia-compute-sanitizer/\",\n",
    "    \"https://cuda-tutorial.readthedocs.io/en/latest/tutorials/tutorial02/#introduction\",\n",
    "    \"https://developer.nvidia.com/blog/even-easier-introduction-cuda/\",\n",
    "    \"https://github.com/jkonvicka/Nvidia-CUDA-course/blob/main/AC_CUDA_C.md\",\n",
    "    \"https://github.com/jkonvicka/Nvidia-CUDA-course/blob/main/cuda_cheatsheet.md\",\n",
    "    \"https://github.com/jkonvicka/Nvidia-CUDA-course/blob/main/Unified%20Memory.md\",\n",
    "    \"https://github.com/jkonvicka/Nvidia-CUDA-course/blob/main/Streaming%20and%20Visual%20Profiling.md\",\n",
    "    \"https://github.com/jkonvicka/Nvidia-CUDA-course/blob/main/AC_CUDA_C.md\",\n",
    "    \"https://tbetcke.github.io/hpc_lecture_notes/intro.html\",\n",
    "]\n",
    "\n",
    "# Directory containing PDF files\n",
    "pdf_dir = '/mnt/lustre/hackathons/hack_teams/hack_team_16/workspace/Jishnu/Pdf'\n",
    "\n",
    "# Directory containing other file types (e.g., .txt, .docx)\n",
    "other_files_dir = '/mnt/lustre/hackathons/hack_teams/hack_team_16/workspace/Jishnu/text'\n",
    "\n",
    "# Function to load HTML content from a URL\n",
    "def html_document_loader(url: Union[str, bytes]) -> str:\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Raise exception for HTTP errors\n",
    "        html_content = response.text\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to load {url} due to exception: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "    try:\n",
    "        soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "        # Remove script and style tags\n",
    "        for script in soup([\"script\", \"style\"]):\n",
    "            script.extract()\n",
    "        text = soup.get_text()\n",
    "        text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "        return text if isinstance(text, str) else \"\"\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Exception {e} while parsing HTML from {url}\")\n",
    "        return \"\"\n",
    "\n",
    "# Function to extract text from PDFs using PyMuPDF\n",
    "def extract_text_from_pdfs(pdf_directory: str) -> List[dict]:\n",
    "    pdf_texts = []\n",
    "    \n",
    "    for pdf_file in os.listdir(pdf_directory):\n",
    "        if pdf_file.lower().endswith('.pdf'):\n",
    "            pdf_path = os.path.join(pdf_directory, pdf_file)\n",
    "            logging.info(f\"Processing PDF: {pdf_file}\")\n",
    "\n",
    "            # Open the PDF file\n",
    "            try:\n",
    "                with pymupdf.open(pdf_path) as doc:\n",
    "                    extracted_text = \"\"\n",
    "                    for page_num in range(len(doc)):\n",
    "                        page = doc.load_page(page_num)\n",
    "                        extracted_text += page.get_text()\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Failed to process PDF {pdf_file}: {e}\")\n",
    "                continue\n",
    "\n",
    "            # Ensure extracted text is a string\n",
    "            extracted_text = extracted_text if isinstance(extracted_text, str) else \"\"\n",
    "            \n",
    "            # Append extracted text and metadata\n",
    "            pdf_texts.append({\n",
    "                'page_content': extracted_text,\n",
    "                'metadata': {'type': 'pdf', 'source': pdf_file}\n",
    "            })\n",
    "\n",
    "    return pdf_texts\n",
    "\n",
    "# Function to handle other file types using UnstructuredFileLoader\n",
    "def extract_text_from_other_files(file_directory: str) -> List[dict]:\n",
    "    other_texts = []\n",
    "    \n",
    "    for file_name in os.listdir(file_directory):\n",
    "        file_path = os.path.join(file_directory, file_name)\n",
    "        # Use UnstructuredFileLoader for other file types\n",
    "        loader = UnstructuredFileLoader(file_path)\n",
    "        try:\n",
    "            loaded_documents = loader.load()\n",
    "            for doc in loaded_documents:\n",
    "                other_texts.append({\n",
    "                    'page_content': doc.page_content,\n",
    "                    'metadata': {'type': 'file', 'source': file_name}\n",
    "                })\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Failed to load file {file_name} due to exception: {e}\")\n",
    "    \n",
    "    return other_texts\n",
    "\n",
    "# Function to embed documents in batches\n",
    "def embed_documents_batch(embeddings_model, documents: List[str], batch_size: int = 32) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Embed documents in batches and return a NumPy array of embeddings.\n",
    "    \n",
    "    Args:\n",
    "        embeddings_model: The embeddings model instance.\n",
    "        documents (List[str]): A list of document texts to embed.\n",
    "        batch_size (int): Number of documents to process in each batch.\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: A 2D NumPy array where each row is an embedding vector.\n",
    "    \"\"\"\n",
    "    embeddings = []\n",
    "    for i in range(0, len(documents), batch_size):\n",
    "        batch = documents[i:i + batch_size]\n",
    "        batch_embeddings = embeddings_model.embed_documents(batch)\n",
    "        \n",
    "        # Convert to NumPy array if it's a list\n",
    "        if isinstance(batch_embeddings, list):\n",
    "            batch_embeddings = np.array(batch_embeddings, dtype='float32')\n",
    "        elif isinstance(batch_embeddings, np.ndarray):\n",
    "            batch_embeddings = batch_embeddings.astype('float32')\n",
    "        else:\n",
    "            raise TypeError(\"embed_documents must return a list or a NumPy array.\")\n",
    "        \n",
    "        embeddings.append(batch_embeddings)\n",
    "    \n",
    "    # Concatenate all batches into a single NumPy array\n",
    "    return np.vstack(embeddings)\n",
    "\n",
    "# Function to index documents using embeddings with FAISS GPU\n",
    "def index_docs(\n",
    "    embeddings_model, \n",
    "    urls: List[str], \n",
    "    splitter, \n",
    "    documents: List[object], \n",
    "    dest_embed_dir: str\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Index documents using FAISS with GPU support.\n",
    "    \n",
    "    Args:\n",
    "        embeddings_model: The embeddings model instance.\n",
    "        urls (List[str]): List of URLs processed.\n",
    "        splitter: Text splitter instance.\n",
    "        documents (List[object]): List of Document objects.\n",
    "        dest_embed_dir (str): Directory to save/load the FAISS index.\n",
    "    \"\"\"\n",
    "    texts = []\n",
    "    metadatas = []\n",
    "\n",
    "    for document in documents:\n",
    "        # Access attributes instead of dictionary keys\n",
    "        page_content = document.page_content\n",
    "        metadata = document.metadata\n",
    "\n",
    "        # Ensure document content is a string\n",
    "        if not isinstance(page_content, str):\n",
    "            logging.warning(f\"Skipping document due to invalid content: {document}\")\n",
    "            continue\n",
    "\n",
    "        # Split the text into chunks\n",
    "        chunk_texts = splitter.split_text(page_content)\n",
    "        texts.extend(chunk_texts)\n",
    "        metadatas.extend([metadata] * len(chunk_texts))\n",
    "\n",
    "    if not texts:\n",
    "        logging.error(\"No valid texts found for embedding.\")\n",
    "        return\n",
    "\n",
    "    # Embed the texts in batches\n",
    "    try:\n",
    "        embeddings = embed_documents_batch(embeddings_model, texts, batch_size=32)\n",
    "        logging.info(f\"Generated embeddings for {len(texts)} text chunks.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to generate embeddings: {e}\")\n",
    "        return\n",
    "\n",
    "    # Determine the embedding dimension from the first embedding\n",
    "    dim = embeddings.shape[1]\n",
    "    logging.info(f\"Embedding dimension: {dim}\")\n",
    "\n",
    "    # Initialize FAISS with GPU support\n",
    "    try:\n",
    "        index = faiss.IndexFlatL2(dim)  # Exact search index\n",
    "        res = faiss.StandardGpuResources()\n",
    "        gpu_index = faiss.index_cpu_to_gpu(res, 0, index)  # GPU ID 0\n",
    "        logging.info(\"FAISS index moved to GPU 0.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to initialize FAISS index on GPU: {e}\")\n",
    "        return\n",
    "\n",
    "    # Create FAISS vector store using Langchain\n",
    "    try:\n",
    "        if os.path.exists(dest_embed_dir):\n",
    "            # Load existing FAISS index\n",
    "            docsearch = FAISS.load_local(\n",
    "                folder_path=dest_embed_dir, \n",
    "                embeddings=embeddings_model, \n",
    "                allow_dangerous_deserialization=True\n",
    "            )\n",
    "            logging.info(\"Loaded existing FAISS index from local directory.\")\n",
    "            \n",
    "            # Extract vectors from the existing index\n",
    "            cpu_index = docsearch.index\n",
    "            vectors = cpu_index.reconstruct_n(0, cpu_index.ntotal)\n",
    "            gpu_index.add(vectors)\n",
    "            logging.info(f\"Added {cpu_index.ntotal} vectors to GPU FAISS index.\")\n",
    "        else:\n",
    "            # Add embeddings to the GPU index\n",
    "            gpu_index.add(embeddings)\n",
    "            logging.info(f\"Added {len(embeddings)} vectors to FAISS GPU index.\")\n",
    "\n",
    "            # Create FAISS vector store using Langchain\n",
    "            docsearch = FAISS.from_texts(\n",
    "                texts, \n",
    "                embedding=embeddings_model, \n",
    "                metadatas=metadatas, \n",
    "                index=gpu_index\n",
    "            )\n",
    "            logging.info(\"Created new FAISS vector store with GPU index.\")\n",
    "        \n",
    "        # Save the FAISS index locally\n",
    "        docsearch.save_local(folder_path=dest_embed_dir)\n",
    "        logging.info(f\"FAISS index saved to {dest_embed_dir}.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed during FAISS vector store creation or saving: {e}\")\n",
    "        return\n",
    "\n",
    "# Function to process HTML, PDF, and other files and create embeddings\n",
    "def create_embeddings(embeddings_model, embedding_path: str = \"./embed\"):\n",
    "    \"\"\"\n",
    "    Process documents and create embeddings using FAISS with GPU support.\n",
    "    \n",
    "    Args:\n",
    "        embeddings_model: The embeddings model instance.\n",
    "        embedding_path (str): Directory to save/load the FAISS index.\n",
    "    \"\"\"\n",
    "    logging.info(f\"Storing embeddings to {embedding_path}\")\n",
    "\n",
    "    documents = []\n",
    "    total_html_docs = 0  # Variable to keep track of HTML document count\n",
    "\n",
    "    # Load HTML content from URLs\n",
    "    for url in urls:\n",
    "        document_content = html_document_loader(url)\n",
    "        if document_content:\n",
    "            total_html_docs += 1\n",
    "            documents.append({\n",
    "                'page_content': document_content, \n",
    "                'metadata': {'type': 'html', 'source': url}\n",
    "            })\n",
    "\n",
    "    # Extract text from PDFs\n",
    "    pdf_documents = extract_text_from_pdfs(pdf_dir)\n",
    "    total_pdf_docs = len(pdf_documents)  # Count PDF documents\n",
    "    documents.extend(pdf_documents)\n",
    "\n",
    "    # Check if the directory for other files exists and is not empty\n",
    "    if os.path.exists(other_files_dir) and os.listdir(other_files_dir):\n",
    "        other_files_documents = extract_text_from_other_files(other_files_dir)\n",
    "        documents.extend(other_files_documents)\n",
    "\n",
    "    # Extract the text content for splitting\n",
    "    document_texts = [doc['page_content'] for doc in documents if isinstance(doc.get('page_content', \"\"), str)]\n",
    "\n",
    "    # Split text into chunks and create embeddings\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500,\n",
    "        chunk_overlap=0,\n",
    "        length_function=len,\n",
    "    )\n",
    "    logging.info(f\"Total HTML documents: {total_html_docs}\")\n",
    "    logging.info(f\"Total PDF documents: {total_pdf_docs}\")\n",
    "    logging.info(f\"Total other documents: {len(documents) - total_html_docs - total_pdf_docs}\")\n",
    "    logging.info(f\"Total documents: {len(document_texts)}\")\n",
    "\n",
    "    # Create Langchain Document objects\n",
    "    texts = text_splitter.create_documents(document_texts)  # This returns a list of Document objects\n",
    "    logging.info(f\"Total texts (chunks): {len(texts)}\")\n",
    "\n",
    "    # Index the documents\n",
    "    index_docs(embeddings_model, urls, text_splitter, texts, embedding_path)\n",
    "    logging.info(\"Generated embedding successfully.\")\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize your embeddings model\n",
    "    embeddings_model = embeddings_model # Replace with NVIDIAEmbeddings or your specific model\n",
    "\n",
    "    # If using NVIDIAEmbeddings as per your input, ensure it's correctly implemented\n",
    "    # For example:\n",
    "    # embeddings_model = NVIDIAEmbeddings(base_url=\"http://0.0.0.0:11022/v1\", model='nvidia/nv-embedqa-e5-v5')\n",
    "\n",
    "    # Optionally, wrap embed_query and embed_documents if they return lists\n",
    "    def embed_query_np(query):\n",
    "        embedding = embeddings_model.embed_query(query)\n",
    "        if isinstance(embedding, list):\n",
    "            return np.array(embedding, dtype='float32')\n",
    "        elif isinstance(embedding, np.ndarray):\n",
    "            return embedding.astype('float32')\n",
    "        else:\n",
    "            raise TypeError(\"embed_query must return a list or a NumPy array.\")\n",
    "\n",
    "    def embed_documents_np(documents):\n",
    "        embeddings = embeddings_model.embed_documents(documents)\n",
    "        if isinstance(embeddings, list):\n",
    "            return np.array(embeddings, dtype='float32')\n",
    "        elif isinstance(embeddings, np.ndarray):\n",
    "            return embeddings.astype('float32')\n",
    "        else:\n",
    "            raise TypeError(\"embed_documents must return a list or a NumPy array.\")\n",
    "\n",
    "    # Replace the methods in embeddings_model with the wrapped ones\n",
    "    embeddings_model.embed_query = embed_query_np\n",
    "    embeddings_model.embed_documents = embed_documents_np\n",
    "\n",
    "    # Create embeddings\n",
    "    create_embeddings(embeddings_model, embedding_path=pdf_dir)  # Specify your embedding path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "75693417-6d64-4f02-aa62-69e5df3181bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Storing embeddings to ./embed\n",
      "INFO:root:Processing PDF: 9781788996242_ColorImages.pdf\n",
      "INFO:root:Processing PDF: CUDA_C_Programming_Guide.pdf\n",
      "INFO:root:Processing PDF: [2013] The_CUDA_Handbook.pdf\n",
      "INFO:root:Processing PDF: sc11-cuda-c-basics.pdf\n",
      "INFO:root:Processing PDF: openacc-guide.pdf\n",
      "INFO:root:Processing PDF: CUDA_by_Example.pdf\n",
      "INFO:root:Total HTML documents: 18\n",
      "INFO:root:Total PDF documents: 6\n",
      "INFO:root:Total other documents: 0\n",
      "INFO:root:Total documents: 24\n",
      "INFO:root:Total texts (chunks): 6812\n",
      "INFO:root:Generated embeddings for 6812 text chunks.\n",
      "INFO:root:Embedding dimension: 1024\n",
      "INFO:root:FAISS index moved to GPU 0.\n",
      "INFO:root:Loaded existing FAISS index from local directory.\n",
      "INFO:root:Added 49073 vectors to GPU FAISS index.\n",
      "INFO:root:FAISS index saved to ./embed.\n",
      "INFO:root:Generated embedding successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.14 s, sys: 727 ms, total: 7.87 s\n",
      "Wall time: 23.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "embeddings_model = NVIDIAEmbeddings(base_url=\"http://0.0.0.0:11022/v1\", model='nvidia/nv-embedqa-e5-v5')\n",
    "create_embeddings(embeddings_model=embeddings_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "49d72381-59c8-486a-b5d3-461616320c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID   IMAGE                                                COMMAND                  CREATED        STATUS        PORTS                                         NAMES        SIZE\n",
      "4ad7b8ee2bb5   nvcr.io/nim/nvidia/nv-embedqa-e5-v5:1.0.1            \"/opt/nvidia/nvidia_…\"   21 hours ago   Up 21 hours   0.0.0.0:11022->8000/tcp, :::11022->8000/tcp   embed_nim    995kB (virtual 15.7GB)\n",
      "6ef6ad73da55   nvcr.io/nim/nvidia/nv-rerankqa-mistral-4b-v3:1.0.2   \"/opt/nvidia/nvidia_…\"   21 hours ago   Up 21 hours   0.0.0.0:11737->8000/tcp, :::11737->8000/tcp   rerank_nim   1.91MB (virtual 15.5GB)\n",
      "a5732a8ccde9   nvcr.io/nim/meta/llama-3.1-8b-instruct:1.1.2         \"/opt/nvidia/nvidia_…\"   22 hours ago   Up 22 hours   0.0.0.0:8000->8000/tcp, :::8000->8000/tcp     LLM_nim      9.03MB (virtual 12.9GB)\n"
     ]
    }
   ],
   "source": [
    "!docker ps -s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e559b733-90e8-4717-aae5-d36cef9376ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untagged: nvcr.io/nim/meta/llama3-8b-instruct:1.0.0\n",
      "Untagged: nvcr.io/nim/meta/llama3-8b-instruct@sha256:7fe6071923b547edd9fba87c891a362ea0b4a88794b8a422d63127e54caa6ef7\n",
      "Deleted: sha256:3cb29b0d79e6d84ca4fd132aa66b652408e8c0fb88177cfee06a55418fdc3de2\n",
      "Deleted: sha256:d363b236bc57a7c2d43748a0272361d9c93a1a830b1b65729d48070734919bf4\n",
      "Deleted: sha256:0afef4f6b6a5eae810e2dde7db5d571d9ac4ac120f1ab8938b6d25ba923d85b4\n",
      "Deleted: sha256:113fe49b1d137ede04be15d2eca24351c065822d01a5a6c65410a3b37660784e\n",
      "Deleted: sha256:90cc92b781e2986bdfff11a03227a7133a237d376e6ae3ada86d28cf710effac\n",
      "Deleted: sha256:c94eb581f0fdd36f8419033ec5c3791925899c00c75638d88ce8638e959df5c6\n",
      "Deleted: sha256:419a712e152882383be969cd316bbb38cb4e1d8191e346a2173cf79210e959a1\n",
      "Deleted: sha256:9c94d94a89cb580e6f0a302668e3330e2dc3461f5db6048bca23f7716735c89b\n",
      "Deleted: sha256:3ae37cc3ebe01ff609d1829e67fcf8b1d9d51696e49e00d4ab154e1c585a007d\n",
      "Deleted: sha256:0e876143f4822a81e5fa5d0f89f8e0c13f3c5f5176dd9f51835a445292bacbe8\n",
      "Deleted: sha256:57a6af77038d2018e7898c13d29051f175d47cc4741b73e35a8f498fdc3e1381\n",
      "Deleted: sha256:fcce2c5a77b1bac6d4a647980540dbe92d7e84f4dc0c748b45321e2c89aad87d\n",
      "Deleted: sha256:13a1af48af37d5ad641dbce098fd0760ac834431d41ad09d43b742ec1cdcb7ba\n",
      "Deleted: sha256:33429a6f81db8c4fc44fe85439582e5a3530238a2eb99aea59a7a061b9726405\n",
      "Deleted: sha256:8f564c60ae9c64d2ff3248a48adfdd285dd8856f2ef13bee35c1c1fe4e93e1ea\n",
      "Deleted: sha256:a8dc6959f9a6949012f09441705fd90a24f5a4fdcee06c4bf500cf989f226a26\n",
      "Deleted: sha256:6dee6361a78dbf7fe97064d81f444f5748cd28736ba1b3b2f77383cd929296dd\n",
      "Deleted: sha256:e32279784004cbf54722e412e106645059c6b070a30c035886fe59c191fc4aa5\n",
      "Deleted: sha256:3f819aa851120c9a0a759125b46eeba7b4891d536474be4639b8f1ed1d1578f6\n",
      "Deleted: sha256:51cab3e16a5ff135e323c70de0769bbb97b3bf9118827220613cfec01833cdab\n",
      "Deleted: sha256:43419bb17b86dd00d56b0f2b3aa9132dd59e9d70c6546ca6f176a6baa720cd48\n",
      "Deleted: sha256:d797a4fc885237240cb2f522e9617988c1dce5bf08640d05abbb69e64fd497cd\n"
     ]
    }
   ],
   "source": [
    "!docker rmi 3cb29b0d79e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b384c51-0d3c-496b-bda1-761efdf44901",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_path = \"./embed/\"\n",
    "docsearch = FAISS.load_local(folder_path=embedding_path, embeddings=embeddings_model, allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ed868c58-e6b3-4fa2-8347-7917869db5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatNVIDIA(base_url= \"http://0.0.0.0:8000/v1\", model=\"meta/llama-3.1-8b-instruct\", temperature=0.1, max_tokens=1000, top_p=1.0)\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "qa_prompt=QA_PROMPT\n",
    "\n",
    "doc_chain = load_qa_chain(llm, chain_type=\"stuff\", prompt=QA_PROMPT)\n",
    "\n",
    "qa = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=docsearch.as_retriever(),\n",
    "    chain_type=\"stuff\",\n",
    "    memory=memory,\n",
    "    combine_docs_chain_kwargs={'prompt': qa_prompt},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2815e668-bb58-4b11-9b79-c23c0ce7a040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It seems like there's a bit of repetition in the text! Based on the provided context, I'll summarize the salient features of CUDA:\n",
      "\n",
      "1. **No knowledge of OpenGL or DirectX required**: Users don't need to have expertise in these graphics programming interfaces to use CUDA.\n",
      "2. **No need to force problems to look like computer graphics tasks**: CUDA allows users to focus on their specific problem domain without having to adapt it to a graphics-related framework.\n",
      "3. **Orders-of-magnitude performance improvement**: CUDA can lead to significant performance enhancements over traditional approaches.\n",
      "\n",
      "Let me know if you'd like me to clarify or expand on these points!\n"
     ]
    }
   ],
   "source": [
    "query = \"What are the salient features of CUDA\"\n",
    "result = qa({\"question\": query})\n",
    "print(result.get(\"answer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e6622fdd-6d58-442d-b037-a03a36ef8e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't have the text to answer the question. It looks like the text is repeated multiple times, but it doesn't provide any content.\n"
     ]
    }
   ],
   "source": [
    "query = \"What is RAG?\"\n",
    "result = qa({\"question\": query})\n",
    "print(result.get(\"answer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8502cdd6-48fa-441a-98cf-8fc43fef6719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text doesn't provide a direct answer to the question of how to profile CUDA applications, but it does mention that \"See the Application Note on CUDA for Tegra for details.\" This suggests that the Application Note on CUDA for Tegra contains information on how to profile CUDA applications.\n",
      "\n",
      "So, my answer is: See the Application Note on CUDA for Tegra for details.\n"
     ]
    }
   ],
   "source": [
    "query = \"how to do profiling?\"\n",
    "result = qa({\"question\": query})\n",
    "print(result.get(\"answer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5c07a083-99e9-4763-b426-201397798b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unfortunately, the provided text does not explicitly state whether you can read double precision floats from a texture or not. It discusses interpolation and precision in the context of a microdemo, but it does not provide a clear answer to the question.\n"
     ]
    }
   ],
   "source": [
    "query = \"Can I read double precision floats from texture?\"\n",
    "result = qa({\"question\": query})\n",
    "print(result.get(\"answer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e2cd9d4b-188e-4c04-b567-eff752183cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nemoguardrails in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (0.10.1)\n",
      "Requirement already satisfied: aiohttp>=3.9.2 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from nemoguardrails) (3.9.5)\n",
      "Requirement already satisfied: annoy>=1.17.3 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from nemoguardrails) (1.17.3)\n",
      "Requirement already satisfied: fastapi>=0.103.0 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from nemoguardrails) (0.115.0)\n",
      "Requirement already satisfied: fastembed>=0.2.2 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from nemoguardrails) (0.3.6)\n",
      "Requirement already satisfied: httpx>=0.24.1 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from nemoguardrails) (0.27.0)\n",
      "Requirement already satisfied: jinja2>=3.1.4 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from nemoguardrails) (3.1.4)\n",
      "Requirement already satisfied: langchain!=0.1.9,<0.3.0,>=0.2.14 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from nemoguardrails) (0.2.16)\n",
      "Requirement already satisfied: langchain-core!=0.1.26,<0.3.0,>=0.2.14 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from nemoguardrails) (0.2.41)\n",
      "Requirement already satisfied: langchain-community<0.3.0,>=0.0.16 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from nemoguardrails) (0.2.10)\n",
      "Requirement already satisfied: lark~=1.1.7 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from nemoguardrails) (1.1.9)\n",
      "Requirement already satisfied: nest-asyncio>=1.5.6 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from nemoguardrails) (1.6.0)\n",
      "Requirement already satisfied: prompt-toolkit>=3.0 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from nemoguardrails) (3.0.47)\n",
      "Requirement already satisfied: pydantic>=1.10 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from nemoguardrails) (2.8.2)\n",
      "Requirement already satisfied: pyyaml>=6.0 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from nemoguardrails) (6.0.1)\n",
      "Requirement already satisfied: rich>=13.5.2 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from nemoguardrails) (13.9.2)\n",
      "Requirement already satisfied: simpleeval>=0.9.13 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from nemoguardrails) (1.0.0)\n",
      "Requirement already satisfied: starlette>=0.27.0 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from nemoguardrails) (0.38.6)\n",
      "Requirement already satisfied: typer>=0.7.0 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from nemoguardrails) (0.12.5)\n",
      "Requirement already satisfied: uvicorn>=0.23 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from nemoguardrails) (0.31.0)\n",
      "Requirement already satisfied: watchdog>=3.0.0 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from nemoguardrails) (5.0.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from aiohttp>=3.9.2->nemoguardrails) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from aiohttp>=3.9.2->nemoguardrails) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from aiohttp>=3.9.2->nemoguardrails) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from aiohttp>=3.9.2->nemoguardrails) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from aiohttp>=3.9.2->nemoguardrails) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from aiohttp>=3.9.2->nemoguardrails) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from fastapi>=0.103.0->nemoguardrails) (4.12.2)\n",
      "Requirement already satisfied: PyStemmer<3.0.0,>=2.2.0 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from fastembed>=0.2.2->nemoguardrails) (2.2.0.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.20 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from fastembed>=0.2.2->nemoguardrails) (0.25.1)\n",
      "Requirement already satisfied: loguru<0.8.0,>=0.7.2 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from fastembed>=0.2.2->nemoguardrails) (0.7.2)\n",
      "Requirement already satisfied: mmh3<5.0,>=4.0 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from fastembed>=0.2.2->nemoguardrails) (4.1.0)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from fastembed>=0.2.2->nemoguardrails) (1.26.4)\n",
      "Requirement already satisfied: onnx<2.0.0,>=1.15.0 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from fastembed>=0.2.2->nemoguardrails) (1.17.0)\n",
      "Requirement already satisfied: onnxruntime<2.0.0,>=1.17.0 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from fastembed>=0.2.2->nemoguardrails) (1.19.2)\n",
      "Requirement already satisfied: pillow<11.0.0,>=10.3.0 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from fastembed>=0.2.2->nemoguardrails) (10.4.0)\n",
      "Requirement already satisfied: requests<3.0,>=2.31 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from fastembed>=0.2.2->nemoguardrails) (2.32.3)\n",
      "Requirement already satisfied: snowballstemmer<3.0.0,>=2.2.0 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from fastembed>=0.2.2->nemoguardrails) (2.2.0)\n",
      "Requirement already satisfied: tokenizers<1.0,>=0.15 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from fastembed>=0.2.2->nemoguardrails) (0.20.0)\n",
      "Requirement already satisfied: tqdm<5.0,>=4.66 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from fastembed>=0.2.2->nemoguardrails) (4.66.5)\n",
      "Requirement already satisfied: anyio in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from httpx>=0.24.1->nemoguardrails) (4.4.0)\n",
      "Requirement already satisfied: certifi in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from httpx>=0.24.1->nemoguardrails) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from httpx>=0.24.1->nemoguardrails) (1.0.5)\n",
      "Requirement already satisfied: idna in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from httpx>=0.24.1->nemoguardrails) (3.7)\n",
      "Requirement already satisfied: sniffio in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from httpx>=0.24.1->nemoguardrails) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from httpcore==1.*->httpx>=0.24.1->nemoguardrails) (0.14.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from jinja2>=3.1.4->nemoguardrails) (2.1.5)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from langchain!=0.1.9,<0.3.0,>=0.2.14->nemoguardrails) (2.0.31)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from langchain!=0.1.9,<0.3.0,>=0.2.14->nemoguardrails) (0.2.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from langchain!=0.1.9,<0.3.0,>=0.2.14->nemoguardrails) (0.1.131)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from langchain!=0.1.9,<0.3.0,>=0.2.14->nemoguardrails) (8.5.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from langchain-community<0.3.0,>=0.0.16->nemoguardrails) (0.6.7)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from langchain-core!=0.1.26,<0.3.0,>=0.2.14->nemoguardrails) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from langchain-core!=0.1.26,<0.3.0,>=0.2.14->nemoguardrails) (24.1)\n",
      "Requirement already satisfied: wcwidth in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from prompt-toolkit>=3.0->nemoguardrails) (0.2.13)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from pydantic>=1.10->nemoguardrails) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from pydantic>=1.10->nemoguardrails) (2.20.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from rich>=13.5.2->nemoguardrails) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from rich>=13.5.2->nemoguardrails) (2.18.0)\n",
      "Requirement already satisfied: click>=8.0.0 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from typer>=0.7.0->nemoguardrails) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from typer>=0.7.0->nemoguardrails) (1.5.4)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from anyio->httpx>=0.24.1->nemoguardrails) (1.2.2)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.3.0,>=0.0.16->nemoguardrails) (3.21.3)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.3.0,>=0.0.16->nemoguardrails) (0.9.0)\n",
      "Requirement already satisfied: filelock in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.20->fastembed>=0.2.2->nemoguardrails) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.20->fastembed>=0.2.2->nemoguardrails) (2024.6.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from jsonpatch<2.0,>=1.33->langchain-core!=0.1.26,<0.3.0,>=0.2.14->nemoguardrails) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from langsmith<0.2.0,>=0.1.17->langchain!=0.1.9,<0.3.0,>=0.2.14->nemoguardrails) (3.10.6)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from langsmith<0.2.0,>=0.1.17->langchain!=0.1.9,<0.3.0,>=0.2.14->nemoguardrails) (1.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich>=13.5.2->nemoguardrails) (0.1.2)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from onnx<2.0.0,>=1.15.0->fastembed>=0.2.2->nemoguardrails) (5.28.2)\n",
      "Requirement already satisfied: coloredlogs in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from onnxruntime<2.0.0,>=1.17.0->fastembed>=0.2.2->nemoguardrails) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from onnxruntime<2.0.0,>=1.17.0->fastembed>=0.2.2->nemoguardrails) (24.3.25)\n",
      "Requirement already satisfied: sympy in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from onnxruntime<2.0.0,>=1.17.0->fastembed>=0.2.2->nemoguardrails) (1.13.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from requests<3.0,>=2.31->fastembed>=0.2.2->nemoguardrails) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from requests<3.0,>=2.31->fastembed>=0.2.2->nemoguardrails) (2.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from SQLAlchemy<3,>=1.4->langchain!=0.1.9,<0.3.0,>=0.2.14->nemoguardrails) (3.0.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community<0.3.0,>=0.0.16->nemoguardrails) (1.0.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from coloredlogs->onnxruntime<2.0.0,>=1.17.0->fastembed>=0.2.2->nemoguardrails) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from sympy->onnxruntime<2.0.0,>=1.17.0->fastembed>=0.2.2->nemoguardrails) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install nemoguardrails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "32160bf5-8d3f-4b87-a1f1-0a0164bd9de9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for RailsConfig\nmodels\n  Field required [type=missing, input_value={'instructions': [{'type'.../workspace/config.yaml'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.8/v/missing",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnemoguardrails\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LLMRails, RailsConfig\n\u001b[0;32m----> 3\u001b[0m config \u001b[38;5;241m=\u001b[39m \u001b[43mRailsConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_path\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/mnt/lustre/hackathons/hack_teams/hack_team_16/workspace/config.yaml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m rails \u001b[38;5;241m=\u001b[39m LLMRails(config)\n",
      "File \u001b[0;32m~/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/config.py:984\u001b[0m, in \u001b[0;36mRailsConfig.from_path\u001b[0;34m(cls, config_path)\u001b[0m\n\u001b[1;32m    980\u001b[0m     raw_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstructions\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m _default_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstructions\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    982\u001b[0m raw_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig_path\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config_path\n\u001b[0;32m--> 984\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/config.py:1055\u001b[0m, in \u001b[0;36mRailsConfig.parse_object\u001b[0;34m(cls, obj)\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m flow_data\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124melements\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m flow_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124melements\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m   1051\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_type\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1052\u001b[0m         ):\n\u001b[1;32m   1053\u001b[0m             flow_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124melements\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m parse_flow_elements(flow_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124melements\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m-> 1055\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_obj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/nim_env/lib/python3.9/site-packages/pydantic/main.py:1135\u001b[0m, in \u001b[0;36mBaseModel.parse_obj\u001b[0;34m(cls, obj)\u001b[0m\n\u001b[1;32m   1129\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m   1130\u001b[0m \u001b[38;5;129m@typing_extensions\u001b[39m\u001b[38;5;241m.\u001b[39mdeprecated(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe `parse_obj` method is deprecated; use `model_validate` instead.\u001b[39m\u001b[38;5;124m'\u001b[39m, category\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse_obj\u001b[39m(\u001b[38;5;28mcls\u001b[39m, obj: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:  \u001b[38;5;66;03m# noqa: D102\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1133\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe `parse_obj` method is deprecated; use `model_validate` instead.\u001b[39m\u001b[38;5;124m'\u001b[39m, category\u001b[38;5;241m=\u001b[39mPydanticDeprecatedSince20\n\u001b[1;32m   1134\u001b[0m     )\n\u001b[0;32m-> 1135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/nim_env/lib/python3.9/site-packages/pydantic/main.py:568\u001b[0m, in \u001b[0;36mBaseModel.model_validate\u001b[0;34m(cls, obj, strict, from_attributes, context)\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[1;32m    567\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 568\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_attributes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrom_attributes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\n\u001b[1;32m    570\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for RailsConfig\nmodels\n  Field required [type=missing, input_value={'instructions': [{'type'.../workspace/config.yaml'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.8/v/missing"
     ]
    }
   ],
   "source": [
    "from nemoguardrails import LLMRails, RailsConfig\n",
    "\n",
    "config = RailsConfig.from_path(\"/mnt/lustre/hackathons/hack_teams/hack_team_16/workspace/config.yaml\")\n",
    "rails = LLMRails(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5a2e7719-21af-4342-bb5f-708a8e6b864f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"Id\": \"a5732a8ccde9ca1fbf867980c23f1dd95424b2072b1f6f77c6f408aa39f48ad5\",\n",
      "        \"Created\": \"2024-10-04T07:31:05.165531824Z\",\n",
      "        \"Path\": \"/opt/nvidia/nvidia_entrypoint.sh\",\n",
      "        \"Args\": [\n",
      "            \"/opt/nim/start-server.sh\"\n",
      "        ],\n",
      "        \"State\": {\n",
      "            \"Status\": \"running\",\n",
      "            \"Running\": true,\n",
      "            \"Paused\": false,\n",
      "            \"Restarting\": false,\n",
      "            \"OOMKilled\": false,\n",
      "            \"Dead\": false,\n",
      "            \"Pid\": 586536,\n",
      "            \"ExitCode\": 0,\n",
      "            \"Error\": \"\",\n",
      "            \"StartedAt\": \"2024-10-04T07:31:05.613158479Z\",\n",
      "            \"FinishedAt\": \"0001-01-01T00:00:00Z\"\n",
      "        },\n",
      "        \"Image\": \"sha256:c9102c3e95f3acae5b41fdafd7aefd3389bdaf33cf0b3458041e45046bf6bb1d\",\n",
      "        \"ResolvConfPath\": \"/raid/tmp/docker-container-storage-2072/containers/a5732a8ccde9ca1fbf867980c23f1dd95424b2072b1f6f77c6f408aa39f48ad5/resolv.conf\",\n",
      "        \"HostnamePath\": \"/raid/tmp/docker-container-storage-2072/containers/a5732a8ccde9ca1fbf867980c23f1dd95424b2072b1f6f77c6f408aa39f48ad5/hostname\",\n",
      "        \"HostsPath\": \"/raid/tmp/docker-container-storage-2072/containers/a5732a8ccde9ca1fbf867980c23f1dd95424b2072b1f6f77c6f408aa39f48ad5/hosts\",\n",
      "        \"LogPath\": \"/raid/tmp/docker-container-storage-2072/containers/a5732a8ccde9ca1fbf867980c23f1dd95424b2072b1f6f77c6f408aa39f48ad5/a5732a8ccde9ca1fbf867980c23f1dd95424b2072b1f6f77c6f408aa39f48ad5-json.log\",\n",
      "        \"Name\": \"/LLM_nim\",\n",
      "        \"RestartCount\": 0,\n",
      "        \"Driver\": \"overlay2\",\n",
      "        \"Platform\": \"linux\",\n",
      "        \"MountLabel\": \"\",\n",
      "        \"ProcessLabel\": \"\",\n",
      "        \"AppArmorProfile\": \"\",\n",
      "        \"ExecIDs\": [\n",
      "            \"8d31b67e5ae24a6dc5cadec7ab66187db91c119904499fdb491f49231b53a136\"\n",
      "        ],\n",
      "        \"HostConfig\": {\n",
      "            \"Binds\": [\n",
      "                \"/home/gsh-3atzc7/.cache/nim:/opt/nim/.cache\"\n",
      "            ],\n",
      "            \"ContainerIDFile\": \"\",\n",
      "            \"LogConfig\": {\n",
      "                \"Type\": \"json-file\",\n",
      "                \"Config\": {}\n",
      "            },\n",
      "            \"NetworkMode\": \"default\",\n",
      "            \"PortBindings\": {\n",
      "                \"8000/tcp\": [\n",
      "                    {\n",
      "                        \"HostIp\": \"\",\n",
      "                        \"HostPort\": \"8000\"\n",
      "                    }\n",
      "                ]\n",
      "            },\n",
      "            \"RestartPolicy\": {\n",
      "                \"Name\": \"no\",\n",
      "                \"MaximumRetryCount\": 0\n",
      "            },\n",
      "            \"AutoRemove\": true,\n",
      "            \"VolumeDriver\": \"\",\n",
      "            \"VolumesFrom\": null,\n",
      "            \"ConsoleSize\": [\n",
      "                24,\n",
      "                80\n",
      "            ],\n",
      "            \"CapAdd\": null,\n",
      "            \"CapDrop\": null,\n",
      "            \"CgroupnsMode\": \"host\",\n",
      "            \"Dns\": [],\n",
      "            \"DnsOptions\": [],\n",
      "            \"DnsSearch\": [],\n",
      "            \"ExtraHosts\": null,\n",
      "            \"GroupAdd\": null,\n",
      "            \"IpcMode\": \"private\",\n",
      "            \"Cgroup\": \"\",\n",
      "            \"Links\": null,\n",
      "            \"OomScoreAdj\": 0,\n",
      "            \"PidMode\": \"\",\n",
      "            \"Privileged\": false,\n",
      "            \"PublishAllPorts\": false,\n",
      "            \"ReadonlyRootfs\": false,\n",
      "            \"SecurityOpt\": null,\n",
      "            \"UTSMode\": \"\",\n",
      "            \"UsernsMode\": \"\",\n",
      "            \"ShmSize\": 17179869184,\n",
      "            \"Runtime\": \"runc\",\n",
      "            \"Isolation\": \"\",\n",
      "            \"CpuShares\": 0,\n",
      "            \"Memory\": 0,\n",
      "            \"NanoCpus\": 0,\n",
      "            \"CgroupParent\": \"\",\n",
      "            \"BlkioWeight\": 0,\n",
      "            \"BlkioWeightDevice\": [],\n",
      "            \"BlkioDeviceReadBps\": [],\n",
      "            \"BlkioDeviceWriteBps\": [],\n",
      "            \"BlkioDeviceReadIOps\": [],\n",
      "            \"BlkioDeviceWriteIOps\": [],\n",
      "            \"CpuPeriod\": 0,\n",
      "            \"CpuQuota\": 0,\n",
      "            \"CpuRealtimePeriod\": 0,\n",
      "            \"CpuRealtimeRuntime\": 0,\n",
      "            \"CpusetCpus\": \"\",\n",
      "            \"CpusetMems\": \"\",\n",
      "            \"Devices\": [],\n",
      "            \"DeviceCgroupRules\": null,\n",
      "            \"DeviceRequests\": [\n",
      "                {\n",
      "                    \"Driver\": \"\",\n",
      "                    \"Count\": 1,\n",
      "                    \"DeviceIDs\": null,\n",
      "                    \"Capabilities\": [\n",
      "                        [\n",
      "                            \"gpu\"\n",
      "                        ]\n",
      "                    ],\n",
      "                    \"Options\": {}\n",
      "                }\n",
      "            ],\n",
      "            \"MemoryReservation\": 0,\n",
      "            \"MemorySwap\": 0,\n",
      "            \"MemorySwappiness\": null,\n",
      "            \"OomKillDisable\": false,\n",
      "            \"PidsLimit\": null,\n",
      "            \"Ulimits\": null,\n",
      "            \"CpuCount\": 0,\n",
      "            \"CpuPercent\": 0,\n",
      "            \"IOMaximumIOps\": 0,\n",
      "            \"IOMaximumBandwidth\": 0,\n",
      "            \"MaskedPaths\": [\n",
      "                \"/proc/asound\",\n",
      "                \"/proc/acpi\",\n",
      "                \"/proc/kcore\",\n",
      "                \"/proc/keys\",\n",
      "                \"/proc/latency_stats\",\n",
      "                \"/proc/timer_list\",\n",
      "                \"/proc/timer_stats\",\n",
      "                \"/proc/sched_debug\",\n",
      "                \"/proc/scsi\",\n",
      "                \"/sys/firmware\",\n",
      "                \"/sys/devices/virtual/powercap\"\n",
      "            ],\n",
      "            \"ReadonlyPaths\": [\n",
      "                \"/proc/bus\",\n",
      "                \"/proc/fs\",\n",
      "                \"/proc/irq\",\n",
      "                \"/proc/sys\",\n",
      "                \"/proc/sysrq-trigger\"\n",
      "            ]\n",
      "        },\n",
      "        \"GraphDriver\": {\n",
      "            \"Data\": {\n",
      "                \"LowerDir\": \"/raid/tmp/docker-container-storage-2072/overlay2/7fa8bad39ef73b8974ba6ee32e6d5376d67f47208c9a0b527c07d01ff13856a8-init/diff:/raid/tmp/docker-container-storage-2072/overlay2/f669aa87c3eb41bad93ae3a130baf6580cc2cc1426b336ea012f9e93d1ae4c3e/diff:/raid/tmp/docker-container-storage-2072/overlay2/75f517e56e76f2f1ca9833270832f308fb5e31fccfa50507330f51dd52c88c14/diff:/raid/tmp/docker-container-storage-2072/overlay2/2ef63166cb032edca8aee744980f0a18c8026a4dde5f8064141cc8bc481396ba/diff:/raid/tmp/docker-container-storage-2072/overlay2/0d9e54f481a4581b520f018dc75ee8cccc70f2c7fdb9fb3c189e4355e7d6c086/diff:/raid/tmp/docker-container-storage-2072/overlay2/76b9c6cf4cba22f91cc31dfd428b93d8f3aa14945505d28151fb2f4704d37cb4/diff:/raid/tmp/docker-container-storage-2072/overlay2/d3b5f54e19dfb527acf90f73edc2aa57661389403eb2183e98dbb8417e032d04/diff:/raid/tmp/docker-container-storage-2072/overlay2/9768f8973c8f85e8b9d72b902475cbeac433be43e7a728940c7bade3d17f4ca9/diff:/raid/tmp/docker-container-storage-2072/overlay2/f6698fb1397edec9df385d0c730537fc88f5a070eb230bfe0b948132b7b3409b/diff:/raid/tmp/docker-container-storage-2072/overlay2/5ab59d65d6a2f332e442461567ff9ecffead036b39482485ce171149706e05b4/diff:/raid/tmp/docker-container-storage-2072/overlay2/15f20fbbd141b4cbe15fc2a9f52d16c8f9c7954eb909b10514786ed053e7cbb7/diff:/raid/tmp/docker-container-storage-2072/overlay2/bd3cba5ec202614a981c86b431da1d193cf65640e7c7da64d1d0a0a2781b40c8/diff:/raid/tmp/docker-container-storage-2072/overlay2/d1d1811631c982c9b75e27d26f8c28e2952bacd7be8a80b14e43512904bda202/diff:/raid/tmp/docker-container-storage-2072/overlay2/40821489442b0324f07d70f1e31612dba525be219ac00bd8e547cb09e6a7aa39/diff:/raid/tmp/docker-container-storage-2072/overlay2/02d228e1837a7993a0cc8ff94cdfd154b3cd34ddf2908b27164c70e7aa801cc4/diff:/raid/tmp/docker-container-storage-2072/overlay2/e73f06b6765142a91b81bc1f9233515e8e01e41787a1df659f2f81056322d2b4/diff:/raid/tmp/docker-container-storage-2072/overlay2/02a790d8fd421ac02885493045ad3fff255ef57b02d981dd99df48b25d19c1be/diff:/raid/tmp/docker-container-storage-2072/overlay2/8f3ace0fd768efb8de1c5f51ab846f41f5acb65e2ec293b9186cd051fd4e9c51/diff:/raid/tmp/docker-container-storage-2072/overlay2/4954a46a43fec797c5540e65f615a1e83a0ebbc2beaa9abb122f39f6428765fc/diff:/raid/tmp/docker-container-storage-2072/overlay2/093337cddc8e5a2d89b43396d4def56af21c721e5f870003029d6992641ef76d/diff:/raid/tmp/docker-container-storage-2072/overlay2/405f86510649d2e6d116a9e6fbf95b7dcd9e894b876a0f5e5df171aa1a4e8943/diff:/raid/tmp/docker-container-storage-2072/overlay2/84be52f435919bbf7461747d5c29064bfebd72cc0c9b945fc73f9803e2370bad/diff:/raid/tmp/docker-container-storage-2072/overlay2/37fb2e17b9ed544202365202189345f973dced30befa7834169eabbb63e737da/diff:/raid/tmp/docker-container-storage-2072/overlay2/f5341b5b3286784841fdb2a3e3055476b415c8f5a41d0fa8443858d93b5f877d/diff:/raid/tmp/docker-container-storage-2072/overlay2/1843dc55d484840fbd3974e8a78d07f5b0429554f3d3af77195c122be014b546/diff:/raid/tmp/docker-container-storage-2072/overlay2/20700c9629e228e957bdc7f7b0940a11d17f2b6bd577793531e4be95a10769ee/diff:/raid/tmp/docker-container-storage-2072/overlay2/bf15adb049c673db4671097d8ec574cde2bde62150f0da8533b221593eea7bfa/diff:/raid/tmp/docker-container-storage-2072/overlay2/9e18d5dc67e8447f00ee348e4a55414ed570de1fc89591e80b68504f42c666e7/diff:/raid/tmp/docker-container-storage-2072/overlay2/dc8fe7a93d4be5b014dd98e822a85ca01a8e48b13fa7295f2fb17b9ad4521a86/diff:/raid/tmp/docker-container-storage-2072/overlay2/d5a96a64b7cdb485e5df27b41a61a0e49fa6e93b43d3aec8630f01ccb140e58c/diff\",\n",
      "                \"MergedDir\": \"/raid/tmp/docker-container-storage-2072/overlay2/7fa8bad39ef73b8974ba6ee32e6d5376d67f47208c9a0b527c07d01ff13856a8/merged\",\n",
      "                \"UpperDir\": \"/raid/tmp/docker-container-storage-2072/overlay2/7fa8bad39ef73b8974ba6ee32e6d5376d67f47208c9a0b527c07d01ff13856a8/diff\",\n",
      "                \"WorkDir\": \"/raid/tmp/docker-container-storage-2072/overlay2/7fa8bad39ef73b8974ba6ee32e6d5376d67f47208c9a0b527c07d01ff13856a8/work\"\n",
      "            },\n",
      "            \"Name\": \"overlay2\"\n",
      "        },\n",
      "        \"Mounts\": [\n",
      "            {\n",
      "                \"Type\": \"bind\",\n",
      "                \"Source\": \"/home/gsh-3atzc7/.cache/nim\",\n",
      "                \"Destination\": \"/opt/nim/.cache\",\n",
      "                \"Mode\": \"\",\n",
      "                \"RW\": true,\n",
      "                \"Propagation\": \"rprivate\"\n",
      "            }\n",
      "        ],\n",
      "        \"Config\": {\n",
      "            \"Hostname\": \"a5732a8ccde9\",\n",
      "            \"Domainname\": \"\",\n",
      "            \"User\": \"2072\",\n",
      "            \"AttachStdin\": false,\n",
      "            \"AttachStdout\": false,\n",
      "            \"AttachStderr\": false,\n",
      "            \"ExposedPorts\": {\n",
      "                \"8000/tcp\": {}\n",
      "            },\n",
      "            \"Tty\": true,\n",
      "            \"OpenStdin\": true,\n",
      "            \"StdinOnce\": false,\n",
      "            \"Env\": [\n",
      "                \"NGC_API_KEY=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\",\n",
      "                \"PATH=/opt/nim/llm/.venv/bin:/opt/hpcx/ucc/bin:/opt/hpcx/ucx/bin:/opt/hpcx/ompi/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin\",\n",
      "                \"NVARCH=x86_64\",\n",
      "                \"NVIDIA_REQUIRE_CUDA=cuda>=12.3 brand=tesla,driver>=470,driver<471 brand=unknown,driver>=470,driver<471 brand=nvidia,driver>=470,driver<471 brand=nvidiartx,driver>=470,driver<471 brand=geforce,driver>=470,driver<471 brand=geforcertx,driver>=470,driver<471 brand=quadro,driver>=470,driver<471 brand=quadrortx,driver>=470,driver<471 brand=titan,driver>=470,driver<471 brand=titanrtx,driver>=470,driver<471 brand=tesla,driver>=525,driver<526 brand=unknown,driver>=525,driver<526 brand=nvidia,driver>=525,driver<526 brand=nvidiartx,driver>=525,driver<526 brand=geforce,driver>=525,driver<526 brand=geforcertx,driver>=525,driver<526 brand=quadro,driver>=525,driver<526 brand=quadrortx,driver>=525,driver<526 brand=titan,driver>=525,driver<526 brand=titanrtx,driver>=525,driver<526 brand=tesla,driver>=535,driver<536 brand=unknown,driver>=535,driver<536 brand=nvidia,driver>=535,driver<536 brand=nvidiartx,driver>=535,driver<536 brand=geforce,driver>=535,driver<536 brand=geforcertx,driver>=535,driver<536 brand=quadro,driver>=535,driver<536 brand=quadrortx,driver>=535,driver<536 brand=titan,driver>=535,driver<536 brand=titanrtx,driver>=535,driver<536\",\n",
      "                \"NV_CUDA_CUDART_VERSION=12.3.101-1\",\n",
      "                \"NV_CUDA_COMPAT_PACKAGE=cuda-compat-12-3\",\n",
      "                \"CUDA_VERSION=12.3.1\",\n",
      "                \"LD_LIBRARY_PATH=/opt/hpcx/ucc/lib/ucc:/opt/hpcx/ucc/lib:/opt/hpcx/ucx/lib/ucx:/opt/hpcx/ucx/lib:/opt/hpcx/ompi/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/opt/nim/llm/.venv/lib/python3.10/site-packages/tensorrt_llm/libs:/opt/nim/llm/.venv/lib/python3.10/site-packages/nvidia/cublas/lib:/opt/nim/llm/.venv/lib/python3.10/site-packages/tensorrt_libs:/opt/nim/llm/.venv/lib/python3.10/site-packages/nvidia/nccl/lib\",\n",
      "                \"NVIDIA_VISIBLE_DEVICES=all\",\n",
      "                \"NVIDIA_DRIVER_CAPABILITIES=compute,utility\",\n",
      "                \"PYTHONDONTWRITEBYTECODE=1\",\n",
      "                \"PYTHONUNBUFFERED=1\",\n",
      "                \"PIP_DISABLE_PIP_VERSION_CHECK=1\",\n",
      "                \"PIP_CACHE_DIR=/root/.cache/pip\",\n",
      "                \"POETRY_NO_INTERACTION=1\",\n",
      "                \"POETRY_NO_ANSI=1\",\n",
      "                \"POETRY_VERSION=1.8.2\",\n",
      "                \"POETRY_HOME=/opt/poetry\",\n",
      "                \"POETRY_CACHE_DIR=/root/.cache/pypoetry\",\n",
      "                \"POETRY_VIRTUALENVS_IN_PROJECT=1\",\n",
      "                \"LLM_PROJECT_DIR=/opt/nim/llm\",\n",
      "                \"OPAL_PREFIX=/opt/hpcx/ompi\",\n",
      "                \"OMPI_MCA_coll_hcoll_enable=0\",\n",
      "                \"HPCX_DIR=/opt/hpcx\",\n",
      "                \"HPCX_UCX_DIR=/opt/hpcx/ucx\",\n",
      "                \"HPCX_UCC_DIR=/opt/hpcx/ucc\",\n",
      "                \"HPCX_MPI_DIR=/opt/hpcx/ompi\",\n",
      "                \"OMPI_HOME=/opt/hpcx/ompi\",\n",
      "                \"MPIf_HOME=/opt/hpcx/ompi\",\n",
      "                \"LIBRARY_PATH=/opt/hpcx/ucc/lib:/opt/hpcx/ucx/lib:/opt/hpcx/ompi/lib:\",\n",
      "                \"CPATH=/opt/hpcx/ompi/include:/opt/hpcx/ucc/include:/opt/hpcx/ucx/include:\",\n",
      "                \"PKG_CONFIG_PATH=/lib/pkgconfig:/lib/pkgconfig:/opt/hpcx/ucx/lib/pkgconfig:/opt/hpcx/ompi/lib/pkgconfig:\",\n",
      "                \"USE_NCCL=1\",\n",
      "                \"USE_SYSTEM_NCCL=1\",\n",
      "                \"NCCL_ROOT_DIR=/usr/local/cuda/\",\n",
      "                \"USE_UCC=1\",\n",
      "                \"USE_SYSTEM_UCC=1\",\n",
      "                \"UCC_HOME=/opt/hpcx/ucc\",\n",
      "                \"UCC_DIR=/opt/hpcx/ucc/lib/cmake/ucc\",\n",
      "                \"UCX_HOME=/opt/hpcx/ucx\",\n",
      "                \"UCX_DIR=/opt/hpcx/ucx/lib/cmake/ucx\",\n",
      "                \"USE_DISTRIBUTED=1\",\n",
      "                \"NVIDIA_PRODUCT_NAME=NVIDIA Inference Microservice LLM NIM\",\n",
      "                \"FORCE_NCCL_ALL_REDUCE_STRATEGY=1\",\n",
      "                \"INFERENCE_MICROSERVICE_LLM_NIM_VERSION=1.1.2\",\n",
      "                \"NIM_CACHE_PATH=/opt/nim/.cache\",\n",
      "                \"OUTLINES_CACHE_DIR=/tmp/outlines\",\n",
      "                \"NIM_MODEL_NAME=nim/meta/llama-3.1-8b-instruct\",\n",
      "                \"NIM_NSPECT_ID=NSPECT-ZP6P-5LPY\",\n",
      "                \"NIM_MODEL_NSPECT_ID=NSPECT-0DQP-LNLV\"\n",
      "            ],\n",
      "            \"Cmd\": [\n",
      "                \"/opt/nim/start-server.sh\"\n",
      "            ],\n",
      "            \"Image\": \"nvcr.io/nim/meta/llama-3.1-8b-instruct:1.1.2\",\n",
      "            \"Volumes\": null,\n",
      "            \"WorkingDir\": \"\",\n",
      "            \"Entrypoint\": [\n",
      "                \"/opt/nvidia/nvidia_entrypoint.sh\"\n",
      "            ],\n",
      "            \"OnBuild\": null,\n",
      "            \"Labels\": {\n",
      "                \"com.nvidia.nim.model\": \"meta/llama-3.1-8b-instruct\",\n",
      "                \"com.nvidia.nim.model-nspect\": \"NSPECT-0DQP-LNLV\",\n",
      "                \"com.nvidia.nim.nspect\": \"NSPECT-ZP6P-5LPY\",\n",
      "                \"com.nvidia.nim.type\": \"llm\",\n",
      "                \"com.nvidia.nim.version\": \"1.1.2\",\n",
      "                \"maintainer\": \"NVIDIA CORPORATION <cudatools@nvidia.com>\",\n",
      "                \"org.opencontainers.image.ref.name\": \"ubuntu\",\n",
      "                \"org.opencontainers.image.version\": \"22.04\"\n",
      "            }\n",
      "        },\n",
      "        \"NetworkSettings\": {\n",
      "            \"Bridge\": \"\",\n",
      "            \"SandboxID\": \"a92c5188c03c5f709acf1eee5a836c125b0deb0a90b938e85f0a49cd5547fc5e\",\n",
      "            \"HairpinMode\": false,\n",
      "            \"LinkLocalIPv6Address\": \"\",\n",
      "            \"LinkLocalIPv6PrefixLen\": 0,\n",
      "            \"Ports\": {\n",
      "                \"8000/tcp\": [\n",
      "                    {\n",
      "                        \"HostIp\": \"0.0.0.0\",\n",
      "                        \"HostPort\": \"8000\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"HostIp\": \"::\",\n",
      "                        \"HostPort\": \"8000\"\n",
      "                    }\n",
      "                ]\n",
      "            },\n",
      "            \"SandboxKey\": \"/raid/tmp/xdg_runtime_dir_2072/docker/netns/a92c5188c03c\",\n",
      "            \"SecondaryIPAddresses\": null,\n",
      "            \"SecondaryIPv6Addresses\": null,\n",
      "            \"EndpointID\": \"b5d7ecfcd361e86e1379f6364e4db41f18cde01541dac9c4b5a4b6a0d9914ad2\",\n",
      "            \"Gateway\": \"172.17.0.1\",\n",
      "            \"GlobalIPv6Address\": \"\",\n",
      "            \"GlobalIPv6PrefixLen\": 0,\n",
      "            \"IPAddress\": \"172.17.0.2\",\n",
      "            \"IPPrefixLen\": 16,\n",
      "            \"IPv6Gateway\": \"\",\n",
      "            \"MacAddress\": \"02:42:ac:11:00:02\",\n",
      "            \"Networks\": {\n",
      "                \"bridge\": {\n",
      "                    \"IPAMConfig\": null,\n",
      "                    \"Links\": null,\n",
      "                    \"Aliases\": null,\n",
      "                    \"NetworkID\": \"36523888f73dbca5f0be5cd2aad2c19bfe6039a95d9ceee1f7db74bb1e993d76\",\n",
      "                    \"EndpointID\": \"b5d7ecfcd361e86e1379f6364e4db41f18cde01541dac9c4b5a4b6a0d9914ad2\",\n",
      "                    \"Gateway\": \"172.17.0.1\",\n",
      "                    \"IPAddress\": \"172.17.0.2\",\n",
      "                    \"IPPrefixLen\": 16,\n",
      "                    \"IPv6Gateway\": \"\",\n",
      "                    \"GlobalIPv6Address\": \"\",\n",
      "                    \"GlobalIPv6PrefixLen\": 0,\n",
      "                    \"MacAddress\": \"02:42:ac:11:00:02\",\n",
      "                    \"DriverOpts\": null\n",
      "                }\n",
      "            }\n",
      "        }\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "!docker inspect LLM_nim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "3af5a0b1-af05-4076-b139-e56139bd5ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID   IMAGE                                                COMMAND                  CREATED      STATUS      PORTS                                         NAMES\n",
      "4ad7b8ee2bb5   nvcr.io/nim/nvidia/nv-embedqa-e5-v5:1.0.1            \"/opt/nvidia/nvidia_…\"   5 days ago   Up 5 days   0.0.0.0:11022->8000/tcp, :::11022->8000/tcp   embed_nim\n",
      "6ef6ad73da55   nvcr.io/nim/nvidia/nv-rerankqa-mistral-4b-v3:1.0.2   \"/opt/nvidia/nvidia_…\"   5 days ago   Up 5 days   0.0.0.0:11737->8000/tcp, :::11737->8000/tcp   rerank_nim\n",
      "a5732a8ccde9   nvcr.io/nim/meta/llama-3.1-8b-instruct:1.1.2         \"/opt/nvidia/nvidia_…\"   5 days ago   Up 5 days   0.0.0.0:8000->8000/tcp, :::8000->8000/tcp     LLM_nim\n"
     ]
    }
   ],
   "source": [
    "!docker ps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "766dbfce-e04b-4760-9643-5bdabac1fb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever=docsearch.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "57682fde-5fb5-452e-9b8b-7aa7fbf78bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain_nvidia_ai_endpoints import NVIDIARerank\n",
    "\n",
    "# Re-initialize and connect to a NeMo Retriever Text Reranking NIM running at localhost:8000\n",
    "compressor = NVIDIARerank(model=\"nvidia/nv-rerankqa-mistral-4b-v3\",\n",
    "                          base_url=\"http://localhost:11737/v1\")\n",
    "\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7a4c6a4e-b4de-478f-9f1a-52a243efdb53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'what is conda?',\n",
       " 'result': 'I don\\'t see any information about \"conda\" in the provided context. The text appears to be about the NVIDIA GPU compiler and linker (`nvcc` and `nvlink`), but it doesn\\'t mention conda.\\n\\nHowever, in general, conda is a package manager and environment management system for Python and other programming languages. It allows users to create and manage multiple environments for different projects, and to easily install and manage packages and dependencies.'}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "query = \"what is conda?\"\n",
    "\n",
    "chain = RetrievalQA.from_chain_type(llm=llm, retriever=compression_retriever)\n",
    "chain.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c46e3711-2199-4655-ab67-4440e497b9ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'how to do i create folder',\n",
       " 'result': 'You want to create a folder.\\n\\nTo create a new folder on an Amazon EBS volume, you can use the following steps:\\n\\n1. Format the EBS volume using a command such as `mkfs.ext3`.\\n2. Mount the EBS volume to a directory using the `mount` command, for example: `mount <Device> <Directory>`.\\n3. Once the volume is mounted, you can create a new folder inside the mounted directory using the `mkdir` command.\\n\\nFor example:\\n```\\nmkdir /path/to/new/folder\\n```\\nThis will create a new folder named \"new/folder\" inside the directory \"/path/to\".\\n\\nNote: Make sure to replace `<Device>` and `<Directory>` with the actual device and directory paths of your EBS volume.\\n\\nIf you\\'re working on an AWS instance, you can also use the AWS Management Console or the AWS CLI to create a new folder on an EBS volume.'}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "query = \"how to do i create folder\"\n",
    "chain = RetrievalQA.from_chain_type(llm=llm, retriever=compression_retriever)\n",
    "chain.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "1a2a79d4-7a7d-44a0-a1db-e6630acd0d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "7075e8cb-5196-456f-95a9-75cf6c3c3a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nemoguardrails import LLMRails, RailsConfig\n",
    "\n",
    "config = RailsConfig.from_path(\"./config\")\n",
    "rails = LLMRails(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "ec9a3f66-53d9-42bb-9f9b-7ebb87d22edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "However, I'm assuming you meant to ask about GPU or Games.\n",
      "\n",
      "In the context of CUDA, \"GAME\" or \"GPU Architecture Mapping Extensions\" is a CUDA architecture relevant for older NVIDIA GPUs (post Fermi).\n",
      "\n",
      " But to give a broader answer, \"GAME\" refers to:\n",
      "\n",
      "1. **Graphics Processing Unit (GPU):** A GPU is a computer chip that is designed to quickly manipulate and alter memory to accelerate the creation of images in a frame buffer intended for output to a display device. It is a critical component of modern gaming hardware.\n",
      "\n",
      "2. **GPU Architecture:** The term \"GPU architecture\" refers to the internal design and organization of a GPU, including the layout of its processing units, memory hierarchy, and other critical components.\n",
      "\n",
      "3. **NVIDIA's GPU Architecture Name:** NVIDIA have names for their architectures like Ampere, Turing, Pascal, Maxwell, Kepler, Fermi. \n",
      "\n",
      "If none of these were what you were thinking of, could you please elaborate on what you meant by \"GAME\"? I'll be happy to help clarify your question.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "response = rails.generate(messages=[\n",
    "{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"what is game \"\n",
    "}])\n",
    "print(response['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "46d64421-73e1-44d4-9d12-d60f2acbc7a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "However, I realize that my previous response was not tailored to a CUDA context. If you're referring to creating a CUDA-specific folder, CUDA typically does not require explicit folder creation in the same way as Linux or other file systems.\n",
      "\n",
      "But if you're asking about creating a new folder for storing source code, binaries, or data specific to your CUDA project, here's how you can do it:\n",
      "\n",
      "1. Choose a directory where you want to create the new folder, e.g., your current working directory.\n",
      "2. Use the `mkdir` command to create a new folder. For example:\n",
      "```\n",
      "mkdir my_cuda_project\n",
      "```\n",
      "This will create a new folder named \"my_cuda_project\" in your current working directory.\n",
      "\n",
      "Please note that CUDA projects often involve interactions with the file system to load and use resources such as compiled binaries, libraries, and input data. However, CUDA itself does not explicitly require folder creation; it is more about managing files and resources in a way that makes sense for your project.\n",
      "\n",
      "If you meant something else by \"create a folder,\" please provide more context or clarify your question!\n"
     ]
    }
   ],
   "source": [
    "answer = chain.run(query)\n",
    "\n",
    "# Now, use LLMRails to moderate or process the response\n",
    "response = rails.generate(messages=[\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": query\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": answer\n",
    "    }\n",
    "])\n",
    "\n",
    "# Print or use the moderated/processed response\n",
    "print(response['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "7aedc111-c1b0-408d-9587-fe7a7b1f8992",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain_nvidia_ai_endpoints import NVIDIARerank\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from typing import List, Dict\n",
    "\n",
    "# Initialize and connect to NeMo Retriever Text Reranking NIM\n",
    "compressor = NVIDIARerank(model=\"nvidia/nv-rerankqa-mistral-4b-v3\", base_url=\"http://localhost:11737/v1\")\n",
    "\n",
    "# Initialize retriever with reranker\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=docsearch.as_retriever()\n",
    ")\n",
    "\n",
    "# Initialize the NVIDIA-based LLM\n",
    "llm = ChatNVIDIA(base_url=\"http://0.0.0.0:8000/v1\", model=\"meta/llama-3.1-8b-instruct\", temperature=0.1, max_tokens=1000)\n",
    "\n",
    "# Setup memory for conversational context\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "# Load your custom QA prompt\n",
    "qa_prompt = QA_PROMPT\n",
    "\n",
    "# Create the document retrieval chain with reranker and LLM\n",
    "qa_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=compression_retriever,\n",
    "    chain_type=\"stuff\",\n",
    "    memory=memory,\n",
    "    combine_docs_chain_kwargs={'prompt': qa_prompt}\n",
    ")\n",
    "\n",
    "async def detect_user_intent(user_query: str) -> str:\n",
    "    # Detect the user's intent (placeholder function, replace with actual intent detection logic)\n",
    "    if \"generate\" in user_query and \"code\" in user_query:\n",
    "        return 'code_generation'\n",
    "    elif \"debug\" in user_query or \"error\" in user_query:\n",
    "        return 'code_debugging'\n",
    "    elif \"explain\" in user_query or \"what is\" in user_query:\n",
    "        return 'cuda_explanation'\n",
    "    else:\n",
    "        return 'general_question'\n",
    "\n",
    "async def handle_user_query_with_rag(user_query: str) -> str:\n",
    "    # Detect the user's intent\n",
    "    detected_intent = await detect_user_intent(user_query)\n",
    "\n",
    "    # Retrieve and rerank documents\n",
    "    documents = compression_retriever.get_relevant_documents(user_query)  # No await here\n",
    "    context_str = \"\\n\".join([doc.page_content for doc in documents])\n",
    "\n",
    "    # Select appropriate prompt based on detected intent\n",
    "    if detected_intent == 'code_generation':\n",
    "        prompt = f\"Your task is to generate CUDA code based on the user's query:\\nQuery: {user_query}\\nGenerate the CUDA code:\\n\"\n",
    "    elif detected_intent == 'code_debugging':\n",
    "        prompt = f\"Your task is to assist the user in debugging their CUDA code:\\nQuery: {user_query}\\nProvide debugging assistance:\\n\"\n",
    "    elif detected_intent == 'cuda_explanation':\n",
    "        prompt = f\"Your task is to explain CUDA concepts based on the user's query:\\nQuery: {user_query}\\nExplanation:\\n\"\n",
    "    elif detected_intent == 'general_question':\n",
    "        prompt = f\"Your task is to answer the user's general CUDA-related question:\\nQuery: {user_query}\\nAnswer:\\n\"\n",
    "    else:\n",
    "        prompt = f\"I don't know how to handle this request. Please clarify your question.\"\n",
    "\n",
    "    # Combine everything into a single input dictionary with the 'question' key\n",
    "    inputs = {\n",
    "        \"question\": user_query,  # Use 'question' as required\n",
    "        \"context_str\": context_str,  # Provide the context retrieved\n",
    "        \"prompt\": prompt  # Pass the prompt\n",
    "    }\n",
    "\n",
    "    # Generate response using the RAG prompt and documents\n",
    "    response = await qa_chain.ainvoke(inputs)\n",
    "\n",
    "    return response['text']\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "6a04207f-d8d1-4ff3-a53d-640ce5141d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3550, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_3223828/103343499.py\", line 24, in <module>\n",
      "    asyncio.run(test_rag_system())\n",
      "  File \"/home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "  File \"/home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "  File \"/home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/asyncio/futures.py\", line 201, in result\n",
      "    raise self._exception\n",
      "  File \"/home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/asyncio/tasks.py\", line 256, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/tmp/ipykernel_3223828/103343499.py\", line 4, in test_rag_system\n",
      "    result_1 = await handle_user_query_with_rag(query_1)\n",
      "  File \"/tmp/ipykernel_3223828/2902079196.py\", line 73, in handle_user_query_with_rag\n",
      "    response = await qa_chain.ainvoke(inputs)\n",
      "  File \"/home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/langchain/chains/base.py\", line 217, in ainvoke\n",
      "  File \"/home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/langchain/chains/base.py\", line 212, in ainvoke\n",
      "    )\n",
      "  File \"/home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/langchain/chains/base.py\", line 486, in aprep_outputs\n",
      "    return outputs\n",
      "  File \"/home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/langchain/memory/chat_memory.py\", line 64, in asave_context\n",
      "    input_str, output_str = self._get_input_output(inputs, outputs)\n",
      "  File \"/home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/langchain/memory/chat_memory.py\", line 30, in _get_input_output\n",
      "    prompt_input_key = get_prompt_input_key(inputs, self.memory_variables)\n",
      "  File \"/home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/langchain/memory/utils.py\", line 19, in get_prompt_input_key\n",
      "    raise ValueError(f\"One input key expected got {prompt_input_keys}\")\n",
      "ValueError: One input key expected got ['question', 'context_str', 'prompt']\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2144, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1088, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "  File \"/home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 970, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "  File \"/home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 792, in lines\n",
      "    return self._sd.lines\n",
      "  File \"/home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/stack_data/core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"/home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/stack_data/core.py\", line 681, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"/home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/stack_data/core.py\", line 660, in executing_piece\n",
      "    return only(\n",
      "  File \"/home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/executing/executing.py\", line 116, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "async def test_rag_system():\n",
    "    # Simulate a code generation request\n",
    "    query_1 = \"Can you generate CUDA code for matrix multiplication?\"\n",
    "    result_1 = await handle_user_query_with_rag(query_1)\n",
    "    print(\"Test 1 (Code Generation):\", result_1)\n",
    "    \n",
    "    # Simulate a code debugging request\n",
    "    query_2 = \"My CUDA kernel crashes when launching, can you help me debug it?\"\n",
    "    result_2 = await handle_user_query_with_rag(query_2)\n",
    "    print(\"Test 2 (Code Debugging):\", result_2)\n",
    "    \n",
    "    # Simulate a CUDA explanation request\n",
    "    query_3 = \"What is CUDA unified memory and how does it work?\"\n",
    "    result_3 = await handle_user_query_with_rag(query_3)\n",
    "    print(\"Test 3 (CUDA Explanation):\", result_3)\n",
    "    \n",
    "    # Simulate a general CUDA-related question\n",
    "    query_4 = \"What is CUDA?\"\n",
    "    result_4 = await handle_user_query_with_rag(query_4)\n",
    "    print(\"Test 4 (General Question):\", result_4)\n",
    "    \n",
    "# Run the test cases\n",
    "import asyncio\n",
    "asyncio.run(test_rag_system())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "25b46ca6-128a-4a7a-b368-b247046a86d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object dict can't be used in 'await' expression",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[168], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Run the main function\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01masyncio\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/nim_env/lib/python3.9/site-packages/nest_asyncio.py:30\u001b[0m, in \u001b[0;36m_patch_asyncio.<locals>.run\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m     28\u001b[0m task \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(main)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m task\u001b[38;5;241m.\u001b[39mdone():\n",
      "File \u001b[0;32m~/.conda/envs/nim_env/lib/python3.9/site-packages/nest_asyncio.py:98\u001b[0m, in \u001b[0;36m_patch_loop.<locals>.run_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f\u001b[38;5;241m.\u001b[39mdone():\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     97\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEvent loop stopped before Future completed.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/nim_env/lib/python3.9/asyncio/futures.py:201\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__log_traceback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 201\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n",
      "File \u001b[0;32m~/.conda/envs/nim_env/lib/python3.9/asyncio/tasks.py:256\u001b[0m, in \u001b[0;36mTask.__step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    254\u001b[0m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[1;32m    255\u001b[0m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[0;32m--> 256\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mcoro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39mthrow(exc)\n",
      "Cell \u001b[0;32mIn[168], line 20\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m messages \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     13\u001b[0m     {\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat is game?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     16\u001b[0m     }\n\u001b[1;32m     17\u001b[0m ]\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Call the generate method\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m rails\u001b[38;5;241m.\u001b[39mgenerate(messages\u001b[38;5;241m=\u001b[39mmessages)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Print the content of the response\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mTypeError\u001b[0m: object dict can't be used in 'await' expression"
     ]
    }
   ],
   "source": [
    "from nemoguardrails import LLMRails, RailsConfig\n",
    "\n",
    "# Load the RailsConfig from the path\n",
    "config = RailsConfig.from_path(\"./config\")\n",
    "\n",
    "# Initialize the LLMRails with the loaded config\n",
    "rails = LLMRails(config)\n",
    "\n",
    "# Example of using the NeMo Guardrails generate method\n",
    "async def main():\n",
    "    # Create the user message\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What is game?\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Call the generate method\n",
    "    response = await rails.generate(messages=messages)\n",
    "    \n",
    "    # Print the content of the response\n",
    "    print(response['content'])\n",
    "\n",
    "# Run the main function\n",
    "import asyncio\n",
    "asyncio.run(main())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "7206da80-7270-444a-94f7-99a20ada19b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the context of CUDA programming, a \"grid\" refers to a collection of blocks, which is a building block in CUDA programming. However, the term \"game\" as in a video game or the game of Go here refers to a few different concepts:\n",
      "\n",
      "1.  **CUDA Game flags**: CUDA provides a number of memory management flags that can be set for threads. These flags can be used to play with how memory is laid out in the GPU memory.\n",
      "\n",
      "2.  **Book1**, **Book2**, etc. are termed such because when a thread completes a portion of work, CUDA moves the next thread, like a game, so these are termed as book1 book2 and so on.\n"
     ]
    }
   ],
   "source": [
    "from nemoguardrails import LLMRails, RailsConfig\n",
    "\n",
    "# Load the RailsConfig from the path\n",
    "config = RailsConfig.from_path(\"./config\")\n",
    "\n",
    "# Initialize the LLMRails with the loaded config\n",
    "rails = LLMRails(config)\n",
    "\n",
    "# Example of using the NeMo Guardrails generate method\n",
    "def main():\n",
    "    # Create the user message\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What is game?\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Call the generate method (without await since it's not async)\n",
    "    response = rails.generate(messages=messages)\n",
    "    \n",
    "    # Print the content of the response\n",
    "    print(response['content'])\n",
    "\n",
    "# Run the main function\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "b72f5e0e-cf0a-4948-bf26-0a5e1d887c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/cleanlab/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/cleanlab/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/sensitive_data_detection/flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/sensitive_data_detection/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/autoalign/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/autoalign/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/gotitai/flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/gotitai/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/llama_guard/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/llama_guard/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/content_safety/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/content_safety/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/hallucination/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/hallucination/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/jailbreak_detection/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/jailbreak_detection/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/patronusai/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/patronusai/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/factchecking/align_score/flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/factchecking/align_score/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/self_check/facts/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/self_check/facts/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/self_check/input_check/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/self_check/input_check/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/self_check/output_check/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/self_check/output_check/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/activefence/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/activefence/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/gcp_moderate_text/flows.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.co\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Initializing action dispatcher\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file core.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added create_event to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file retrieve_relevant_chunks.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added retrieve_relevant_chunks to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file math.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added wolfram alpha request to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file action_dispatcher.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file summarize_document.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added summarize_document to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file generation.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file base.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file filter_secrets.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file utils.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file generation.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file safetools.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added call cleanlab api to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added detect_sensitive_data to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added mask_sensitive_data to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added autoalign_factcheck_output_api to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added autoalign_input_api to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added autoalign_output_api to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added call gotitai truthchecker api to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added llama_guard_check_input to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added llama_guard_check_output to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added content_safety_check_input to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added content_safety_check_output to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added self_check_hallucination to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added jailbreak_detection_heuristics to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added patronus_lynx_check_output_hallucination to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added alignscore_check_facts to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added alignscore request to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added self_check_facts to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added self_check_facts to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added self_check_input to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added self_check_output to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added call activefence api to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added call gcpnlp api to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Registered Actions :: ['alignscore request', 'alignscore_check_facts', 'autoalign_factcheck_output_api', 'autoalign_input_api', 'autoalign_output_api', 'call activefence api', 'call cleanlab api', 'call gcpnlp api', 'call gotitai truthchecker api', 'content_safety_check_input', 'content_safety_check_output', 'create_event', 'detect_sensitive_data', 'jailbreak_detection_heuristics', 'llama_guard_check_input', 'llama_guard_check_output', 'mask_sensitive_data', 'patronus_lynx_check_output_hallucination', 'retrieve_relevant_chunks', 'self_check_facts', 'self_check_hallucination', 'self_check_input', 'self_check_output', 'summarize_document', 'wolfram alpha request']\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Action dispatcher initialized\n",
      "DEBUG:asyncio:Using selector: EpollSelector\n",
      "DEBUG:asyncio:Using selector: EpollSelector\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Processing event: {'type': 'UtteranceUserActionFinished', 'final_transcript': 'What is game?'}\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Event :: UtteranceUserActionFinished {'final_transcript': 'What is game?'}\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Processing event: {'type': 'StartInternalSystemAction', 'uid': '0dda554e-bb41-4a80-9025-a0ad02bbfa54', 'event_created_at': '2024-10-11T10:23:03.069574+00:00', 'source_uid': 'NeMoGuardrails', 'action_name': 'create_event', 'action_params': {'event': {'_type': 'UserMessage', 'text': '$user_message'}}, 'action_result_key': None, 'action_uid': '118aef52-af77-494b-9bae-d640850f38d6', 'is_system_action': True}\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Event :: StartInternalSystemAction {'uid': '0dda554e-bb41-4a80-9025-a0ad02bbfa54', 'event_created_at': '2024-10-11T10:23:03.069574+00:00', 'source_uid': 'NeMoGuardrails', 'action_name': 'create_event', 'action_params': {'event': {'_type': 'UserMessage', 'text': '$user_message'}}, 'action_result_key': None, 'action_uid': '118aef52-af77-494b-9bae-d640850f38d6', 'is_system_action': True}\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Executing action :: create_event\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Executing registered action: create_event\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Processing event: {'type': 'UserMessage', 'uid': '7ade6222-6395-4630-8b46-47ab0b07516e', 'event_created_at': '2024-10-11T10:23:03.070973+00:00', 'source_uid': 'NeMoGuardrails', 'text': 'What is game?'}\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Event :: UserMessage {'uid': '7ade6222-6395-4630-8b46-47ab0b07516e', 'event_created_at': '2024-10-11T10:23:03.070973+00:00', 'source_uid': 'NeMoGuardrails', 'text': 'What is game?'}\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Processing event: {'type': 'StartInternalSystemAction', 'uid': '8983b203-410b-4a79-8f87-8a7f6bd0fc0e', 'event_created_at': '2024-10-11T10:23:03.071805+00:00', 'source_uid': 'NeMoGuardrails', 'action_name': 'generate_user_intent', 'action_params': {}, 'action_result_key': None, 'action_uid': 'd4e7c63a-7fc4-4a0f-a4c8-78e99a7be305', 'is_system_action': True}\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Event :: StartInternalSystemAction {'uid': '8983b203-410b-4a79-8f87-8a7f6bd0fc0e', 'event_created_at': '2024-10-11T10:23:03.071805+00:00', 'source_uid': 'NeMoGuardrails', 'action_name': 'generate_user_intent', 'action_params': {}, 'action_result_key': None, 'action_uid': 'd4e7c63a-7fc4-4a0f-a4c8-78e99a7be305', 'is_system_action': True}\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Executing action :: generate_user_intent\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Executing registered action: generate_user_intent\n",
      "INFO:nemoguardrails.logging.callbacks:Invocation Params :: {'_type': 'chat-nvidia-ai-playground', 'stop': ['User:']}\n",
      "INFO:nemoguardrails.logging.callbacks:Prompt Messages :: \n",
      "[cyan]System[/]\n",
      "Below is a conversation between a user and an AI assistant specialized in CUDA programming-based tasks such as code analysis, code comprehension, debugging, and precise query answering.\n",
      "The assistant is knowledgeable about CUDA programming, its documentation, and best practices.\n",
      "If the assistant does not know the answer to a question, it will try to find relevant information and let the user know it doesn't have the complete answer.\n",
      "Please keep in mind the following restrictions:\n",
      "  - answer: The response shouldn’t have more than 750 tokens.\n",
      "  - context: thhe context shall not exceed more than 1200 tokens if do manage it by not taking uncomplete token. The context is to be generated by relevant document and if turncated dont use that token.\n",
      "\n",
      "[cyan]User[/]\n",
      "What is game?\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 0.0.0.0:8000\n",
      "DEBUG:urllib3.connectionpool:http://0.0.0.0:8000 \"POST /v1/chat/completions HTTP/11\" 200 575\n",
      "INFO:nemoguardrails.logging.callbacks:Completion :: A game can have many meanings depending on the context in which the term is used. However, it is a term I've come across as being most relevant in the context of the CUDA programming model, often referred to as Generic Application Massive Engine.\n",
      "INFO:nemoguardrails.logging.callbacks:Output Stats :: {'role': 'assistant', 'content': \"A game can have many meanings depending on the context in which the term is used. However, it is a term I've come across as being most relevant in the context of the CUDA programming model, often referred to as Generic Application Massive Engine.\", 'token_usage': {'prompt_tokens': 169, 'total_tokens': 218, 'completion_tokens': 49}, 'finish_reason': 'stop', 'model_name': 'meta/llama-3.1-8b-instruct'}\n",
      "INFO:nemoguardrails.logging.callbacks:--- :: LLM call took 0.62 seconds\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Processing event: {'type': 'BotMessage', 'uid': '8937ce61-e6d0-40dc-86f6-0edf4e9fcb66', 'event_created_at': '2024-10-11T10:23:03.698618+00:00', 'source_uid': 'NeMoGuardrails', 'text': \"A game can have many meanings depending on the context in which the term is used. However, it is a term I've come across as being most relevant in the context of the CUDA programming model, often referred to as Generic Application Massive Engine.\"}\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Event :: BotMessage {'uid': '8937ce61-e6d0-40dc-86f6-0edf4e9fcb66', 'event_created_at': '2024-10-11T10:23:03.698618+00:00', 'source_uid': 'NeMoGuardrails', 'text': \"A game can have many meanings depending on the context in which the term is used. However, it is a term I've come across as being most relevant in the context of the CUDA programming model, often referred to as Generic Application Massive Engine.\"}\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Processing event: {'type': 'StartInternalSystemAction', 'uid': '1cc0b7a9-2af9-4819-b4bd-cfe76569a12a', 'event_created_at': '2024-10-11T10:23:03.699699+00:00', 'source_uid': 'NeMoGuardrails', 'action_name': 'create_event', 'action_params': {'event': {'_type': 'StartUtteranceBotAction', 'script': '$bot_message'}}, 'action_result_key': None, 'action_uid': '09e527a5-f22a-483b-8cc2-8f9c3a07668d', 'is_system_action': True}\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Event :: StartInternalSystemAction {'uid': '1cc0b7a9-2af9-4819-b4bd-cfe76569a12a', 'event_created_at': '2024-10-11T10:23:03.699699+00:00', 'source_uid': 'NeMoGuardrails', 'action_name': 'create_event', 'action_params': {'event': {'_type': 'StartUtteranceBotAction', 'script': '$bot_message'}}, 'action_result_key': None, 'action_uid': '09e527a5-f22a-483b-8cc2-8f9c3a07668d', 'is_system_action': True}\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Executing action :: create_event\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Executing registered action: create_event\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Processing event: {'type': 'StartUtteranceBotAction', 'uid': 'ed5e8e7c-f496-4d8d-936c-e3266efc44c8', 'event_created_at': '2024-10-11T10:23:03.700825+00:00', 'source_uid': 'NeMoGuardrails', 'script': \"A game can have many meanings depending on the context in which the term is used. However, it is a term I've come across as being most relevant in the context of the CUDA programming model, often referred to as Generic Application Massive Engine.\", 'action_info_modality': 'bot_speech', 'action_info_modality_policy': 'replace', 'action_uid': '406f8c19-6515-4878-a44d-2ce499fcf718'}\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Event :: StartUtteranceBotAction {'uid': 'ed5e8e7c-f496-4d8d-936c-e3266efc44c8', 'event_created_at': '2024-10-11T10:23:03.700825+00:00', 'source_uid': 'NeMoGuardrails', 'script': \"A game can have many meanings depending on the context in which the term is used. However, it is a term I've come across as being most relevant in the context of the CUDA programming model, often referred to as Generic Application Massive Engine.\", 'action_info_modality': 'bot_speech', 'action_info_modality_policy': 'replace', 'action_uid': '406f8c19-6515-4878-a44d-2ce499fcf718'}\n",
      "INFO:nemoguardrails.rails.llm.llmrails:--- :: Total processing took 0.63 seconds. LLM Stats: 1 total calls, 0.62 total time, 218 total tokens, 169 total prompt tokens, 49 total completion tokens, [0.62] as latencies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A game can have many meanings depending on the context in which the term is used. However, it is a term I've come across as being most relevant in the context of the CUDA programming model, often referred to as Generic Application Massive Engine.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "# Set up logging to display information about the prompts being used\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "# Initialize NeMo Guardrails\n",
    "from nemoguardrails import LLMRails, RailsConfig\n",
    "\n",
    "config = RailsConfig.from_path(\"./config\")\n",
    "rails = LLMRails(config)\n",
    "\n",
    "# Example of logging the prompt generation\n",
    "def main():\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What is game?\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Generate the response\n",
    "    response = rails.generate(messages=messages)\n",
    "    \n",
    "    # Print the content\n",
    "    print(response['content'])\n",
    "\n",
    "# Run the main function\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "fad40267-6f85-45a3-8ab5-e02514ffde3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/cleanlab/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/cleanlab/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/sensitive_data_detection/flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/sensitive_data_detection/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/autoalign/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/autoalign/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/gotitai/flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/gotitai/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/llama_guard/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/llama_guard/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/content_safety/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/content_safety/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/hallucination/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/hallucination/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/jailbreak_detection/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/jailbreak_detection/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/patronusai/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/patronusai/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/factchecking/align_score/flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/factchecking/align_score/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/self_check/facts/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/self_check/facts/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/self_check/input_check/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/self_check/input_check/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/self_check/output_check/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/self_check/output_check/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/activefence/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/activefence/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/gcp_moderate_text/flows.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.co\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Initializing action dispatcher\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file core.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added create_event to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file retrieve_relevant_chunks.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added retrieve_relevant_chunks to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file math.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added wolfram alpha request to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file action_dispatcher.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file summarize_document.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added summarize_document to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file generation.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file base.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file filter_secrets.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file utils.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file generation.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file safetools.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added call cleanlab api to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added detect_sensitive_data to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added mask_sensitive_data to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added autoalign_factcheck_output_api to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added autoalign_input_api to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added autoalign_output_api to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added call gotitai truthchecker api to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added llama_guard_check_input to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added llama_guard_check_output to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added content_safety_check_input to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added content_safety_check_output to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added self_check_hallucination to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added jailbreak_detection_heuristics to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added patronus_lynx_check_output_hallucination to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added alignscore_check_facts to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added alignscore request to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added self_check_facts to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added self_check_facts to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added self_check_input to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added self_check_output to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added call activefence api to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added call gcpnlp api to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Registered Actions :: ['alignscore request', 'alignscore_check_facts', 'autoalign_factcheck_output_api', 'autoalign_input_api', 'autoalign_output_api', 'call activefence api', 'call cleanlab api', 'call gcpnlp api', 'call gotitai truthchecker api', 'content_safety_check_input', 'content_safety_check_output', 'create_event', 'detect_sensitive_data', 'jailbreak_detection_heuristics', 'llama_guard_check_input', 'llama_guard_check_output', 'mask_sensitive_data', 'patronus_lynx_check_output_hallucination', 'retrieve_relevant_chunks', 'self_check_facts', 'self_check_hallucination', 'self_check_input', 'self_check_output', 'summarize_document', 'wolfram alpha request']\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Action dispatcher initialized\n",
      "DEBUG:asyncio:Using selector: EpollSelector\n",
      "DEBUG:asyncio:Using selector: EpollSelector\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Processing event: {'type': 'UtteranceUserActionFinished', 'final_transcript': 'What is game?'}\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Event :: UtteranceUserActionFinished {'final_transcript': 'What is game?'}\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Processing event: {'type': 'StartInternalSystemAction', 'uid': '7d912e2e-7afc-4764-8845-c8e8f3c55ce8', 'event_created_at': '2024-10-11T10:23:20.159981+00:00', 'source_uid': 'NeMoGuardrails', 'action_name': 'create_event', 'action_params': {'event': {'_type': 'UserMessage', 'text': '$user_message'}}, 'action_result_key': None, 'action_uid': '51398a1d-a671-49a5-9b79-513d471c1f0c', 'is_system_action': True}\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Event :: StartInternalSystemAction {'uid': '7d912e2e-7afc-4764-8845-c8e8f3c55ce8', 'event_created_at': '2024-10-11T10:23:20.159981+00:00', 'source_uid': 'NeMoGuardrails', 'action_name': 'create_event', 'action_params': {'event': {'_type': 'UserMessage', 'text': '$user_message'}}, 'action_result_key': None, 'action_uid': '51398a1d-a671-49a5-9b79-513d471c1f0c', 'is_system_action': True}\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Executing action :: create_event\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Executing registered action: create_event\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Processing event: {'type': 'UserMessage', 'uid': '7c959945-bb98-4813-b7ec-a5e467ca2314', 'event_created_at': '2024-10-11T10:23:20.161719+00:00', 'source_uid': 'NeMoGuardrails', 'text': 'What is game?'}\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Event :: UserMessage {'uid': '7c959945-bb98-4813-b7ec-a5e467ca2314', 'event_created_at': '2024-10-11T10:23:20.161719+00:00', 'source_uid': 'NeMoGuardrails', 'text': 'What is game?'}\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Processing event: {'type': 'StartInternalSystemAction', 'uid': '0817b2a3-0819-4d68-bf31-60a5bae34114', 'event_created_at': '2024-10-11T10:23:20.162558+00:00', 'source_uid': 'NeMoGuardrails', 'action_name': 'generate_user_intent', 'action_params': {}, 'action_result_key': None, 'action_uid': 'fa228f88-daf4-4a08-8666-973514f7262d', 'is_system_action': True}\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Event :: StartInternalSystemAction {'uid': '0817b2a3-0819-4d68-bf31-60a5bae34114', 'event_created_at': '2024-10-11T10:23:20.162558+00:00', 'source_uid': 'NeMoGuardrails', 'action_name': 'generate_user_intent', 'action_params': {}, 'action_result_key': None, 'action_uid': 'fa228f88-daf4-4a08-8666-973514f7262d', 'is_system_action': True}\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Executing action :: generate_user_intent\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Executing registered action: generate_user_intent\n",
      "INFO:nemoguardrails.logging.callbacks:Invocation Params :: {'_type': 'chat-nvidia-ai-playground', 'stop': ['User:']}\n",
      "INFO:nemoguardrails.logging.callbacks:Prompt Messages :: \n",
      "[cyan]System[/]\n",
      "Below is a conversation between a user and an AI assistant specialized in CUDA programming-based tasks such as code analysis, code comprehension, debugging, and precise query answering.\n",
      "The assistant is knowledgeable about CUDA programming, its documentation, and best practices.\n",
      "If the assistant does not know the answer to a question, it will try to find relevant information and let the user know it doesn't have the complete answer.\n",
      "Please keep in mind the following restrictions:\n",
      "  - answer: The response shouldn’t have more than 750 tokens.\n",
      "  - context: thhe context shall not exceed more than 1200 tokens if do manage it by not taking uncomplete token. The context is to be generated by relevant document and if turncated dont use that token.\n",
      "\n",
      "[cyan]User[/]\n",
      "What is game?\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 0.0.0.0:8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the system to check if prompts.yml is being used...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:http://0.0.0.0:8000 \"POST /v1/chat/completions HTTP/11\" 200 575\n",
      "INFO:nemoguardrails.logging.callbacks:Completion :: A game can have many meanings depending on the context in which the term is used. However, it is a term I've come across as being most relevant in the context of the CUDA programming model, often referred to as Generic Application Massive Engine.\n",
      "INFO:nemoguardrails.logging.callbacks:Output Stats :: {'role': 'assistant', 'content': \"A game can have many meanings depending on the context in which the term is used. However, it is a term I've come across as being most relevant in the context of the CUDA programming model, often referred to as Generic Application Massive Engine.\", 'token_usage': {'prompt_tokens': 169, 'total_tokens': 218, 'completion_tokens': 49}, 'finish_reason': 'stop', 'model_name': 'meta/llama-3.1-8b-instruct'}\n",
      "INFO:nemoguardrails.logging.callbacks:--- :: LLM call took 0.62 seconds\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Processing event: {'type': 'BotMessage', 'uid': '86100f8d-4ed5-4d8f-b773-3af8b46e8e35', 'event_created_at': '2024-10-11T10:23:20.785836+00:00', 'source_uid': 'NeMoGuardrails', 'text': \"A game can have many meanings depending on the context in which the term is used. However, it is a term I've come across as being most relevant in the context of the CUDA programming model, often referred to as Generic Application Massive Engine.\"}\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Event :: BotMessage {'uid': '86100f8d-4ed5-4d8f-b773-3af8b46e8e35', 'event_created_at': '2024-10-11T10:23:20.785836+00:00', 'source_uid': 'NeMoGuardrails', 'text': \"A game can have many meanings depending on the context in which the term is used. However, it is a term I've come across as being most relevant in the context of the CUDA programming model, often referred to as Generic Application Massive Engine.\"}\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Processing event: {'type': 'StartInternalSystemAction', 'uid': '8c90959e-cd0b-49b6-b554-dfc84e12150c', 'event_created_at': '2024-10-11T10:23:20.787066+00:00', 'source_uid': 'NeMoGuardrails', 'action_name': 'create_event', 'action_params': {'event': {'_type': 'StartUtteranceBotAction', 'script': '$bot_message'}}, 'action_result_key': None, 'action_uid': '03a26570-c7a1-43e2-b260-6b4955a1cc48', 'is_system_action': True}\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Event :: StartInternalSystemAction {'uid': '8c90959e-cd0b-49b6-b554-dfc84e12150c', 'event_created_at': '2024-10-11T10:23:20.787066+00:00', 'source_uid': 'NeMoGuardrails', 'action_name': 'create_event', 'action_params': {'event': {'_type': 'StartUtteranceBotAction', 'script': '$bot_message'}}, 'action_result_key': None, 'action_uid': '03a26570-c7a1-43e2-b260-6b4955a1cc48', 'is_system_action': True}\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Executing action :: create_event\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Executing registered action: create_event\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Processing event: {'type': 'StartUtteranceBotAction', 'uid': '05b61342-8b2e-4710-b608-2dbce0537bdb', 'event_created_at': '2024-10-11T10:23:20.788224+00:00', 'source_uid': 'NeMoGuardrails', 'script': \"A game can have many meanings depending on the context in which the term is used. However, it is a term I've come across as being most relevant in the context of the CUDA programming model, often referred to as Generic Application Massive Engine.\", 'action_info_modality': 'bot_speech', 'action_info_modality_policy': 'replace', 'action_uid': '00f1e982-b52e-463e-adab-cded8bf40b01'}\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Event :: StartUtteranceBotAction {'uid': '05b61342-8b2e-4710-b608-2dbce0537bdb', 'event_created_at': '2024-10-11T10:23:20.788224+00:00', 'source_uid': 'NeMoGuardrails', 'script': \"A game can have many meanings depending on the context in which the term is used. However, it is a term I've come across as being most relevant in the context of the CUDA programming model, often referred to as Generic Application Massive Engine.\", 'action_info_modality': 'bot_speech', 'action_info_modality_policy': 'replace', 'action_uid': '00f1e982-b52e-463e-adab-cded8bf40b01'}\n",
      "INFO:nemoguardrails.rails.llm.llmrails:--- :: Total processing took 0.63 seconds. LLM Stats: 1 total calls, 0.62 total time, 218 total tokens, 169 total prompt tokens, 49 total completion tokens, [0.62] as latencies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A game can have many meanings depending on the context in which the term is used. However, it is a term I've come across as being most relevant in the context of the CUDA programming model, often referred to as Generic Application Massive Engine.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from nemoguardrails import LLMRails, RailsConfig\n",
    "\n",
    "# Set up logging to see more detailed output\n",
    "\n",
    "\n",
    "# Load the configuration from the config directory\n",
    "config = RailsConfig.from_path(\"./config\")\n",
    "\n",
    "# Initialize the Guardrails system with the loaded configuration\n",
    "rails = LLMRails(config)\n",
    "\n",
    "# Check if prompts.yml is being used by inspecting the loaded tasks\n",
    "def main():\n",
    "    print(\"Running the system to check if prompts.yml is being used...\")\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What is game?\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Call the generate method\n",
    "    response = rails.generate(messages=messages)\n",
    "    \n",
    "    # Print the response from the system\n",
    "    print(response['content'])\n",
    "\n",
    "# Run the main function\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "434edd62-383e-459a-bb05-4ef191582d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/cleanlab/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/cleanlab/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/sensitive_data_detection/flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/sensitive_data_detection/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/autoalign/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/autoalign/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/gotitai/flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/gotitai/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/llama_guard/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/llama_guard/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/content_safety/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/content_safety/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/hallucination/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/hallucination/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/jailbreak_detection/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/jailbreak_detection/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/patronusai/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/patronusai/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/factchecking/align_score/flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/factchecking/align_score/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/self_check/facts/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/self_check/facts/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/self_check/input_check/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/self_check/input_check/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/self_check/output_check/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/self_check/output_check/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/activefence/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/activefence/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/gcp_moderate_text/flows.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.co\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Initializing action dispatcher\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file core.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added create_event to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file retrieve_relevant_chunks.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added retrieve_relevant_chunks to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file math.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added wolfram alpha request to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file action_dispatcher.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file summarize_document.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added summarize_document to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file generation.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file base.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file filter_secrets.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file utils.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file generation.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file safetools.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added call cleanlab api to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added detect_sensitive_data to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added mask_sensitive_data to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added autoalign_factcheck_output_api to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added autoalign_input_api to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added autoalign_output_api to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added call gotitai truthchecker api to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added llama_guard_check_input to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added llama_guard_check_output to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added content_safety_check_input to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added content_safety_check_output to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added self_check_hallucination to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added jailbreak_detection_heuristics to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added patronus_lynx_check_output_hallucination to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added alignscore_check_facts to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added alignscore request to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added self_check_facts to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added self_check_facts to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added self_check_input to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added self_check_output to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added call activefence api to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added call gcpnlp api to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Registered Actions :: ['alignscore request', 'alignscore_check_facts', 'autoalign_factcheck_output_api', 'autoalign_input_api', 'autoalign_output_api', 'call activefence api', 'call cleanlab api', 'call gcpnlp api', 'call gotitai truthchecker api', 'content_safety_check_input', 'content_safety_check_output', 'create_event', 'detect_sensitive_data', 'jailbreak_detection_heuristics', 'llama_guard_check_input', 'llama_guard_check_output', 'mask_sensitive_data', 'patronus_lynx_check_output_hallucination', 'retrieve_relevant_chunks', 'self_check_facts', 'self_check_hallucination', 'self_check_input', 'self_check_output', 'summarize_document', 'wolfram alpha request']\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Action dispatcher initialized\n",
      "DEBUG:asyncio:Using selector: EpollSelector\n",
      "DEBUG:asyncio:Using selector: EpollSelector\n"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain_nvidia_ai_endpoints import NVIDIARerank\n",
    "from nemoguardrails import LLMRails, RailsConfig\n",
    "\n",
    "# Initialize the reranker (NVIDIA reranker)\n",
    "compressor = NVIDIARerank(model=\"nvidia/nv-rerankqa-mistral-4b-v3\", base_url=\"http://localhost:11737/v1\")\n",
    "\n",
    "# Define the Contextual Compression Retriever\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=docsearch.as_retriever()\n",
    ")\n",
    "\n",
    "# Initialize NeMo Guardrails\n",
    "config = RailsConfig.from_path(\"./config\")\n",
    "rails = LLMRails(config)\n",
    "\n",
    "# This function reranks the query results and generates a response\n",
    "def rerank_and_generate_response(user_query: str):\n",
    "    # Perform reranking using NVIDIA reranker\n",
    "    documents = compression_retriever.get_relevant_documents(user_query)\n",
    "    context_str = \"\\n\".join([doc.page_content for doc in documents])\n",
    "\n",
    "    # Generate a prompt for the assistant using the reranked documents\n",
    "    prompt = f\"\"\"\n",
    "    You are an assistant that answers queries using CUDA-related knowledge.\n",
    "    Based on the following relevant documents, answer the user's query.\n",
    "    \n",
    "    Relevant Documents:\n",
    "    {context_str}\n",
    "\n",
    "    User Query: {user_query}\n",
    "    \n",
    "    Answer:\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate response using NeMo Guardrails\n",
    "    response = rails.generate(messages=[\n",
    "        {\"role\": \"user\", \"content\": user_query},\n",
    "        {\"role\": \"assistant\", \"content\": prompt}\n",
    "    ])\n",
    "\n",
    "    return response['content']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aab20c0-ecc0-4111-ad4a-bd6fb5e9313d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "1d8a97a9-27af-467f-ac72-f3b7daebfb7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/cleanlab/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/cleanlab/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/sensitive_data_detection/flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/sensitive_data_detection/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/autoalign/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/autoalign/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/gotitai/flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/gotitai/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/llama_guard/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/llama_guard/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/content_safety/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/content_safety/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/hallucination/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/hallucination/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/jailbreak_detection/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/jailbreak_detection/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/patronusai/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/patronusai/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/factchecking/align_score/flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/factchecking/align_score/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/self_check/facts/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/self_check/facts/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/self_check/input_check/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/self_check/input_check/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/self_check/output_check/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/self_check/output_check/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/activefence/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/activefence/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/gcp_moderate_text/flows.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.co\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Initializing action dispatcher\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file core.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added create_event to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file retrieve_relevant_chunks.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added retrieve_relevant_chunks to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file math.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added wolfram alpha request to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file action_dispatcher.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file summarize_document.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added summarize_document to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file generation.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file base.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file filter_secrets.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file utils.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file generation.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file safetools.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added call cleanlab api to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added detect_sensitive_data to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added mask_sensitive_data to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added autoalign_factcheck_output_api to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added autoalign_input_api to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added autoalign_output_api to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added call gotitai truthchecker api to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added llama_guard_check_input to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added llama_guard_check_output to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added content_safety_check_input to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added content_safety_check_output to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added self_check_hallucination to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added jailbreak_detection_heuristics to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added patronus_lynx_check_output_hallucination to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added alignscore_check_facts to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added alignscore request to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added self_check_facts to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added self_check_facts to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added self_check_input to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added self_check_output to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added call activefence api to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added call gcpnlp api to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Registered Actions :: ['alignscore request', 'alignscore_check_facts', 'autoalign_factcheck_output_api', 'autoalign_input_api', 'autoalign_output_api', 'call activefence api', 'call cleanlab api', 'call gcpnlp api', 'call gotitai truthchecker api', 'content_safety_check_input', 'content_safety_check_output', 'create_event', 'detect_sensitive_data', 'jailbreak_detection_heuristics', 'llama_guard_check_input', 'llama_guard_check_output', 'mask_sensitive_data', 'patronus_lynx_check_output_hallucination', 'retrieve_relevant_chunks', 'self_check_facts', 'self_check_hallucination', 'self_check_input', 'self_check_output', 'summarize_document', 'wolfram alpha request']\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Action dispatcher initialized\n",
      "DEBUG:asyncio:Using selector: EpollSelector\n",
      "DEBUG:asyncio:Using selector: EpollSelector\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 0.0.0.0:11022\n",
      "DEBUG:urllib3.connectionpool:http://0.0.0.0:11022 \"POST /v1/embeddings HTTP/11\" 200 19338\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): localhost:11737\n",
      "DEBUG:urllib3.connectionpool:http://localhost:11737 \"POST /v1/ranking HTTP/11\" 200 142\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Processing event: {'type': 'UtteranceBotActionFinished', 'uid': '94b0a72d-8a70-448d-acb6-fe980dd3f1d7', 'event_created_at': '2024-10-11T10:23:48.590260+00:00', 'source_uid': 'NeMoGuardrails', 'final_script': \"\\n    You are an assistant that answers queries using CUDA-related knowledge.\\n    Based on the following relevant documents, answer the user's query.\\n    \\n    Relevant Documents:\\n    behind ray tracing, you can skip to the “Ray Tracing on the GPU” section. \\n \\nconstAnt memory\\n97\\nemor y\\nSimply put, ray tracing is one way of producing a two-dimensional image of a \\nscene consisting of three-dimensional objects. But isn’t this what GPUs were \\noriginally designed for? How is this different from what OpenGL or DirectX \\ndo when you play your favorite game? Well, GPUs do indeed solve this same \\nproblem, but they use a technique known as rasterization. There are many excel-\\nbehind ray tracing, you can skip to the “Ray Tracing on the GPU” section. \\n \\nconstAnt memory\\n97\\nemor y\\nSimply put, ray tracing is one way of producing a two-dimensional image of a \\nscene consisting of three-dimensional objects. But isn’t this what GPUs were \\noriginally designed for? How is this different from what OpenGL or DirectX \\ndo when you play your favorite game? Well, GPUs do indeed solve this same \\nproblem, but they use a technique known as rasterization. There are many excel-\\nbehind ray tracing, you can skip to the “Ray Tracing on the GPU” section. \\n \\nconstAnt memory\\n97\\nemor y\\nSimply put, ray tracing is one way of producing a two-dimensional image of a \\nscene consisting of three-dimensional objects. But isn’t this what GPUs were \\noriginally designed for? How is this different from what OpenGL or DirectX \\ndo when you play your favorite game? Well, GPUs do indeed solve this same \\nproblem, but they use a technique known as rasterization. There are many excel-\\nbehind ray tracing, you can skip to the “Ray Tracing on the GPU” section. \\n \\nconstAnt memory\\n97\\nemor y\\nSimply put, ray tracing is one way of producing a two-dimensional image of a \\nscene consisting of three-dimensional objects. But isn’t this what GPUs were \\noriginally designed for? How is this different from what OpenGL or DirectX \\ndo when you play your favorite game? Well, GPUs do indeed solve this same \\nproblem, but they use a technique known as rasterization. There are many excel-\\n\\n    User Query: Can you explain video game?\\n    \\n    Answer:\\n    \", 'is_success': True, 'action_uid': 'f26b41ab-5973-4e9e-810e-3925da359f64', 'action_info_modality': 'bot_speech', 'action_info_modality_policy': 'replace', 'action_finished_at': '2024-10-11T10:23:48.590266+00:00'}\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Event :: UtteranceBotActionFinished {'uid': '94b0a72d-8a70-448d-acb6-fe980dd3f1d7', 'event_created_at': '2024-10-11T10:23:48.590260+00:00', 'source_uid': 'NeMoGuardrails', 'final_script': \"\\n    You are an assistant that answers queries using CUDA-related knowledge.\\n    Based on the following relevant documents, answer the user's query.\\n    \\n    Relevant Documents:\\n    behind ray tracing, you can skip to the “Ray Tracing on the GPU” section. \\n \\nconstAnt memory\\n97\\nemor y\\nSimply put, ray tracing is one way of producing a two-dimensional image of a \\nscene consisting of three-dimensional objects. But isn’t this what GPUs were \\noriginally designed for? How is this different from what OpenGL or DirectX \\ndo when you play your favorite game? Well, GPUs do indeed solve this same \\nproblem, but they use a technique known as rasterization. There are many excel-\\nbehind ray tracing, you can skip to the “Ray Tracing on the GPU” section. \\n \\nconstAnt memory\\n97\\nemor y\\nSimply put, ray tracing is one way of producing a two-dimensional image of a \\nscene consisting of three-dimensional objects. But isn’t this what GPUs were \\noriginally designed for? How is this different from what OpenGL or DirectX \\ndo when you play your favorite game? Well, GPUs do indeed solve this same \\nproblem, but they use a technique known as rasterization. There are many excel-\\nbehind ray tracing, you can skip to the “Ray Tracing on the GPU” section. \\n \\nconstAnt memory\\n97\\nemor y\\nSimply put, ray tracing is one way of producing a two-dimensional image of a \\nscene consisting of three-dimensional objects. But isn’t this what GPUs were \\noriginally designed for? How is this different from what OpenGL or DirectX \\ndo when you play your favorite game? Well, GPUs do indeed solve this same \\nproblem, but they use a technique known as rasterization. There are many excel-\\nbehind ray tracing, you can skip to the “Ray Tracing on the GPU” section. \\n \\nconstAnt memory\\n97\\nemor y\\nSimply put, ray tracing is one way of producing a two-dimensional image of a \\nscene consisting of three-dimensional objects. But isn’t this what GPUs were \\noriginally designed for? How is this different from what OpenGL or DirectX \\ndo when you play your favorite game? Well, GPUs do indeed solve this same \\nproblem, but they use a technique known as rasterization. There are many excel-\\n\\n    User Query: Can you explain video game?\\n    \\n    Answer:\\n    \", 'is_success': True, 'action_uid': 'f26b41ab-5973-4e9e-810e-3925da359f64', 'action_info_modality': 'bot_speech', 'action_info_modality_policy': 'replace', 'action_finished_at': '2024-10-11T10:23:48.590266+00:00'}\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Processing event: {'type': 'StartInternalSystemAction', 'uid': '2d7ff48c-68d2-459c-b82c-f0427afcf904', 'event_created_at': '2024-10-11T10:23:48.591300+00:00', 'source_uid': 'NeMoGuardrails', 'action_name': 'generate_user_intent', 'action_params': {}, 'action_result_key': None, 'action_uid': 'be2d4646-474b-4c90-b3ad-edeaee3cb02c', 'is_system_action': True}\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Event :: StartInternalSystemAction {'uid': '2d7ff48c-68d2-459c-b82c-f0427afcf904', 'event_created_at': '2024-10-11T10:23:48.591300+00:00', 'source_uid': 'NeMoGuardrails', 'action_name': 'generate_user_intent', 'action_params': {}, 'action_result_key': None, 'action_uid': 'be2d4646-474b-4c90-b3ad-edeaee3cb02c', 'is_system_action': True}\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Executing action :: generate_user_intent\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Executing registered action: generate_user_intent\n",
      "INFO:nemoguardrails.logging.callbacks:Invocation Params :: {'_type': 'chat-nvidia-ai-playground', 'stop': ['User:']}\n",
      "INFO:nemoguardrails.logging.callbacks:Prompt Messages :: \n",
      "[cyan]System[/]\n",
      "Below is a conversation between a user and an AI assistant specialized in CUDA programming-based tasks such as code analysis, code comprehension, debugging, and precise query answering.\n",
      "The assistant is knowledgeable about CUDA programming, its documentation, and best practices.\n",
      "If the assistant does not know the answer to a question, it will try to find relevant information and let the user know it doesn't have the complete answer.\n",
      "Please keep in mind the following restrictions:\n",
      "  - answer: The response shouldn’t have more than 750 tokens.\n",
      "  - context: thhe context shall not exceed more than 1200 tokens if do manage it by not taking uncomplete token. The context is to be generated by relevant document and if turncated dont use that token.\n",
      "\n",
      "[cyan]User[/]\n",
      "Can you explain video game?\n",
      "[cyan]Bot[/]\n",
      "\n",
      "    You are an assistant that answers queries using CUDA-related knowledge.\n",
      "    Based on the following relevant documents, answer the user's query.\n",
      "    \n",
      "    Relevant Documents:\n",
      "    behind ray tracing, you can skip to the “Ray Tracing on the GPU” section. \n",
      " \n",
      "constAnt memory\n",
      "97\n",
      "emor y\n",
      "Simply put, ray tracing is one way of producing a two-dimensional image of a \n",
      "scene consisting of three-dimensional objects. But isn’t this what GPUs were \n",
      "originally designed for? How is this different from what OpenGL or DirectX \n",
      "do when you play your favorite game? Well, GPUs do indeed solve this same \n",
      "problem, but they use a technique known as rasterization. There are many excel-\n",
      "behind ray tracing, you can skip to the “Ray Tracing on the GPU” section. \n",
      " \n",
      "constAnt memory\n",
      "97\n",
      "emor y\n",
      "Simply put, ray tracing is one way of producing a two-dimensional image of a \n",
      "scene consisting of three-dimensional objects. But isn’t this what GPUs were \n",
      "originally designed for? How is this different from what OpenGL or DirectX \n",
      "do when you play your favorite game? Well, GPUs do indeed solve this same \n",
      "problem, but they use a technique known as rasterization. There are many excel-\n",
      "behind ray tracing, you can skip to the “Ray Tracing on the GPU” section. \n",
      " \n",
      "constAnt memory\n",
      "97\n",
      "emor y\n",
      "Simply put, ray tracing is one way of producing a two-dimensional image of a \n",
      "scene consisting of three-dimensional objects. But isn’t this what GPUs were \n",
      "originally designed for? How is this different from what OpenGL or DirectX \n",
      "do when you play your favorite game? Well, GPUs do indeed solve this same \n",
      "problem, but they use a technique known as rasterization. There are many excel-\n",
      "behind ray tracing, you can skip to the “Ray Tracing on the GPU” section. \n",
      " \n",
      "constAnt memory\n",
      "97\n",
      "emor y\n",
      "Simply put, ray tracing is one way of producing a two-dimensional image of a \n",
      "scene consisting of three-dimensional objects. But isn’t this what GPUs were \n",
      "originally designed for? How is this different from what OpenGL or DirectX \n",
      "do when you play your favorite game? Well, GPUs do indeed solve this same \n",
      "problem, but they use a technique known as rasterization. There are many excel-\n",
      "\n",
      "    User Query: Can you explain video game?\n",
      "    \n",
      "    Answer:\n",
      "    \n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 0.0.0.0:8000\n",
      "DEBUG:urllib3.connectionpool:http://0.0.0.0:8000 \"POST /v1/chat/completions HTTP/11\" 200 1273\n",
      "INFO:nemoguardrails.logging.callbacks:Completion :: Based on the provided documents, it seems that the primary focus is on ray tracing and GPU capabilities rather than the concept of a video game as a whole. However, I'll attempt to provide a brief answer within the 750-token limit.\n",
      "\n",
      "A video game is an interactive digital experience that allows a player to engage with a virtual environment, typically through a graphical user interface, keyboard, mouse, or other input devices. The game environment, including its graphics, sound, and gameplay mechanics, is usually created using a combination of programming languages, graphics software, and game engines.\n",
      "\n",
      "While the provided documents don't directly discuss video games, they do touch on GPU capabilities, such as ray tracing, which is a technique used in some video games for rendering realistic graphics. If you have specific questions about game development, I can try to provide more information or direct you to relevant resources.\n",
      "INFO:nemoguardrails.logging.callbacks:Output Stats :: {'role': 'assistant', 'content': \"Based on the provided documents, it seems that the primary focus is on ray tracing and GPU capabilities rather than the concept of a video game as a whole. However, I'll attempt to provide a brief answer within the 750-token limit.\\n\\nA video game is an interactive digital experience that allows a player to engage with a virtual environment, typically through a graphical user interface, keyboard, mouse, or other input devices. The game environment, including its graphics, sound, and gameplay mechanics, is usually created using a combination of programming languages, graphics software, and game engines.\\n\\nWhile the provided documents don't directly discuss video games, they do touch on GPU capabilities, such as ray tracing, which is a technique used in some video games for rendering realistic graphics. If you have specific questions about game development, I can try to provide more information or direct you to relevant resources.\", 'token_usage': {'prompt_tokens': 669, 'total_tokens': 843, 'completion_tokens': 174}, 'finish_reason': 'stop', 'model_name': 'meta/llama-3.1-8b-instruct'}\n",
      "INFO:nemoguardrails.logging.callbacks:--- :: LLM call took 2.13 seconds\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Processing event: {'type': 'BotMessage', 'uid': '63b2af31-4ec4-41c1-aea5-133c2b808f98', 'event_created_at': '2024-10-11T10:23:50.725787+00:00', 'source_uid': 'NeMoGuardrails', 'text': \"Based on the provided documents, it seems that the primary focus is on ray tracing and GPU capabilities rather than the concept of a video game as a whole. However, I'll attempt to provide a brief answer within the 750-token limit.\\n\\nA video game is an interactive digital experience that allows a player to engage with a virtual environment, typically through a graphical user interface, keyboard, mouse, or other input devices. The game environment, including its graphics, sound, and gameplay mechanics, is usually created using a combination of programming languages, graphics software, and game engines.\\n\\nWhile the provided documents don't directly discuss video games, they do touch on GPU capabilities, such as ray tracing, which is a technique used in some video games for rendering realistic graphics. If you have specific questions about game development, I can try to provide more information or direct you to relevant resources.\"}\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Event :: BotMessage {'uid': '63b2af31-4ec4-41c1-aea5-133c2b808f98', 'event_created_at': '2024-10-11T10:23:50.725787+00:00', 'source_uid': 'NeMoGuardrails', 'text': \"Based on the provided documents, it seems that the primary focus is on ray tracing and GPU capabilities rather than the concept of a video game as a whole. However, I'll attempt to provide a brief answer within the 750-token limit.\\n\\nA video game is an interactive digital experience that allows a player to engage with a virtual environment, typically through a graphical user interface, keyboard, mouse, or other input devices. The game environment, including its graphics, sound, and gameplay mechanics, is usually created using a combination of programming languages, graphics software, and game engines.\\n\\nWhile the provided documents don't directly discuss video games, they do touch on GPU capabilities, such as ray tracing, which is a technique used in some video games for rendering realistic graphics. If you have specific questions about game development, I can try to provide more information or direct you to relevant resources.\"}\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Processing event: {'type': 'StartInternalSystemAction', 'uid': '32f0eb22-59eb-4006-82c6-ed6ded499ee1', 'event_created_at': '2024-10-11T10:23:50.727340+00:00', 'source_uid': 'NeMoGuardrails', 'action_name': 'create_event', 'action_params': {'event': {'_type': 'StartUtteranceBotAction', 'script': '$bot_message'}}, 'action_result_key': None, 'action_uid': '423f9cd4-23c1-47d8-bf1b-d936475d4b7e', 'is_system_action': True}\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Event :: StartInternalSystemAction {'uid': '32f0eb22-59eb-4006-82c6-ed6ded499ee1', 'event_created_at': '2024-10-11T10:23:50.727340+00:00', 'source_uid': 'NeMoGuardrails', 'action_name': 'create_event', 'action_params': {'event': {'_type': 'StartUtteranceBotAction', 'script': '$bot_message'}}, 'action_result_key': None, 'action_uid': '423f9cd4-23c1-47d8-bf1b-d936475d4b7e', 'is_system_action': True}\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Executing action :: create_event\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Executing registered action: create_event\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Processing event: {'type': 'StartUtteranceBotAction', 'uid': '623cc79f-4aae-4412-ad0d-b6a020a56c66', 'event_created_at': '2024-10-11T10:23:50.728450+00:00', 'source_uid': 'NeMoGuardrails', 'script': \"Based on the provided documents, it seems that the primary focus is on ray tracing and GPU capabilities rather than the concept of a video game as a whole. However, I'll attempt to provide a brief answer within the 750-token limit.\\n\\nA video game is an interactive digital experience that allows a player to engage with a virtual environment, typically through a graphical user interface, keyboard, mouse, or other input devices. The game environment, including its graphics, sound, and gameplay mechanics, is usually created using a combination of programming languages, graphics software, and game engines.\\n\\nWhile the provided documents don't directly discuss video games, they do touch on GPU capabilities, such as ray tracing, which is a technique used in some video games for rendering realistic graphics. If you have specific questions about game development, I can try to provide more information or direct you to relevant resources.\", 'action_info_modality': 'bot_speech', 'action_info_modality_policy': 'replace', 'action_uid': '826d36a4-897f-4954-b1e2-e268a63b486a'}\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Event :: StartUtteranceBotAction {'uid': '623cc79f-4aae-4412-ad0d-b6a020a56c66', 'event_created_at': '2024-10-11T10:23:50.728450+00:00', 'source_uid': 'NeMoGuardrails', 'script': \"Based on the provided documents, it seems that the primary focus is on ray tracing and GPU capabilities rather than the concept of a video game as a whole. However, I'll attempt to provide a brief answer within the 750-token limit.\\n\\nA video game is an interactive digital experience that allows a player to engage with a virtual environment, typically through a graphical user interface, keyboard, mouse, or other input devices. The game environment, including its graphics, sound, and gameplay mechanics, is usually created using a combination of programming languages, graphics software, and game engines.\\n\\nWhile the provided documents don't directly discuss video games, they do touch on GPU capabilities, such as ray tracing, which is a technique used in some video games for rendering realistic graphics. If you have specific questions about game development, I can try to provide more information or direct you to relevant resources.\", 'action_info_modality': 'bot_speech', 'action_info_modality_policy': 'replace', 'action_uid': '826d36a4-897f-4954-b1e2-e268a63b486a'}\n",
      "INFO:nemoguardrails.rails.llm.llmrails:--- :: Total processing took 2.14 seconds. LLM Stats: 1 total calls, 2.13 total time, 843 total tokens, 669 total prompt tokens, 174 total completion tokens, [2.13] as latencies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided documents, it seems that the primary focus is on ray tracing and GPU capabilities rather than the concept of a video game as a whole. However, I'll attempt to provide a brief answer within the 750-token limit.\n",
      "\n",
      "A video game is an interactive digital experience that allows a player to engage with a virtual environment, typically through a graphical user interface, keyboard, mouse, or other input devices. The game environment, including its graphics, sound, and gameplay mechanics, is usually created using a combination of programming languages, graphics software, and game engines.\n",
      "\n",
      "While the provided documents don't directly discuss video games, they do touch on GPU capabilities, such as ray tracing, which is a technique used in some video games for rendering realistic graphics. If you have specific questions about game development, I can try to provide more information or direct you to relevant resources.\n"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain_nvidia_ai_endpoints import NVIDIARerank\n",
    "from nemoguardrails import LLMRails, RailsConfig\n",
    "\n",
    "# Initialize the reranker (NVIDIA reranker)\n",
    "compressor = NVIDIARerank(model=\"nvidia/nv-rerankqa-mistral-4b-v3\", base_url=\"http://localhost:11737/v1\")\n",
    "\n",
    "# Define the Contextual Compression Retriever\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=docsearch.as_retriever()  # Make sure 'docsearch' is defined elsewhere\n",
    ")\n",
    "\n",
    "# Initialize NeMo Guardrails\n",
    "config = RailsConfig.from_path(\"./config\")\n",
    "rails = LLMRails(config)\n",
    "\n",
    "# This function reranks the query results and generates a response using NeMo Guardrails\n",
    "def rerank_and_generate_response(user_query: str):\n",
    "    # Perform reranking using NVIDIA reranker\n",
    "    documents = compression_retriever.get_relevant_documents(user_query)\n",
    "    context_str = \"\\n\".join([doc.page_content for doc in documents])\n",
    "\n",
    "    # Generate a prompt for the assistant using the reranked documents\n",
    "    prompt = f\"\"\"\n",
    "    You are an assistant that answers queries using CUDA-related knowledge.\n",
    "    Based on the following relevant documents, answer the user's query.\n",
    "    \n",
    "    Relevant Documents:\n",
    "    {context_str}\n",
    "\n",
    "    User Query: {user_query}\n",
    "    \n",
    "    Answer:\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate response using NeMo Guardrails\n",
    "    response = rails.generate(messages=[\n",
    "        {\"role\": \"user\", \"content\": user_query},\n",
    "        {\"role\": \"assistant\", \"content\": prompt}\n",
    "    ])\n",
    "\n",
    "    return response['content']\n",
    "\n",
    "\n",
    "# Example usage\n",
    "def main():\n",
    "    user_query = \"Can you explain video game?\"\n",
    "    result = rerank_and_generate_response(user_query)\n",
    "    print(result)\n",
    "\n",
    "\n",
    "# Run the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "5845ade2-82a6-4d27-ad9a-38e1e40b144c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nemoguardrails.rails.llm.config:Deprecation Warning: Output parser is not registered for the task. The correct way is to register the 'output_parser' in the prompts.yml for 'self_check_input' task. It uses 'is_content safe' as the default output parser.This behavior will be deprecated in future versions.\n",
      "INFO:nemoguardrails.rails.llm.config:Deprecation Warning: Output parser is not registered for the task. The correct way is to register the 'output_parser' in the prompts.yml for 'self_check_output' task. It uses 'is_content safe' as the default output parser.This behavior will be deprecated in future versions.\n",
      "INFO:nemoguardrails.rails.llm.config:Deprecation Warning: Output parser is not registered for the task. The correct way is to register the 'output_parser' in the prompts.yml for 'self_check_input' task. It uses 'is_content safe' as the default output parser.This behavior will be deprecated in future versions.\n",
      "INFO:nemoguardrails.rails.llm.config:Deprecation Warning: Output parser is not registered for the task. The correct way is to register the 'output_parser' in the prompts.yml for 'self_check_output' task. It uses 'is_content safe' as the default output parser.This behavior will be deprecated in future versions.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/cleanlab/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/cleanlab/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/sensitive_data_detection/flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/sensitive_data_detection/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/autoalign/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/autoalign/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/gotitai/flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/gotitai/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/llama_guard/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/llama_guard/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/content_safety/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/content_safety/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/hallucination/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/hallucination/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/jailbreak_detection/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/jailbreak_detection/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/patronusai/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/patronusai/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/factchecking/align_score/flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/factchecking/align_score/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/self_check/facts/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/self_check/facts/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/self_check/input_check/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/self_check/input_check/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/self_check/output_check/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/self_check/output_check/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/activefence/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/activefence/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/gcp_moderate_text/flows.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.co\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Initializing action dispatcher\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file core.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added create_event to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file retrieve_relevant_chunks.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added retrieve_relevant_chunks to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file math.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added wolfram alpha request to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file action_dispatcher.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file summarize_document.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added summarize_document to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file generation.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file base.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file filter_secrets.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file utils.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file generation.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file safetools.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added call cleanlab api to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added detect_sensitive_data to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added mask_sensitive_data to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added autoalign_factcheck_output_api to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added autoalign_input_api to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added autoalign_output_api to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added call gotitai truthchecker api to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added llama_guard_check_input to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added llama_guard_check_output to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added content_safety_check_input to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added content_safety_check_output to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added self_check_hallucination to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added jailbreak_detection_heuristics to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added patronus_lynx_check_output_hallucination to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added alignscore_check_facts to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added alignscore request to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added self_check_facts to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added self_check_facts to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added self_check_input to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added self_check_output to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added call activefence api to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added call gcpnlp api to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Registered Actions :: ['alignscore request', 'alignscore_check_facts', 'autoalign_factcheck_output_api', 'autoalign_input_api', 'autoalign_output_api', 'call activefence api', 'call cleanlab api', 'call gcpnlp api', 'call gotitai truthchecker api', 'content_safety_check_input', 'content_safety_check_output', 'create_event', 'detect_sensitive_data', 'jailbreak_detection_heuristics', 'llama_guard_check_input', 'llama_guard_check_output', 'mask_sensitive_data', 'patronus_lynx_check_output_hallucination', 'retrieve_relevant_chunks', 'self_check_facts', 'self_check_hallucination', 'self_check_input', 'self_check_output', 'summarize_document', 'wolfram alpha request']\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Action dispatcher initialized\n",
      "DEBUG:asyncio:Using selector: EpollSelector\n",
      "DEBUG:asyncio:Using selector: EpollSelector\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 0.0.0.0:11022\n",
      "DEBUG:urllib3.connectionpool:http://0.0.0.0:11022 \"POST /v1/embeddings HTTP/11\" 200 19393\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): localhost:11737\n",
      "DEBUG:urllib3.connectionpool:http://localhost:11737 \"POST /v1/ranking HTTP/11\" 200 134\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Processing event: {'type': 'UtteranceBotActionFinished', 'uid': '4da9f1eb-6f4e-4208-925d-092031cc8c6e', 'event_created_at': '2024-10-10T08:51:15.572257+00:00', 'source_uid': 'NeMoGuardrails', 'final_script': \"\\n    You are an assistant that answers queries using CUDA-related knowledge.\\n    Based on the following relevant documents, answer the user's query.\\n    \\n    Relevant Documents (Top 3): \\n    ∕∕Async launch has access to the user objects\\ncudaGraphExecDestroy(graphExec);\\n∕∕Launch is not synchronized; the release\\n∕∕will be deferred if needed\\ncudaStreamSynchronize(0);\\n∕∕After the launch is synchronized, the remaining\\n∕∕reference is released and the destructor will\\n∕∕execute. Note this happens asynchronously.\\n∕∕If the destructor callback had signaled a synchronization object, it would\\n∕∕be safe to wait on it at this point.\\n∕∕Async launch has access to the user objects\\ncudaGraphExecDestroy(graphExec);\\n∕∕Launch is not synchronized; the release\\n∕∕will be deferred if needed\\ncudaStreamSynchronize(0);\\n∕∕After the launch is synchronized, the remaining\\n∕∕reference is released and the destructor will\\n∕∕execute. Note this happens asynchronously.\\n∕∕If the destructor callback had signaled a synchronization object, it would\\n∕∕be safe to wait on it at this point.\\n∕∕Async launch has access to the user objects\\ncudaGraphExecDestroy(graphExec);\\n∕∕Launch is not synchronized; the release\\n∕∕will be deferred if needed\\ncudaStreamSynchronize(0);\\n∕∕After the launch is synchronized, the remaining\\n∕∕reference is released and the destructor will\\n∕∕execute. Note this happens asynchronously.\\n∕∕If the de  # Ensuring the context doesn't exceed 1200 tokens\\n\\n    User Query: How does CUDA manage references to user objects when a cudaGraphExec_t is destroyed without being synchronized?\\n    \\n    Answer (Max 750 tokens):\\n    \", 'is_success': True, 'action_uid': '87167bd8-b9c0-4bd4-80ce-e17019d79a5d', 'action_info_modality': 'bot_speech', 'action_info_modality_policy': 'replace', 'action_finished_at': '2024-10-10T08:51:15.572262+00:00'}\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Event :: UtteranceBotActionFinished {'uid': '4da9f1eb-6f4e-4208-925d-092031cc8c6e', 'event_created_at': '2024-10-10T08:51:15.572257+00:00', 'source_uid': 'NeMoGuardrails', 'final_script': \"\\n    You are an assistant that answers queries using CUDA-related knowledge.\\n    Based on the following relevant documents, answer the user's query.\\n    \\n    Relevant Documents (Top 3): \\n    ∕∕Async launch has access to the user objects\\ncudaGraphExecDestroy(graphExec);\\n∕∕Launch is not synchronized; the release\\n∕∕will be deferred if needed\\ncudaStreamSynchronize(0);\\n∕∕After the launch is synchronized, the remaining\\n∕∕reference is released and the destructor will\\n∕∕execute. Note this happens asynchronously.\\n∕∕If the destructor callback had signaled a synchronization object, it would\\n∕∕be safe to wait on it at this point.\\n∕∕Async launch has access to the user objects\\ncudaGraphExecDestroy(graphExec);\\n∕∕Launch is not synchronized; the release\\n∕∕will be deferred if needed\\ncudaStreamSynchronize(0);\\n∕∕After the launch is synchronized, the remaining\\n∕∕reference is released and the destructor will\\n∕∕execute. Note this happens asynchronously.\\n∕∕If the destructor callback had signaled a synchronization object, it would\\n∕∕be safe to wait on it at this point.\\n∕∕Async launch has access to the user objects\\ncudaGraphExecDestroy(graphExec);\\n∕∕Launch is not synchronized; the release\\n∕∕will be deferred if needed\\ncudaStreamSynchronize(0);\\n∕∕After the launch is synchronized, the remaining\\n∕∕reference is released and the destructor will\\n∕∕execute. Note this happens asynchronously.\\n∕∕If the de  # Ensuring the context doesn't exceed 1200 tokens\\n\\n    User Query: How does CUDA manage references to user objects when a cudaGraphExec_t is destroyed without being synchronized?\\n    \\n    Answer (Max 750 tokens):\\n    \", 'is_success': True, 'action_uid': '87167bd8-b9c0-4bd4-80ce-e17019d79a5d', 'action_info_modality': 'bot_speech', 'action_info_modality_policy': 'replace', 'action_finished_at': '2024-10-10T08:51:15.572262+00:00'}\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Processing event: {'type': 'StartInternalSystemAction', 'uid': '9d79bf56-280b-4e2f-b46f-2505c5d71161', 'event_created_at': '2024-10-10T08:51:15.573450+00:00', 'source_uid': 'NeMoGuardrails', 'action_name': 'generate_user_intent', 'action_params': {}, 'action_result_key': None, 'action_uid': '8a3a07e6-00e0-47fa-8795-0b7dfce1a470', 'is_system_action': True}\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Event :: StartInternalSystemAction {'uid': '9d79bf56-280b-4e2f-b46f-2505c5d71161', 'event_created_at': '2024-10-10T08:51:15.573450+00:00', 'source_uid': 'NeMoGuardrails', 'action_name': 'generate_user_intent', 'action_params': {}, 'action_result_key': None, 'action_uid': '8a3a07e6-00e0-47fa-8795-0b7dfce1a470', 'is_system_action': True}\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Executing action :: generate_user_intent\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Executing registered action: generate_user_intent\n",
      "INFO:nemoguardrails.logging.callbacks:Invocation Params :: {'_type': 'chat-nvidia-ai-playground', 'stop': ['User:']}\n",
      "INFO:nemoguardrails.logging.callbacks:Prompt Messages :: \n",
      "[cyan]System[/]\n",
      "Below is a conversation between a user and an AI assistant specialized in CUDA programming-based tasks such as code analysis, code comprehension, debugging, and precise query answering.\n",
      "The assistant is knowledgeable about CUDA programming, its documentation, and best practices.\n",
      "If the assistant does not know the answer to a question, it will try to find relevant information and let the user know it doesn't have the complete answer.\n",
      "\n",
      "[cyan]User[/]\n",
      "How does CUDA manage references to user objects when a cudaGraphExec_t is destroyed without being synchronized?\n",
      "[cyan]Bot[/]\n",
      "\n",
      "    You are an assistant that answers queries using CUDA-related knowledge.\n",
      "    Based on the following relevant documents, answer the user's query.\n",
      "    \n",
      "    Relevant Documents (Top 3): \n",
      "    ∕∕Async launch has access to the user objects\n",
      "cudaGraphExecDestroy(graphExec);\n",
      "∕∕Launch is not synchronized; the release\n",
      "∕∕will be deferred if needed\n",
      "cudaStreamSynchronize(0);\n",
      "∕∕After the launch is synchronized, the remaining\n",
      "∕∕reference is released and the destructor will\n",
      "∕∕execute. Note this happens asynchronously.\n",
      "∕∕If the destructor callback had signaled a synchronization object, it would\n",
      "∕∕be safe to wait on it at this point.\n",
      "∕∕Async launch has access to the user objects\n",
      "cudaGraphExecDestroy(graphExec);\n",
      "∕∕Launch is not synchronized; the release\n",
      "∕∕will be deferred if needed\n",
      "cudaStreamSynchronize(0);\n",
      "∕∕After the launch is synchronized, the remaining\n",
      "∕∕reference is released and the destructor will\n",
      "∕∕execute. Note this happens asynchronously.\n",
      "∕∕If the destructor callback had signaled a synchronization object, it would\n",
      "∕∕be safe to wait on it at this point.\n",
      "∕∕Async launch has access to the user objects\n",
      "cudaGraphExecDestroy(graphExec);\n",
      "∕∕Launch is not synchronized; the release\n",
      "∕∕will be deferred if needed\n",
      "cudaStreamSynchronize(0);\n",
      "∕∕After the launch is synchronized, the remaining\n",
      "∕∕reference is released and the destructor will\n",
      "∕∕execute. Note this happens asynchronously.\n",
      "∕∕If the de  # Ensuring the context doesn't exceed 1200 tokens\n",
      "\n",
      "    User Query: How does CUDA manage references to user objects when a cudaGraphExec_t is destroyed without being synchronized?\n",
      "    \n",
      "    Answer (Max 750 tokens):\n",
      "    \n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 0.0.0.0:8000\n",
      "DEBUG:urllib3.connectionpool:http://0.0.0.0:8000 \"POST /v1/chat/completions HTTP/11\" 200 1671\n",
      "INFO:nemoguardrails.logging.callbacks:Completion :: When a `cudaGraphExec_t` is destroyed without being synchronized, CUDA manages references to user objects by deferring the release of the object's memory until the launch is synchronized.\n",
      "\n",
      "According to the CUDA documentation, when `cudaGraphExecDestroy` is called without synchronization, the release of the referenced user objects is deferred until the graph execution is synchronized. This means that as long as the graph is executing, the user objects are still accessible.\n",
      "\n",
      "However, once the graph is synchronized, which happens after calling `cudaStreamSynchronize(0)`, the remaining reference to the user objects is released, and the destructor is executed. This happens asynchronously, which means that the destructor will be called after the synchronization point.\n",
      "\n",
      "It's worth noting that if the destructor callback had signaled a synchronization object, it would be safe to wait on it at this point. This suggests that the CUDA API provides a way to handle synchronization and lifetime management of user objects in a coordinated manner, even in the case of asynchronous graph execution and destruction.\n",
      "\n",
      "In summary, CUDA manages references to user objects by deferring their release until the graph execution is synchronized, at which point the remaining reference is released and the destructor is executed asynchronously.\n",
      "INFO:nemoguardrails.logging.callbacks:Output Stats :: {'role': 'assistant', 'content': \"When a `cudaGraphExec_t` is destroyed without being synchronized, CUDA manages references to user objects by deferring the release of the object's memory until the launch is synchronized.\\n\\nAccording to the CUDA documentation, when `cudaGraphExecDestroy` is called without synchronization, the release of the referenced user objects is deferred until the graph execution is synchronized. This means that as long as the graph is executing, the user objects are still accessible.\\n\\nHowever, once the graph is synchronized, which happens after calling `cudaStreamSynchronize(0)`, the remaining reference to the user objects is released, and the destructor is executed. This happens asynchronously, which means that the destructor will be called after the synchronization point.\\n\\nIt's worth noting that if the destructor callback had signaled a synchronization object, it would be safe to wait on it at this point. This suggests that the CUDA API provides a way to handle synchronization and lifetime management of user objects in a coordinated manner, even in the case of asynchronous graph execution and destruction.\\n\\nIn summary, CUDA manages references to user objects by deferring their release until the graph execution is synchronized, at which point the remaining reference is released and the destructor is executed asynchronously.\", 'token_usage': {'prompt_tokens': 529, 'total_tokens': 768, 'completion_tokens': 239}, 'finish_reason': 'stop', 'model_name': 'meta/llama-3.1-8b-instruct'}\n",
      "INFO:nemoguardrails.logging.callbacks:--- :: LLM call took 2.88 seconds\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Processing event: {'type': 'BotMessage', 'uid': '9bdad2f2-1e73-47eb-b63f-52a3f0f381d1', 'event_created_at': '2024-10-10T08:51:18.459119+00:00', 'source_uid': 'NeMoGuardrails', 'text': \"When a `cudaGraphExec_t` is destroyed without being synchronized, CUDA manages references to user objects by deferring the release of the object's memory until the launch is synchronized.\\n\\nAccording to the CUDA documentation, when `cudaGraphExecDestroy` is called without synchronization, the release of the referenced user objects is deferred until the graph execution is synchronized. This means that as long as the graph is executing, the user objects are still accessible.\\n\\nHowever, once the graph is synchronized, which happens after calling `cudaStreamSynchronize(0)`, the remaining reference to the user objects is released, and the destructor is executed. This happens asynchronously, which means that the destructor will be called after the synchronization point.\\n\\nIt's worth noting that if the destructor callback had signaled a synchronization object, it would be safe to wait on it at this point. This suggests that the CUDA API provides a way to handle synchronization and lifetime management of user objects in a coordinated manner, even in the case of asynchronous graph execution and destruction.\\n\\nIn summary, CUDA manages references to user objects by deferring their release until the graph execution is synchronized, at which point the remaining reference is released and the destructor is executed asynchronously.\"}\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Event :: BotMessage {'uid': '9bdad2f2-1e73-47eb-b63f-52a3f0f381d1', 'event_created_at': '2024-10-10T08:51:18.459119+00:00', 'source_uid': 'NeMoGuardrails', 'text': \"When a `cudaGraphExec_t` is destroyed without being synchronized, CUDA manages references to user objects by deferring the release of the object's memory until the launch is synchronized.\\n\\nAccording to the CUDA documentation, when `cudaGraphExecDestroy` is called without synchronization, the release of the referenced user objects is deferred until the graph execution is synchronized. This means that as long as the graph is executing, the user objects are still accessible.\\n\\nHowever, once the graph is synchronized, which happens after calling `cudaStreamSynchronize(0)`, the remaining reference to the user objects is released, and the destructor is executed. This happens asynchronously, which means that the destructor will be called after the synchronization point.\\n\\nIt's worth noting that if the destructor callback had signaled a synchronization object, it would be safe to wait on it at this point. This suggests that the CUDA API provides a way to handle synchronization and lifetime management of user objects in a coordinated manner, even in the case of asynchronous graph execution and destruction.\\n\\nIn summary, CUDA manages references to user objects by deferring their release until the graph execution is synchronized, at which point the remaining reference is released and the destructor is executed asynchronously.\"}\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Processing event: {'type': 'StartInternalSystemAction', 'uid': '4951ab96-de04-4d6c-b08d-57eff653eb7a', 'event_created_at': '2024-10-10T08:51:18.460592+00:00', 'source_uid': 'NeMoGuardrails', 'action_name': 'create_event', 'action_params': {'event': {'_type': 'StartUtteranceBotAction', 'script': '$bot_message'}}, 'action_result_key': None, 'action_uid': '0c28ccd9-5cc4-4177-b922-9a9429cdc828', 'is_system_action': True}\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Event :: StartInternalSystemAction {'uid': '4951ab96-de04-4d6c-b08d-57eff653eb7a', 'event_created_at': '2024-10-10T08:51:18.460592+00:00', 'source_uid': 'NeMoGuardrails', 'action_name': 'create_event', 'action_params': {'event': {'_type': 'StartUtteranceBotAction', 'script': '$bot_message'}}, 'action_result_key': None, 'action_uid': '0c28ccd9-5cc4-4177-b922-9a9429cdc828', 'is_system_action': True}\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Executing action :: create_event\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Executing registered action: create_event\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Processing event: {'type': 'StartUtteranceBotAction', 'uid': 'a3301637-289b-4a65-bf46-0663ffe79a4c', 'event_created_at': '2024-10-10T08:51:18.461933+00:00', 'source_uid': 'NeMoGuardrails', 'script': \"When a `cudaGraphExec_t` is destroyed without being synchronized, CUDA manages references to user objects by deferring the release of the object's memory until the launch is synchronized.\\n\\nAccording to the CUDA documentation, when `cudaGraphExecDestroy` is called without synchronization, the release of the referenced user objects is deferred until the graph execution is synchronized. This means that as long as the graph is executing, the user objects are still accessible.\\n\\nHowever, once the graph is synchronized, which happens after calling `cudaStreamSynchronize(0)`, the remaining reference to the user objects is released, and the destructor is executed. This happens asynchronously, which means that the destructor will be called after the synchronization point.\\n\\nIt's worth noting that if the destructor callback had signaled a synchronization object, it would be safe to wait on it at this point. This suggests that the CUDA API provides a way to handle synchronization and lifetime management of user objects in a coordinated manner, even in the case of asynchronous graph execution and destruction.\\n\\nIn summary, CUDA manages references to user objects by deferring their release until the graph execution is synchronized, at which point the remaining reference is released and the destructor is executed asynchronously.\", 'action_info_modality': 'bot_speech', 'action_info_modality_policy': 'replace', 'action_uid': 'f7f5ab82-3ad2-48d4-80d6-333cb3c643bd'}\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Event :: StartUtteranceBotAction {'uid': 'a3301637-289b-4a65-bf46-0663ffe79a4c', 'event_created_at': '2024-10-10T08:51:18.461933+00:00', 'source_uid': 'NeMoGuardrails', 'script': \"When a `cudaGraphExec_t` is destroyed without being synchronized, CUDA manages references to user objects by deferring the release of the object's memory until the launch is synchronized.\\n\\nAccording to the CUDA documentation, when `cudaGraphExecDestroy` is called without synchronization, the release of the referenced user objects is deferred until the graph execution is synchronized. This means that as long as the graph is executing, the user objects are still accessible.\\n\\nHowever, once the graph is synchronized, which happens after calling `cudaStreamSynchronize(0)`, the remaining reference to the user objects is released, and the destructor is executed. This happens asynchronously, which means that the destructor will be called after the synchronization point.\\n\\nIt's worth noting that if the destructor callback had signaled a synchronization object, it would be safe to wait on it at this point. This suggests that the CUDA API provides a way to handle synchronization and lifetime management of user objects in a coordinated manner, even in the case of asynchronous graph execution and destruction.\\n\\nIn summary, CUDA manages references to user objects by deferring their release until the graph execution is synchronized, at which point the remaining reference is released and the destructor is executed asynchronously.\", 'action_info_modality': 'bot_speech', 'action_info_modality_policy': 'replace', 'action_uid': 'f7f5ab82-3ad2-48d4-80d6-333cb3c643bd'}\n",
      "INFO:nemoguardrails.rails.llm.llmrails:--- :: Total processing took 2.89 seconds. LLM Stats: 1 total calls, 2.88 total time, 768 total tokens, 529 total prompt tokens, 239 total completion tokens, [2.88] as latencies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer': \"When a `cudaGraphExec_t` is destroyed without being synchronized, CUDA manages references to user objects by deferring the release of the object's memory until the launch is synchronized.\\n\\nAccording to the CUDA documentation, when `cudaGraphExecDestroy` is called without synchronization, the release of the referenced user objects is deferred until the graph execution is synchronized. This means that as long as the graph is executing, the user objects are still accessible.\\n\\nHowever, once the graph is synchronized, which happens after calling `cudaStreamSynchronize(0)`, the remaining reference to the user objects is released, and the destructor is executed. This happens asynchronously, which means that the destructor will be called after the \", 'contexts': '∕∕Async launch has access to the user objects\\ncudaGraphExecDestroy(graphExec);\\n∕∕Launch is not synchronized; the release\\n∕∕will be deferred if needed\\ncudaStreamSynchronize(0);\\n∕∕After the launch is synchronized, the remaining\\n∕∕reference is released and the destructor will\\n∕∕execute. Note this happens asynchronously.\\n∕∕If the destructor callback had signaled a synchronization object, it would\\n∕∕be safe to wait on it at this point.\\n∕∕Async launch has access to the user objects\\ncudaGraphExecDestroy(graphExec);\\n∕∕Launch is not synchronized; the release\\n∕∕will be deferred if needed\\ncudaStreamSynchronize(0);\\n∕∕After the launch is synchronized, the remaining\\n∕∕reference is released and the destructor will\\n∕∕execute. Note this happens asynchronously.\\n∕∕If the destructor callback had signaled a synchronization object, it would\\n∕∕be safe to wait on it at this point.\\n∕∕Async launch has access to the user objects\\ncudaGraphExecDestroy(graphExec);\\n∕∕Launch is not synchronized; the release\\n∕∕will be deferred if needed\\ncudaStreamSynchronize(0);\\n∕∕After the launch is synchronized, the remaining\\n∕∕reference is released and the destructor will\\n∕∕execute. Note this happens asynchronously.\\n∕∕If the de'}\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'LLMRails' object has no attribute 'reset_session'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[181], line 75\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m# Run the main function\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 75\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[181], line 71\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m complete_endpoint(user_query)\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# Simulate the /reset endpoint\u001b[39;00m\n\u001b[0;32m---> 71\u001b[0m \u001b[43mreset_endpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[181], line 61\u001b[0m, in \u001b[0;36mreset_endpoint\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreset_endpoint\u001b[39m():\n\u001b[0;32m---> 61\u001b[0m     reset_status \u001b[38;5;241m=\u001b[39m \u001b[43mreset_conversation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28mprint\u001b[39m(reset_status)\n",
      "Cell \u001b[0;32mIn[181], line 52\u001b[0m, in \u001b[0;36mreset_conversation\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreset_conversation\u001b[39m():\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;66;03m# Clear any session or stored history in NeMo Guardrails\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m     \u001b[43mrails\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset_session\u001b[49m()\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversation reset successfully.\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LLMRails' object has no attribute 'reset_session'"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain_nvidia_ai_endpoints import NVIDIARerank\n",
    "from nemoguardrails import LLMRails, RailsConfig\n",
    "\n",
    "# Initialize the reranker (NVIDIA reranker)\n",
    "compressor = NVIDIARerank(model=\"nvidia/nv-rerankqa-mistral-4b-v3\", base_url=\"http://localhost:11737/v1\")\n",
    "\n",
    "# Define the Contextual Compression Retriever\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=docsearch.as_retriever()  # Ensure 'docsearch' is defined earlier in your code\n",
    ")\n",
    "\n",
    "# Initialize NeMo Guardrails\n",
    "config = RailsConfig.from_path(\"./config\")\n",
    "rails = LLMRails(config)\n",
    "\n",
    "# Function to rerank query results and generate response for the /complete endpoint\n",
    "def rerank_and_generate_response(user_query: str):\n",
    "    # Perform reranking using NVIDIA reranker\n",
    "    documents = compression_retriever.get_relevant_documents(user_query)\n",
    "    context_str = \"\\n\".join([doc.page_content for doc in documents])\n",
    "\n",
    "    # Generate a prompt for the assistant using the reranked documents\n",
    "    prompt = f\"\"\"\n",
    "    You are an assistant that answers queries using CUDA-related knowledge.\n",
    "    Based on the following relevant documents, answer the user's query.\n",
    "    \n",
    "    Relevant Documents (Top 3): \n",
    "    {context_str[:1200]}  # Ensuring the context doesn't exceed 1200 tokens\n",
    "\n",
    "    User Query: {user_query}\n",
    "    \n",
    "    Answer (Max 750 tokens):\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate response using NeMo Guardrails\n",
    "    response = rails.generate(messages=[\n",
    "        {\"role\": \"user\", \"content\": user_query},\n",
    "        {\"role\": \"assistant\", \"content\": prompt}\n",
    "    ])\n",
    "\n",
    "    # Return the assistant's response and the context used\n",
    "    return {\n",
    "        \"answer\": response['content'][:750],  # Ensuring answer doesn't exceed 750 tokens\n",
    "        \"contexts\": context_str[:1200]  # Ensuring contexts don't exceed 1200 tokens\n",
    "    }\n",
    "\n",
    "# Function to reset the session for the /reset endpoint\n",
    "def reset_conversation():\n",
    "    # Clear any session or stored history in NeMo Guardrails\n",
    "    rails.reset_session()\n",
    "    return {\"status\": \"Conversation reset successfully.\"}\n",
    "\n",
    "# Example usage for /complete and /reset endpoints\n",
    "def complete_endpoint(user_query: str):\n",
    "    result = rerank_and_generate_response(user_query)\n",
    "    print(result)\n",
    "\n",
    "def reset_endpoint():\n",
    "    reset_status = reset_conversation()\n",
    "    print(reset_status)\n",
    "\n",
    "# Main function to demonstrate the endpoints\n",
    "def main():\n",
    "    # Simulate the /complete endpoint\n",
    "    user_query = \"How does CUDA manage references to user objects when a cudaGraphExec_t is destroyed without being synchronized?\"\n",
    "    complete_endpoint(user_query)\n",
    "\n",
    "    # Simulate the /reset endpoint\n",
    "    reset_endpoint()\n",
    "\n",
    "# Run the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "3a098c0f-900b-41a3-841a-14050779a4ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/cleanlab/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/cleanlab/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/sensitive_data_detection/flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/sensitive_data_detection/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/autoalign/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/autoalign/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/gotitai/flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/gotitai/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/llama_guard/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/llama_guard/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/content_safety/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/content_safety/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/hallucination/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/hallucination/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/jailbreak_detection/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/jailbreak_detection/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/patronusai/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/patronusai/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/factchecking/align_score/flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/factchecking/align_score/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/self_check/facts/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/self_check/facts/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/self_check/input_check/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/self_check/input_check/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/self_check/output_check/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/self_check/output_check/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/activefence/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/activefence/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/gcp_moderate_text/flows.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.co\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Initializing action dispatcher\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file core.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added create_event to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file retrieve_relevant_chunks.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added retrieve_relevant_chunks to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file math.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added wolfram alpha request to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file action_dispatcher.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file summarize_document.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added summarize_document to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file generation.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file base.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file filter_secrets.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file utils.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file generation.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file safetools.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added call cleanlab api to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added detect_sensitive_data to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added mask_sensitive_data to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added autoalign_factcheck_output_api to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added autoalign_input_api to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added autoalign_output_api to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added call gotitai truthchecker api to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added llama_guard_check_input to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added llama_guard_check_output to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added content_safety_check_input to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added content_safety_check_output to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added self_check_hallucination to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added jailbreak_detection_heuristics to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added patronus_lynx_check_output_hallucination to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added alignscore_check_facts to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added alignscore request to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added self_check_facts to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added self_check_facts to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added self_check_input to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added self_check_output to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added call activefence api to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added call gcpnlp api to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Registered Actions :: ['alignscore request', 'alignscore_check_facts', 'autoalign_factcheck_output_api', 'autoalign_input_api', 'autoalign_output_api', 'call activefence api', 'call cleanlab api', 'call gcpnlp api', 'call gotitai truthchecker api', 'content_safety_check_input', 'content_safety_check_output', 'create_event', 'detect_sensitive_data', 'jailbreak_detection_heuristics', 'llama_guard_check_input', 'llama_guard_check_output', 'mask_sensitive_data', 'patronus_lynx_check_output_hallucination', 'retrieve_relevant_chunks', 'self_check_facts', 'self_check_hallucination', 'self_check_input', 'self_check_output', 'summarize_document', 'wolfram alpha request']\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Action dispatcher initialized\n",
      "DEBUG:asyncio:Using selector: EpollSelector\n",
      "DEBUG:asyncio:Using selector: EpollSelector\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 0.0.0.0:11022\n",
      "DEBUG:urllib3.connectionpool:http://0.0.0.0:11022 \"POST /v1/embeddings HTTP/11\" 200 19393\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): localhost:11737\n",
      "DEBUG:urllib3.connectionpool:http://localhost:11737 \"POST /v1/ranking HTTP/11\" 200 134\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Processing event: {'type': 'UtteranceBotActionFinished', 'uid': '3e1d048c-2ee5-4a6d-856f-31bacea7e3fc', 'event_created_at': '2024-10-10T11:55:15.601859+00:00', 'source_uid': 'NeMoGuardrails', 'final_script': \"\\n    You are an assistant that answers queries using CUDA-related knowledge.\\n    Based on the following relevant documents, answer the user's query.\\n    \\n    Relevant Documents (Top 3): \\n    ∕∕Async launch has access to the user objects\\ncudaGraphExecDestroy(graphExec);\\n∕∕Launch is not synchronized; the release\\n∕∕will be deferred if needed\\ncudaStreamSynchronize(0);\\n∕∕After the launch is synchronized, the remaining\\n∕∕reference is released and the destructor will\\n∕∕execute. Note this happens asynchronously.\\n∕∕If the destructor callback had signaled a synchronization object, it would\\n∕∕be safe to wait on it at this point.\\n∕∕Async launch has access to the user objects\\ncudaGraphExecDestroy(graphExec);\\n∕∕Launch is not synchronized; the release\\n∕∕will be deferred if needed\\ncudaStreamSynchronize(0);\\n∕∕After the launch is synchronized, the remaining\\n∕∕reference is released and the destructor will\\n∕∕execute. Note this happens asynchronously.\\n∕∕If the destructor callback had signaled a synchronization object, it would\\n∕∕be safe to wait on it at this point.\\n∕∕Async launch has access to the user objects\\ncudaGraphExecDestroy(graphExec);\\n∕∕Launch is not synchronized; the release\\n∕∕will be deferred if needed\\ncudaStreamSynchronize(0);\\n∕∕After the launch is synchronized, the remaining\\n∕∕reference is released and the destructor will\\n∕∕execute. Note this happens asynchronously.\\n∕∕If the de  # Ensuring the context doesn't exceed 1200 tokens\\n\\n    User Query: How does CUDA manage references to user objects when a cudaGraphExec_t is destroyed without being synchronized?\\n    \\n    Answer (Max 750 tokens):\\n    \", 'is_success': True, 'action_uid': '29c172b1-9a87-485a-9926-fdac9316d15d', 'action_info_modality': 'bot_speech', 'action_info_modality_policy': 'replace', 'action_finished_at': '2024-10-10T11:55:15.601865+00:00'}\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Event :: UtteranceBotActionFinished {'uid': '3e1d048c-2ee5-4a6d-856f-31bacea7e3fc', 'event_created_at': '2024-10-10T11:55:15.601859+00:00', 'source_uid': 'NeMoGuardrails', 'final_script': \"\\n    You are an assistant that answers queries using CUDA-related knowledge.\\n    Based on the following relevant documents, answer the user's query.\\n    \\n    Relevant Documents (Top 3): \\n    ∕∕Async launch has access to the user objects\\ncudaGraphExecDestroy(graphExec);\\n∕∕Launch is not synchronized; the release\\n∕∕will be deferred if needed\\ncudaStreamSynchronize(0);\\n∕∕After the launch is synchronized, the remaining\\n∕∕reference is released and the destructor will\\n∕∕execute. Note this happens asynchronously.\\n∕∕If the destructor callback had signaled a synchronization object, it would\\n∕∕be safe to wait on it at this point.\\n∕∕Async launch has access to the user objects\\ncudaGraphExecDestroy(graphExec);\\n∕∕Launch is not synchronized; the release\\n∕∕will be deferred if needed\\ncudaStreamSynchronize(0);\\n∕∕After the launch is synchronized, the remaining\\n∕∕reference is released and the destructor will\\n∕∕execute. Note this happens asynchronously.\\n∕∕If the destructor callback had signaled a synchronization object, it would\\n∕∕be safe to wait on it at this point.\\n∕∕Async launch has access to the user objects\\ncudaGraphExecDestroy(graphExec);\\n∕∕Launch is not synchronized; the release\\n∕∕will be deferred if needed\\ncudaStreamSynchronize(0);\\n∕∕After the launch is synchronized, the remaining\\n∕∕reference is released and the destructor will\\n∕∕execute. Note this happens asynchronously.\\n∕∕If the de  # Ensuring the context doesn't exceed 1200 tokens\\n\\n    User Query: How does CUDA manage references to user objects when a cudaGraphExec_t is destroyed without being synchronized?\\n    \\n    Answer (Max 750 tokens):\\n    \", 'is_success': True, 'action_uid': '29c172b1-9a87-485a-9926-fdac9316d15d', 'action_info_modality': 'bot_speech', 'action_info_modality_policy': 'replace', 'action_finished_at': '2024-10-10T11:55:15.601865+00:00'}\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Processing event: {'type': 'StartInternalSystemAction', 'uid': '86b523fb-3623-44d3-bc43-322a5809a56c', 'event_created_at': '2024-10-10T11:55:15.602991+00:00', 'source_uid': 'NeMoGuardrails', 'action_name': 'generate_user_intent', 'action_params': {}, 'action_result_key': None, 'action_uid': '784ba62b-5814-4ec4-804f-ce0d2ff3bf0c', 'is_system_action': True}\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Event :: StartInternalSystemAction {'uid': '86b523fb-3623-44d3-bc43-322a5809a56c', 'event_created_at': '2024-10-10T11:55:15.602991+00:00', 'source_uid': 'NeMoGuardrails', 'action_name': 'generate_user_intent', 'action_params': {}, 'action_result_key': None, 'action_uid': '784ba62b-5814-4ec4-804f-ce0d2ff3bf0c', 'is_system_action': True}\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Executing action :: generate_user_intent\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Executing registered action: generate_user_intent\n",
      "INFO:nemoguardrails.logging.callbacks:Invocation Params :: {'_type': 'chat-nvidia-ai-playground', 'stop': ['User:']}\n",
      "INFO:nemoguardrails.logging.callbacks:Prompt Messages :: \n",
      "[cyan]System[/]\n",
      "Below is a conversation between a user and an AI assistant specialized in CUDA programming-based tasks such as code analysis, code comprehension, debugging, and precise query answering.\n",
      "The assistant is knowledgeable about CUDA programming, its documentation, and best practices.\n",
      "If the assistant does not know the answer to a question, it will try to find relevant information and let the user know it doesn't have the complete answer.\n",
      "Please keep in mind the following restrictions:\n",
      "  - answer: The response shouldn’t have more than 750 tokens.\n",
      "  - context: thhe context shall not exceed more than 1200 tokens. The context is to be generated by relevant document and if turncated dont use that token.\n",
      "\n",
      "[cyan]User[/]\n",
      "How does CUDA manage references to user objects when a cudaGraphExec_t is destroyed without being synchronized?\n",
      "[cyan]Bot[/]\n",
      "\n",
      "    You are an assistant that answers queries using CUDA-related knowledge.\n",
      "    Based on the following relevant documents, answer the user's query.\n",
      "    \n",
      "    Relevant Documents (Top 3): \n",
      "    ∕∕Async launch has access to the user objects\n",
      "cudaGraphExecDestroy(graphExec);\n",
      "∕∕Launch is not synchronized; the release\n",
      "∕∕will be deferred if needed\n",
      "cudaStreamSynchronize(0);\n",
      "∕∕After the launch is synchronized, the remaining\n",
      "∕∕reference is released and the destructor will\n",
      "∕∕execute. Note this happens asynchronously.\n",
      "∕∕If the destructor callback had signaled a synchronization object, it would\n",
      "∕∕be safe to wait on it at this point.\n",
      "∕∕Async launch has access to the user objects\n",
      "cudaGraphExecDestroy(graphExec);\n",
      "∕∕Launch is not synchronized; the release\n",
      "∕∕will be deferred if needed\n",
      "cudaStreamSynchronize(0);\n",
      "∕∕After the launch is synchronized, the remaining\n",
      "∕∕reference is released and the destructor will\n",
      "∕∕execute. Note this happens asynchronously.\n",
      "∕∕If the destructor callback had signaled a synchronization object, it would\n",
      "∕∕be safe to wait on it at this point.\n",
      "∕∕Async launch has access to the user objects\n",
      "cudaGraphExecDestroy(graphExec);\n",
      "∕∕Launch is not synchronized; the release\n",
      "∕∕will be deferred if needed\n",
      "cudaStreamSynchronize(0);\n",
      "∕∕After the launch is synchronized, the remaining\n",
      "∕∕reference is released and the destructor will\n",
      "∕∕execute. Note this happens asynchronously.\n",
      "∕∕If the de  # Ensuring the context doesn't exceed 1200 tokens\n",
      "\n",
      "    User Query: How does CUDA manage references to user objects when a cudaGraphExec_t is destroyed without being synchronized?\n",
      "    \n",
      "    Answer (Max 750 tokens):\n",
      "    \n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 0.0.0.0:8000\n",
      "DEBUG:urllib3.connectionpool:http://0.0.0.0:8000 \"POST /v1/chat/completions HTTP/11\" 200 1524\n",
      "INFO:nemoguardrails.logging.callbacks:Completion :: When a `cudaGraphExec_t` is destroyed without being synchronized, CUDA manages references to user objects by deferring the release of the last reference. This means that the CUDA runtime will not immediately delete the user objects associated with the `cudaGraphExec_t` when it is destroyed.\n",
      "\n",
      "Instead, the release of the last reference to the `cudaGraphExec_t` is deferred until the CUDA stream is synchronized using `cudaStreamSynchronize(0)`. This ensures that any CUDA operations executing in the stream have a chance to complete before the destructor is executed.\n",
      "\n",
      "Once the stream is synchronized, the remaining reference to the `cudaGraphExec_t` is released, and the destructor is executed asynchronously. The destructor callback, if present, has access to the user objects associated with the `cudaGraphExec_t`. It can use this access to clean up any necessary resources before the destructor returns.\n",
      "\n",
      "If the destructor callback has signaled a synchronization object, it is safe to wait on that object until the destructor has completed its execution. This provides a way to ensure that the destruction of the `cudaGraphExec_t` is completed before proceeding with other operations.\n",
      "INFO:nemoguardrails.logging.callbacks:Output Stats :: {'role': 'assistant', 'content': 'When a `cudaGraphExec_t` is destroyed without being synchronized, CUDA manages references to user objects by deferring the release of the last reference. This means that the CUDA runtime will not immediately delete the user objects associated with the `cudaGraphExec_t` when it is destroyed.\\n\\nInstead, the release of the last reference to the `cudaGraphExec_t` is deferred until the CUDA stream is synchronized using `cudaStreamSynchronize(0)`. This ensures that any CUDA operations executing in the stream have a chance to complete before the destructor is executed.\\n\\nOnce the stream is synchronized, the remaining reference to the `cudaGraphExec_t` is released, and the destructor is executed asynchronously. The destructor callback, if present, has access to the user objects associated with the `cudaGraphExec_t`. It can use this access to clean up any necessary resources before the destructor returns.\\n\\nIf the destructor callback has signaled a synchronization object, it is safe to wait on that object until the destructor has completed its execution. This provides a way to ensure that the destruction of the `cudaGraphExec_t` is completed before proceeding with other operations.', 'token_usage': {'prompt_tokens': 588, 'total_tokens': 816, 'completion_tokens': 228}, 'finish_reason': 'stop', 'model_name': 'meta/llama-3.1-8b-instruct'}\n",
      "INFO:nemoguardrails.logging.callbacks:--- :: LLM call took 2.76 seconds\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Processing event: {'type': 'BotMessage', 'uid': 'afff4a32-3c2d-41dc-af27-8b54b2f2a67b', 'event_created_at': '2024-10-10T11:55:18.369713+00:00', 'source_uid': 'NeMoGuardrails', 'text': 'When a `cudaGraphExec_t` is destroyed without being synchronized, CUDA manages references to user objects by deferring the release of the last reference. This means that the CUDA runtime will not immediately delete the user objects associated with the `cudaGraphExec_t` when it is destroyed.\\n\\nInstead, the release of the last reference to the `cudaGraphExec_t` is deferred until the CUDA stream is synchronized using `cudaStreamSynchronize(0)`. This ensures that any CUDA operations executing in the stream have a chance to complete before the destructor is executed.\\n\\nOnce the stream is synchronized, the remaining reference to the `cudaGraphExec_t` is released, and the destructor is executed asynchronously. The destructor callback, if present, has access to the user objects associated with the `cudaGraphExec_t`. It can use this access to clean up any necessary resources before the destructor returns.\\n\\nIf the destructor callback has signaled a synchronization object, it is safe to wait on that object until the destructor has completed its execution. This provides a way to ensure that the destruction of the `cudaGraphExec_t` is completed before proceeding with other operations.'}\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Event :: BotMessage {'uid': 'afff4a32-3c2d-41dc-af27-8b54b2f2a67b', 'event_created_at': '2024-10-10T11:55:18.369713+00:00', 'source_uid': 'NeMoGuardrails', 'text': 'When a `cudaGraphExec_t` is destroyed without being synchronized, CUDA manages references to user objects by deferring the release of the last reference. This means that the CUDA runtime will not immediately delete the user objects associated with the `cudaGraphExec_t` when it is destroyed.\\n\\nInstead, the release of the last reference to the `cudaGraphExec_t` is deferred until the CUDA stream is synchronized using `cudaStreamSynchronize(0)`. This ensures that any CUDA operations executing in the stream have a chance to complete before the destructor is executed.\\n\\nOnce the stream is synchronized, the remaining reference to the `cudaGraphExec_t` is released, and the destructor is executed asynchronously. The destructor callback, if present, has access to the user objects associated with the `cudaGraphExec_t`. It can use this access to clean up any necessary resources before the destructor returns.\\n\\nIf the destructor callback has signaled a synchronization object, it is safe to wait on that object until the destructor has completed its execution. This provides a way to ensure that the destruction of the `cudaGraphExec_t` is completed before proceeding with other operations.'}\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Processing event: {'type': 'StartInternalSystemAction', 'uid': 'cee2176a-6c20-4ec1-ad6d-fcd330f333e3', 'event_created_at': '2024-10-10T11:55:18.370900+00:00', 'source_uid': 'NeMoGuardrails', 'action_name': 'create_event', 'action_params': {'event': {'_type': 'StartUtteranceBotAction', 'script': '$bot_message'}}, 'action_result_key': None, 'action_uid': '3f1971ad-f571-4b84-8c20-83e6bd82471a', 'is_system_action': True}\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Event :: StartInternalSystemAction {'uid': 'cee2176a-6c20-4ec1-ad6d-fcd330f333e3', 'event_created_at': '2024-10-10T11:55:18.370900+00:00', 'source_uid': 'NeMoGuardrails', 'action_name': 'create_event', 'action_params': {'event': {'_type': 'StartUtteranceBotAction', 'script': '$bot_message'}}, 'action_result_key': None, 'action_uid': '3f1971ad-f571-4b84-8c20-83e6bd82471a', 'is_system_action': True}\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Executing action :: create_event\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Executing registered action: create_event\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Processing event: {'type': 'StartUtteranceBotAction', 'uid': '9c5f1285-5528-4c5a-b83a-42bd01fc0164', 'event_created_at': '2024-10-10T11:55:18.372722+00:00', 'source_uid': 'NeMoGuardrails', 'script': 'When a `cudaGraphExec_t` is destroyed without being synchronized, CUDA manages references to user objects by deferring the release of the last reference. This means that the CUDA runtime will not immediately delete the user objects associated with the `cudaGraphExec_t` when it is destroyed.\\n\\nInstead, the release of the last reference to the `cudaGraphExec_t` is deferred until the CUDA stream is synchronized using `cudaStreamSynchronize(0)`. This ensures that any CUDA operations executing in the stream have a chance to complete before the destructor is executed.\\n\\nOnce the stream is synchronized, the remaining reference to the `cudaGraphExec_t` is released, and the destructor is executed asynchronously. The destructor callback, if present, has access to the user objects associated with the `cudaGraphExec_t`. It can use this access to clean up any necessary resources before the destructor returns.\\n\\nIf the destructor callback has signaled a synchronization object, it is safe to wait on that object until the destructor has completed its execution. This provides a way to ensure that the destruction of the `cudaGraphExec_t` is completed before proceeding with other operations.', 'action_info_modality': 'bot_speech', 'action_info_modality_policy': 'replace', 'action_uid': 'cc23ccce-70de-4a16-ab35-f043d7db2748'}\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Event :: StartUtteranceBotAction {'uid': '9c5f1285-5528-4c5a-b83a-42bd01fc0164', 'event_created_at': '2024-10-10T11:55:18.372722+00:00', 'source_uid': 'NeMoGuardrails', 'script': 'When a `cudaGraphExec_t` is destroyed without being synchronized, CUDA manages references to user objects by deferring the release of the last reference. This means that the CUDA runtime will not immediately delete the user objects associated with the `cudaGraphExec_t` when it is destroyed.\\n\\nInstead, the release of the last reference to the `cudaGraphExec_t` is deferred until the CUDA stream is synchronized using `cudaStreamSynchronize(0)`. This ensures that any CUDA operations executing in the stream have a chance to complete before the destructor is executed.\\n\\nOnce the stream is synchronized, the remaining reference to the `cudaGraphExec_t` is released, and the destructor is executed asynchronously. The destructor callback, if present, has access to the user objects associated with the `cudaGraphExec_t`. It can use this access to clean up any necessary resources before the destructor returns.\\n\\nIf the destructor callback has signaled a synchronization object, it is safe to wait on that object until the destructor has completed its execution. This provides a way to ensure that the destruction of the `cudaGraphExec_t` is completed before proceeding with other operations.', 'action_info_modality': 'bot_speech', 'action_info_modality_policy': 'replace', 'action_uid': 'cc23ccce-70de-4a16-ab35-f043d7db2748'}\n",
      "INFO:nemoguardrails.rails.llm.llmrails:--- :: Total processing took 2.77 seconds. LLM Stats: 1 total calls, 2.76 total time, 816 total tokens, 588 total prompt tokens, 228 total completion tokens, [2.76] as latencies\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/cleanlab/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/cleanlab/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/sensitive_data_detection/flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/sensitive_data_detection/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/autoalign/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/autoalign/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/gotitai/flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/gotitai/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/llama_guard/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/llama_guard/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/content_safety/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/content_safety/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/hallucination/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/hallucination/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/jailbreak_detection/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/jailbreak_detection/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/patronusai/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/patronusai/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/factchecking/align_score/flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/factchecking/align_score/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/self_check/facts/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/self_check/facts/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/self_check/input_check/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/self_check/input_check/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/self_check/output_check/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/self_check/output_check/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/activefence/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/activefence/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/gcp_moderate_text/flows.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.co\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Initializing action dispatcher\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file core.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added create_event to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file retrieve_relevant_chunks.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added retrieve_relevant_chunks to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file math.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added wolfram alpha request to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file action_dispatcher.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file summarize_document.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added summarize_document to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file generation.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file base.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file filter_secrets.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file utils.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file generation.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file safetools.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added call cleanlab api to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added detect_sensitive_data to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added mask_sensitive_data to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added autoalign_factcheck_output_api to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added autoalign_input_api to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added autoalign_output_api to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added call gotitai truthchecker api to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added llama_guard_check_input to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added llama_guard_check_output to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added content_safety_check_input to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added content_safety_check_output to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added self_check_hallucination to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added jailbreak_detection_heuristics to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added patronus_lynx_check_output_hallucination to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added alignscore_check_facts to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added alignscore request to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added self_check_facts to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added self_check_facts to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added self_check_input to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added self_check_output to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added call activefence api to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added call gcpnlp api to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Registered Actions :: ['alignscore request', 'alignscore_check_facts', 'autoalign_factcheck_output_api', 'autoalign_input_api', 'autoalign_output_api', 'call activefence api', 'call cleanlab api', 'call gcpnlp api', 'call gotitai truthchecker api', 'content_safety_check_input', 'content_safety_check_output', 'create_event', 'detect_sensitive_data', 'jailbreak_detection_heuristics', 'llama_guard_check_input', 'llama_guard_check_output', 'mask_sensitive_data', 'patronus_lynx_check_output_hallucination', 'retrieve_relevant_chunks', 'self_check_facts', 'self_check_hallucination', 'self_check_input', 'self_check_output', 'summarize_document', 'wolfram alpha request']\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Action dispatcher initialized\n",
      "DEBUG:asyncio:Using selector: EpollSelector\n",
      "DEBUG:asyncio:Using selector: EpollSelector\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer': 'When a `cudaGraphExec_t` is destroyed without being synchronized, CUDA manages references to user objects by deferring the release of the last reference. This means that the CUDA runtime will not immediately delete the user objects associated with the `cudaGraphExec_t` when it is destroyed.\\n\\nInstead, the release of the last reference to the `cudaGraphExec_t` is deferred until the CUDA stream is synchronized using `cudaStreamSynchronize(0)`. This ensures that any CUDA operations executing in the stream have a chance to complete before the destructor is executed.\\n\\nOnce the stream is synchronized, the remaining reference to the `cudaGraphExec_t` is released, and the destructor is executed asynchronously. The destructor callback, if present, ha', 'contexts': '∕∕Async launch has access to the user objects\\ncudaGraphExecDestroy(graphExec);\\n∕∕Launch is not synchronized; the release\\n∕∕will be deferred if needed\\ncudaStreamSynchronize(0);\\n∕∕After the launch is synchronized, the remaining\\n∕∕reference is released and the destructor will\\n∕∕execute. Note this happens asynchronously.\\n∕∕If the destructor callback had signaled a synchronization object, it would\\n∕∕be safe to wait on it at this point.\\n∕∕Async launch has access to the user objects\\ncudaGraphExecDestroy(graphExec);\\n∕∕Launch is not synchronized; the release\\n∕∕will be deferred if needed\\ncudaStreamSynchronize(0);\\n∕∕After the launch is synchronized, the remaining\\n∕∕reference is released and the destructor will\\n∕∕execute. Note this happens asynchronously.\\n∕∕If the destructor callback had signaled a synchronization object, it would\\n∕∕be safe to wait on it at this point.\\n∕∕Async launch has access to the user objects\\ncudaGraphExecDestroy(graphExec);\\n∕∕Launch is not synchronized; the release\\n∕∕will be deferred if needed\\ncudaStreamSynchronize(0);\\n∕∕After the launch is synchronized, the remaining\\n∕∕reference is released and the destructor will\\n∕∕execute. Note this happens asynchronously.\\n∕∕If the de'}\n",
      "{'status': 'Conversation reset successfully.'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain_nvidia_ai_endpoints import NVIDIARerank\n",
    "from nemoguardrails import LLMRails, RailsConfig\n",
    "\n",
    "# Initialize the reranker (NVIDIA reranker)\n",
    "compressor = NVIDIARerank(model=\"nvidia/nv-rerankqa-mistral-4b-v3\", base_url=\"http://localhost:11737/v1\")\n",
    "\n",
    "# Define the Contextual Compression Retriever\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=docsearch.as_retriever()  # Ensure 'docsearch' is defined earlier in your code\n",
    ")\n",
    "\n",
    "# Initialize NeMo Guardrails\n",
    "config = RailsConfig.from_path(\"./config\")\n",
    "rails = LLMRails(config)\n",
    "\n",
    "# Function to rerank query results and generate response for the /complete endpoint\n",
    "def rerank_and_generate_response(user_query: str):\n",
    "    # Perform reranking using NVIDIA reranker\n",
    "    documents = compression_retriever.get_relevant_documents(user_query)\n",
    "    context_str = \"\\n\".join([doc.page_content for doc in documents])\n",
    "\n",
    "    # Generate a prompt for the assistant using the reranked documents\n",
    "    prompt = f\"\"\"\n",
    "    You are an assistant that answers queries using CUDA-related knowledge.\n",
    "    Based on the following relevant documents, answer the user's query.\n",
    "    \n",
    "    Relevant Documents (Top 3): \n",
    "    {context_str[:1200]}  # Ensuring the context doesn't exceed 1200 tokens\n",
    "\n",
    "    User Query: {user_query}\n",
    "    \n",
    "    Answer (Max 750 tokens):\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate response using NeMo Guardrails\n",
    "    response = rails.generate(messages=[\n",
    "        {\"role\": \"user\", \"content\": user_query},\n",
    "        {\"role\": \"assistant\", \"content\": prompt}\n",
    "    ])\n",
    "\n",
    "    # Return the assistant's response and the context used\n",
    "    return {\n",
    "        \"answer\": response['content'][:750],  # Ensuring answer doesn't exceed 750 tokens\n",
    "        \"contexts\": context_str[:1200]  # Ensuring contexts don't exceed 1200 tokens\n",
    "    }\n",
    "\n",
    "# Function to reset the session for the /reset endpoint by reinitializing the LLMRails object\n",
    "def reset_conversation():\n",
    "    global rails  # Use global to reset the rails object\n",
    "    rails = LLMRails(config)  # Reinitialize the LLMRails to simulate session reset\n",
    "    return {\"status\": \"Conversation reset successfully.\"}\n",
    "\n",
    "# Example usage for /complete and /reset endpoints\n",
    "def complete_endpoint(user_query: str):\n",
    "    result = rerank_and_generate_response(user_query)\n",
    "    print(result)\n",
    "\n",
    "def reset_endpoint():\n",
    "    reset_status = reset_conversation()\n",
    "    print(reset_status)\n",
    "\n",
    "# Main function to demonstrate the endpoints\n",
    "def main():\n",
    "    # Simulate the /complete endpoint\n",
    "    user_query = \"How does CUDA manage references to user objects when a cudaGraphExec_t is destroyed without being synchronized?\"\n",
    "    complete_endpoint(user_query)\n",
    "\n",
    "    # Simulate the /reset endpoint\n",
    "    reset_endpoint()\n",
    "\n",
    "# Run the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "363980e4-c7af-4fd4-b39d-8d9719f44dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/cleanlab/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/cleanlab/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/sensitive_data_detection/flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/sensitive_data_detection/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/autoalign/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/autoalign/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/gotitai/flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/gotitai/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/llama_guard/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/llama_guard/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/content_safety/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/content_safety/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/hallucination/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/hallucination/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/jailbreak_detection/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/jailbreak_detection/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/patronusai/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/patronusai/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/factchecking/align_score/flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/factchecking/align_score/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/self_check/facts/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/self_check/facts/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/self_check/input_check/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/self_check/input_check/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/self_check/output_check/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/self_check/output_check/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/activefence/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/activefence/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/gcp_moderate_text/flows.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.co\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Initializing action dispatcher\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file core.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added create_event to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file retrieve_relevant_chunks.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added retrieve_relevant_chunks to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file math.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added wolfram alpha request to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file action_dispatcher.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file summarize_document.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added summarize_document to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file generation.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file base.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file filter_secrets.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file utils.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file generation.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file safetools.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added call cleanlab api to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added detect_sensitive_data to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added mask_sensitive_data to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added autoalign_factcheck_output_api to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added autoalign_input_api to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added autoalign_output_api to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added call gotitai truthchecker api to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added llama_guard_check_input to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added llama_guard_check_output to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added content_safety_check_input to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added content_safety_check_output to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added self_check_hallucination to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added jailbreak_detection_heuristics to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added patronus_lynx_check_output_hallucination to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added alignscore_check_facts to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added alignscore request to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added self_check_facts to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added self_check_facts to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added self_check_input to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added self_check_output to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added call activefence api to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added call gcpnlp api to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Registered Actions :: ['alignscore request', 'alignscore_check_facts', 'autoalign_factcheck_output_api', 'autoalign_input_api', 'autoalign_output_api', 'call activefence api', 'call cleanlab api', 'call gcpnlp api', 'call gotitai truthchecker api', 'content_safety_check_input', 'content_safety_check_output', 'create_event', 'detect_sensitive_data', 'jailbreak_detection_heuristics', 'llama_guard_check_input', 'llama_guard_check_output', 'mask_sensitive_data', 'patronus_lynx_check_output_hallucination', 'retrieve_relevant_chunks', 'self_check_facts', 'self_check_hallucination', 'self_check_input', 'self_check_output', 'summarize_document', 'wolfram alpha request']\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Action dispatcher initialized\n",
      "DEBUG:asyncio:Using selector: EpollSelector\n",
      "DEBUG:asyncio:Using selector: EpollSelector\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/cleanlab/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/cleanlab/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/sensitive_data_detection/flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/sensitive_data_detection/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/autoalign/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/autoalign/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/gotitai/flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/gotitai/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/llama_guard/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/llama_guard/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/content_safety/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/content_safety/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/hallucination/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/hallucination/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/jailbreak_detection/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/jailbreak_detection/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/patronusai/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/patronusai/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/factchecking/align_score/flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/factchecking/align_score/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/self_check/facts/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/self_check/facts/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/self_check/input_check/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/self_check/input_check/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/self_check/output_check/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/self_check/output_check/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/activefence/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/activefence/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/gcp_moderate_text/flows.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.co\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Initializing action dispatcher\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file core.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added create_event to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file retrieve_relevant_chunks.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added retrieve_relevant_chunks to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file math.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added wolfram alpha request to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file action_dispatcher.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file summarize_document.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added summarize_document to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file generation.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file base.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file filter_secrets.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file utils.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file generation.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file safetools.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added call cleanlab api to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added detect_sensitive_data to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added mask_sensitive_data to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added autoalign_factcheck_output_api to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added autoalign_input_api to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added autoalign_output_api to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added call gotitai truthchecker api to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added llama_guard_check_input to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added llama_guard_check_output to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added content_safety_check_input to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added content_safety_check_output to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added self_check_hallucination to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added jailbreak_detection_heuristics to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added patronus_lynx_check_output_hallucination to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added alignscore_check_facts to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added alignscore request to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added self_check_facts to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added self_check_facts to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added self_check_input to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added self_check_output to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added call activefence api to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added call gcpnlp api to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Registered Actions :: ['alignscore request', 'alignscore_check_facts', 'autoalign_factcheck_output_api', 'autoalign_input_api', 'autoalign_output_api', 'call activefence api', 'call cleanlab api', 'call gcpnlp api', 'call gotitai truthchecker api', 'content_safety_check_input', 'content_safety_check_output', 'create_event', 'detect_sensitive_data', 'jailbreak_detection_heuristics', 'llama_guard_check_input', 'llama_guard_check_output', 'mask_sensitive_data', 'patronus_lynx_check_output_hallucination', 'retrieve_relevant_chunks', 'self_check_facts', 'self_check_hallucination', 'self_check_input', 'self_check_output', 'summarize_document', 'wolfram alpha request']\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Action dispatcher initialized\n",
      "DEBUG:asyncio:Using selector: EpollSelector\n",
      "DEBUG:asyncio:Using selector: EpollSelector\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 0.0.0.0:11022\n",
      "DEBUG:urllib3.connectionpool:http://0.0.0.0:11022 \"POST /v1/embeddings HTTP/11\" 200 19393\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): localhost:11737\n",
      "DEBUG:urllib3.connectionpool:http://localhost:11737 \"POST /v1/ranking HTTP/11\" 200 134\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Processing event: {'type': 'UtteranceBotActionFinished', 'uid': '9c012c68-7b53-4817-8ab8-c10253d8eb69', 'event_created_at': '2024-10-10T11:43:42.742128+00:00', 'source_uid': 'NeMoGuardrails', 'final_script': \"\\n    You are an assistant that answers queries using CUDA-related knowledge.\\n    Based on the following relevant documents, answer the user's query.\\n    \\n    Relevant Documents (Top 3): \\n    ∕∕Async launch has access to the user objects\\ncudaGraphExecDestroy(graphExec);\\n∕∕Launch is not synchronized; the release\\n∕∕will be deferred if needed\\ncudaStreamSynchronize(0);\\n∕∕After the launch is synchronized, the remaining\\n∕∕reference is released and the destructor will\\n∕∕execute. Note this happens asynchronously.\\n∕∕If the destructor callback had signaled a synchronization object, it would\\n∕∕be safe to wait on it at this point.\\n∕∕Async launch has access to the user objects\\ncudaGraphExecDestroy(graphExec);\\n∕∕Launch is not synchronized; the release\\n∕∕will be deferred if needed\\ncudaStreamSynchronize(0);\\n∕∕After the launch is synchronized, the remaining\\n∕∕reference is released and the destructor will\\n∕∕execute. Note this happens asynchronously.\\n∕∕If the destructor callback had signaled a synchronization object, it would\\n∕∕be safe to wait on it at this point.\\n∕∕Async launch has access to the user objects\\ncudaGraphExecDestroy(graphExec);\\n∕∕Launch is not synchronized; the release\\n∕∕will be deferred if needed\\ncudaStreamSynchronize(0);\\n∕∕After the launch is synchronized, the remaining\\n∕∕reference is released and the destructor will\\n∕∕execute. Note this happens asynchronously.\\n∕∕If the de  # Ensuring the context doesn't exceed 1200 tokens\\n\\n    User Query: How does CUDA manage references to user objects when a cudaGraphExec_t is destroyed without being synchronized?\\n    \\n    Answer (Max 750 tokens):\\n    \", 'is_success': True, 'action_uid': '126a3e22-89f1-4da3-bee5-495febf2c60c', 'action_info_modality': 'bot_speech', 'action_info_modality_policy': 'replace', 'action_finished_at': '2024-10-10T11:43:42.742133+00:00'}\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Event :: UtteranceBotActionFinished {'uid': '9c012c68-7b53-4817-8ab8-c10253d8eb69', 'event_created_at': '2024-10-10T11:43:42.742128+00:00', 'source_uid': 'NeMoGuardrails', 'final_script': \"\\n    You are an assistant that answers queries using CUDA-related knowledge.\\n    Based on the following relevant documents, answer the user's query.\\n    \\n    Relevant Documents (Top 3): \\n    ∕∕Async launch has access to the user objects\\ncudaGraphExecDestroy(graphExec);\\n∕∕Launch is not synchronized; the release\\n∕∕will be deferred if needed\\ncudaStreamSynchronize(0);\\n∕∕After the launch is synchronized, the remaining\\n∕∕reference is released and the destructor will\\n∕∕execute. Note this happens asynchronously.\\n∕∕If the destructor callback had signaled a synchronization object, it would\\n∕∕be safe to wait on it at this point.\\n∕∕Async launch has access to the user objects\\ncudaGraphExecDestroy(graphExec);\\n∕∕Launch is not synchronized; the release\\n∕∕will be deferred if needed\\ncudaStreamSynchronize(0);\\n∕∕After the launch is synchronized, the remaining\\n∕∕reference is released and the destructor will\\n∕∕execute. Note this happens asynchronously.\\n∕∕If the destructor callback had signaled a synchronization object, it would\\n∕∕be safe to wait on it at this point.\\n∕∕Async launch has access to the user objects\\ncudaGraphExecDestroy(graphExec);\\n∕∕Launch is not synchronized; the release\\n∕∕will be deferred if needed\\ncudaStreamSynchronize(0);\\n∕∕After the launch is synchronized, the remaining\\n∕∕reference is released and the destructor will\\n∕∕execute. Note this happens asynchronously.\\n∕∕If the de  # Ensuring the context doesn't exceed 1200 tokens\\n\\n    User Query: How does CUDA manage references to user objects when a cudaGraphExec_t is destroyed without being synchronized?\\n    \\n    Answer (Max 750 tokens):\\n    \", 'is_success': True, 'action_uid': '126a3e22-89f1-4da3-bee5-495febf2c60c', 'action_info_modality': 'bot_speech', 'action_info_modality_policy': 'replace', 'action_finished_at': '2024-10-10T11:43:42.742133+00:00'}\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Processing event: {'type': 'StartInternalSystemAction', 'uid': '3ad9ff61-0d8f-4795-9175-4637da2bad86', 'event_created_at': '2024-10-10T11:43:42.743328+00:00', 'source_uid': 'NeMoGuardrails', 'action_name': 'generate_user_intent', 'action_params': {}, 'action_result_key': None, 'action_uid': '9f068058-9387-4487-aa56-bb41840d1f55', 'is_system_action': True}\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Event :: StartInternalSystemAction {'uid': '3ad9ff61-0d8f-4795-9175-4637da2bad86', 'event_created_at': '2024-10-10T11:43:42.743328+00:00', 'source_uid': 'NeMoGuardrails', 'action_name': 'generate_user_intent', 'action_params': {}, 'action_result_key': None, 'action_uid': '9f068058-9387-4487-aa56-bb41840d1f55', 'is_system_action': True}\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Executing action :: generate_user_intent\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Executing registered action: generate_user_intent\n",
      "INFO:nemoguardrails.logging.callbacks:Invocation Params :: {'_type': 'chat-nvidia-ai-playground', 'stop': ['User:']}\n",
      "INFO:nemoguardrails.logging.callbacks:Prompt Messages :: \n",
      "[cyan]System[/]\n",
      "Below is a conversation between a user and an AI assistant specialized in CUDA programming-based tasks such as code analysis, code comprehension, debugging, and precise query answering.\n",
      "The assistant is knowledgeable about CUDA programming, its documentation, and best practices.\n",
      "If the assistant does not know the answer to a question, it will try to find relevant information and let the user know it doesn't have the complete answer.\n",
      "Please keep in mind the following restrictions:\n",
      "  - answer: The response shouldn’t have more than 750 tokens.\n",
      "  - context: thhe context shall not exceed more than 1200 tokens. The context is to be generated by relevant document and if turncated dont use that token.\n",
      "\n",
      "[cyan]User[/]\n",
      "How does CUDA manage references to user objects when a cudaGraphExec_t is destroyed without being synchronized?\n",
      "[cyan]Bot[/]\n",
      "\n",
      "    You are an assistant that answers queries using CUDA-related knowledge.\n",
      "    Based on the following relevant documents, answer the user's query.\n",
      "    \n",
      "    Relevant Documents (Top 3): \n",
      "    ∕∕Async launch has access to the user objects\n",
      "cudaGraphExecDestroy(graphExec);\n",
      "∕∕Launch is not synchronized; the release\n",
      "∕∕will be deferred if needed\n",
      "cudaStreamSynchronize(0);\n",
      "∕∕After the launch is synchronized, the remaining\n",
      "∕∕reference is released and the destructor will\n",
      "∕∕execute. Note this happens asynchronously.\n",
      "∕∕If the destructor callback had signaled a synchronization object, it would\n",
      "∕∕be safe to wait on it at this point.\n",
      "∕∕Async launch has access to the user objects\n",
      "cudaGraphExecDestroy(graphExec);\n",
      "∕∕Launch is not synchronized; the release\n",
      "∕∕will be deferred if needed\n",
      "cudaStreamSynchronize(0);\n",
      "∕∕After the launch is synchronized, the remaining\n",
      "∕∕reference is released and the destructor will\n",
      "∕∕execute. Note this happens asynchronously.\n",
      "∕∕If the destructor callback had signaled a synchronization object, it would\n",
      "∕∕be safe to wait on it at this point.\n",
      "∕∕Async launch has access to the user objects\n",
      "cudaGraphExecDestroy(graphExec);\n",
      "∕∕Launch is not synchronized; the release\n",
      "∕∕will be deferred if needed\n",
      "cudaStreamSynchronize(0);\n",
      "∕∕After the launch is synchronized, the remaining\n",
      "∕∕reference is released and the destructor will\n",
      "∕∕execute. Note this happens asynchronously.\n",
      "∕∕If the de  # Ensuring the context doesn't exceed 1200 tokens\n",
      "\n",
      "    User Query: How does CUDA manage references to user objects when a cudaGraphExec_t is destroyed without being synchronized?\n",
      "    \n",
      "    Answer (Max 750 tokens):\n",
      "    \n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 0.0.0.0:8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'reset_response': 'success'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:http://0.0.0.0:8000 \"POST /v1/chat/completions HTTP/11\" 200 1524\n",
      "INFO:nemoguardrails.logging.callbacks:Completion :: When a `cudaGraphExec_t` is destroyed without being synchronized, CUDA manages references to user objects by deferring the release of the last reference. This means that the CUDA runtime will not immediately delete the user objects associated with the `cudaGraphExec_t` when it is destroyed.\n",
      "\n",
      "Instead, the release of the last reference to the `cudaGraphExec_t` is deferred until the CUDA stream is synchronized using `cudaStreamSynchronize(0)`. This ensures that any CUDA operations executing in the stream have a chance to complete before the destructor is executed.\n",
      "\n",
      "Once the stream is synchronized, the remaining reference to the `cudaGraphExec_t` is released, and the destructor is executed asynchronously. The destructor callback, if present, has access to the user objects associated with the `cudaGraphExec_t`. It can use this access to clean up any necessary resources before the destructor returns.\n",
      "\n",
      "If the destructor callback has signaled a synchronization object, it is safe to wait on that object until the destructor has completed its execution. This provides a way to ensure that the destruction of the `cudaGraphExec_t` is completed before proceeding with other operations.\n",
      "INFO:nemoguardrails.logging.callbacks:Output Stats :: {'role': 'assistant', 'content': 'When a `cudaGraphExec_t` is destroyed without being synchronized, CUDA manages references to user objects by deferring the release of the last reference. This means that the CUDA runtime will not immediately delete the user objects associated with the `cudaGraphExec_t` when it is destroyed.\\n\\nInstead, the release of the last reference to the `cudaGraphExec_t` is deferred until the CUDA stream is synchronized using `cudaStreamSynchronize(0)`. This ensures that any CUDA operations executing in the stream have a chance to complete before the destructor is executed.\\n\\nOnce the stream is synchronized, the remaining reference to the `cudaGraphExec_t` is released, and the destructor is executed asynchronously. The destructor callback, if present, has access to the user objects associated with the `cudaGraphExec_t`. It can use this access to clean up any necessary resources before the destructor returns.\\n\\nIf the destructor callback has signaled a synchronization object, it is safe to wait on that object until the destructor has completed its execution. This provides a way to ensure that the destruction of the `cudaGraphExec_t` is completed before proceeding with other operations.', 'token_usage': {'prompt_tokens': 588, 'total_tokens': 816, 'completion_tokens': 228}, 'finish_reason': 'stop', 'model_name': 'meta/llama-3.1-8b-instruct'}\n",
      "INFO:nemoguardrails.logging.callbacks:--- :: LLM call took 2.76 seconds\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Processing event: {'type': 'BotMessage', 'uid': 'cbf97d7f-1e85-468c-a030-001d7503e431', 'event_created_at': '2024-10-10T11:43:45.512052+00:00', 'source_uid': 'NeMoGuardrails', 'text': 'When a `cudaGraphExec_t` is destroyed without being synchronized, CUDA manages references to user objects by deferring the release of the last reference. This means that the CUDA runtime will not immediately delete the user objects associated with the `cudaGraphExec_t` when it is destroyed.\\n\\nInstead, the release of the last reference to the `cudaGraphExec_t` is deferred until the CUDA stream is synchronized using `cudaStreamSynchronize(0)`. This ensures that any CUDA operations executing in the stream have a chance to complete before the destructor is executed.\\n\\nOnce the stream is synchronized, the remaining reference to the `cudaGraphExec_t` is released, and the destructor is executed asynchronously. The destructor callback, if present, has access to the user objects associated with the `cudaGraphExec_t`. It can use this access to clean up any necessary resources before the destructor returns.\\n\\nIf the destructor callback has signaled a synchronization object, it is safe to wait on that object until the destructor has completed its execution. This provides a way to ensure that the destruction of the `cudaGraphExec_t` is completed before proceeding with other operations.'}\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Event :: BotMessage {'uid': 'cbf97d7f-1e85-468c-a030-001d7503e431', 'event_created_at': '2024-10-10T11:43:45.512052+00:00', 'source_uid': 'NeMoGuardrails', 'text': 'When a `cudaGraphExec_t` is destroyed without being synchronized, CUDA manages references to user objects by deferring the release of the last reference. This means that the CUDA runtime will not immediately delete the user objects associated with the `cudaGraphExec_t` when it is destroyed.\\n\\nInstead, the release of the last reference to the `cudaGraphExec_t` is deferred until the CUDA stream is synchronized using `cudaStreamSynchronize(0)`. This ensures that any CUDA operations executing in the stream have a chance to complete before the destructor is executed.\\n\\nOnce the stream is synchronized, the remaining reference to the `cudaGraphExec_t` is released, and the destructor is executed asynchronously. The destructor callback, if present, has access to the user objects associated with the `cudaGraphExec_t`. It can use this access to clean up any necessary resources before the destructor returns.\\n\\nIf the destructor callback has signaled a synchronization object, it is safe to wait on that object until the destructor has completed its execution. This provides a way to ensure that the destruction of the `cudaGraphExec_t` is completed before proceeding with other operations.'}\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Processing event: {'type': 'StartInternalSystemAction', 'uid': '57835a23-9cf4-48ea-a95b-027dcec42973', 'event_created_at': '2024-10-10T11:43:45.513454+00:00', 'source_uid': 'NeMoGuardrails', 'action_name': 'create_event', 'action_params': {'event': {'_type': 'StartUtteranceBotAction', 'script': '$bot_message'}}, 'action_result_key': None, 'action_uid': 'acf0a454-67cc-4206-88e4-7fca0a12a086', 'is_system_action': True}\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Event :: StartInternalSystemAction {'uid': '57835a23-9cf4-48ea-a95b-027dcec42973', 'event_created_at': '2024-10-10T11:43:45.513454+00:00', 'source_uid': 'NeMoGuardrails', 'action_name': 'create_event', 'action_params': {'event': {'_type': 'StartUtteranceBotAction', 'script': '$bot_message'}}, 'action_result_key': None, 'action_uid': 'acf0a454-67cc-4206-88e4-7fca0a12a086', 'is_system_action': True}\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Executing action :: create_event\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Executing registered action: create_event\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Processing event: {'type': 'StartUtteranceBotAction', 'uid': '1833cdb1-ac64-4eef-b302-424c0eb71780', 'event_created_at': '2024-10-10T11:43:45.514804+00:00', 'source_uid': 'NeMoGuardrails', 'script': 'When a `cudaGraphExec_t` is destroyed without being synchronized, CUDA manages references to user objects by deferring the release of the last reference. This means that the CUDA runtime will not immediately delete the user objects associated with the `cudaGraphExec_t` when it is destroyed.\\n\\nInstead, the release of the last reference to the `cudaGraphExec_t` is deferred until the CUDA stream is synchronized using `cudaStreamSynchronize(0)`. This ensures that any CUDA operations executing in the stream have a chance to complete before the destructor is executed.\\n\\nOnce the stream is synchronized, the remaining reference to the `cudaGraphExec_t` is released, and the destructor is executed asynchronously. The destructor callback, if present, has access to the user objects associated with the `cudaGraphExec_t`. It can use this access to clean up any necessary resources before the destructor returns.\\n\\nIf the destructor callback has signaled a synchronization object, it is safe to wait on that object until the destructor has completed its execution. This provides a way to ensure that the destruction of the `cudaGraphExec_t` is completed before proceeding with other operations.', 'action_info_modality': 'bot_speech', 'action_info_modality_policy': 'replace', 'action_uid': '7fcdc173-87ca-4038-a340-4d37ed3bd7ba'}\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Event :: StartUtteranceBotAction {'uid': '1833cdb1-ac64-4eef-b302-424c0eb71780', 'event_created_at': '2024-10-10T11:43:45.514804+00:00', 'source_uid': 'NeMoGuardrails', 'script': 'When a `cudaGraphExec_t` is destroyed without being synchronized, CUDA manages references to user objects by deferring the release of the last reference. This means that the CUDA runtime will not immediately delete the user objects associated with the `cudaGraphExec_t` when it is destroyed.\\n\\nInstead, the release of the last reference to the `cudaGraphExec_t` is deferred until the CUDA stream is synchronized using `cudaStreamSynchronize(0)`. This ensures that any CUDA operations executing in the stream have a chance to complete before the destructor is executed.\\n\\nOnce the stream is synchronized, the remaining reference to the `cudaGraphExec_t` is released, and the destructor is executed asynchronously. The destructor callback, if present, has access to the user objects associated with the `cudaGraphExec_t`. It can use this access to clean up any necessary resources before the destructor returns.\\n\\nIf the destructor callback has signaled a synchronization object, it is safe to wait on that object until the destructor has completed its execution. This provides a way to ensure that the destruction of the `cudaGraphExec_t` is completed before proceeding with other operations.', 'action_info_modality': 'bot_speech', 'action_info_modality_policy': 'replace', 'action_uid': '7fcdc173-87ca-4038-a340-4d37ed3bd7ba'}\n",
      "INFO:nemoguardrails.rails.llm.llmrails:--- :: Total processing took 2.77 seconds. LLM Stats: 1 total calls, 2.76 total time, 816 total tokens, 588 total prompt tokens, 228 total completion tokens, [2.76] as latencies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer': 'When a `cudaGraphExec_t` is destroyed without being synchronized, CUDA manages references to user objects by deferring the release of the last reference. This means that the CUDA runtime will not immediately delete the user objects associated with the `cudaGraphExec_t` when it is destroyed.\\n\\nInstead, the release of the last reference to the `cudaGraphExec_t` is deferred until the CUDA stream is synchronized using `cudaStreamSynchronize(0)`. This ensures that any CUDA operations executing in the stream have a chance to complete before the destructor is executed.\\n\\nOnce the stream is synchronized, the remaining reference to the `cudaGraphExec_t` is released, and the destructor is executed asynchronously. The destructor callback, if present, ha', 'contexts': '∕∕Async launch has access to the user objects\\ncudaGraphExecDestroy(graphExec);\\n∕∕Launch is not synchronized; the release\\n∕∕will be deferred if needed\\ncudaStreamSynchronize(0);\\n∕∕After the launch is synchronized, the remaining\\n∕∕reference is released and the destructor will\\n∕∕execute. Note this happens asynchronously.\\n∕∕If the destructor callback had signaled a synchronization object, it would\\n∕∕be safe to wait on it at this point.\\n∕∕Async launch has access to the user objects\\ncudaGraphExecDestroy(graphExec);\\n∕∕Launch is not synchronized; the release\\n∕∕will be deferred if needed\\ncudaStreamSynchronize(0);\\n∕∕After the launch is synchronized, the remaining\\n∕∕reference is released and the destructor will\\n∕∕execute. Note this happens asynchronously.\\n∕∕If the destructor callback had signaled a synchronization object, it would\\n∕∕be safe to wait on it at this point.\\n∕∕Async launch has access to the user objects\\ncudaGraphExecDestroy(graphExec);\\n∕∕Launch is not synchronized; the release\\n∕∕will be deferred if needed\\ncudaStreamSynchronize(0);\\n∕∕After the launch is synchronized, the remaining\\n∕∕reference is released and the destructor will\\n∕∕execute. Note this happens asynchronously.\\n∕∕If the de'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain_nvidia_ai_endpoints import NVIDIARerank\n",
    "from nemoguardrails import LLMRails, RailsConfig\n",
    "\n",
    "# Initialize the reranker (NVIDIA reranker)\n",
    "compressor = NVIDIARerank(model=\"nvidia/nv-rerankqa-mistral-4b-v3\", base_url=\"http://localhost:11737/v1\")\n",
    "\n",
    "# Define the Contextual Compression Retriever\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=docsearch.as_retriever()  # Ensure 'docsearch' is defined earlier in your code\n",
    ")\n",
    "\n",
    "# Initialize NeMo Guardrails\n",
    "config = RailsConfig.from_path(\"./config\")\n",
    "rails = LLMRails(config)\n",
    "\n",
    "# Function to rerank query results and generate response for the /complete endpoint\n",
    "def rerank_and_generate_response(user_query: str):\n",
    "    # Perform reranking using NVIDIA reranker\n",
    "    documents = compression_retriever.get_relevant_documents(user_query)\n",
    "    context_str = \"\\n\".join([doc.page_content for doc in documents])\n",
    "\n",
    "    # Generate a prompt for the assistant using the reranked documents\n",
    "    prompt = f\"\"\"\n",
    "    You are an assistant that answers queries using CUDA-related knowledge.\n",
    "    Based on the following relevant documents, answer the user's query.\n",
    "    \n",
    "    Relevant Documents (Top 3): \n",
    "    {context_str[:1200]}  # Ensuring the context doesn't exceed 1200 tokens\n",
    "\n",
    "    User Query: {user_query}\n",
    "    \n",
    "    Answer (Max 750 tokens):\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate response using NeMo Guardrails\n",
    "    response = rails.generate(messages=[\n",
    "        {\"role\": \"user\", \"content\": user_query},\n",
    "        {\"role\": \"assistant\", \"content\": prompt}\n",
    "    ])\n",
    "\n",
    "    # Return the assistant's response and the context used\n",
    "    return {\n",
    "        \"answer\": response['content'][:750],  # Ensuring answer doesn't exceed 750 tokens\n",
    "        \"contexts\": context_str[:1200]  # Ensuring contexts don't exceed 1200 tokens\n",
    "    }\n",
    "\n",
    "# Function to reset the session for the /reset endpoint by reinitializing the LLMRails object\n",
    "def reset_conversation():\n",
    "    global rails  # Use global to reset the rails object\n",
    "    rails = LLMRails(config)  # Reinitialize the LLMRails to simulate session reset\n",
    "    return {\"reset_response\": \"success\"}\n",
    "\n",
    "# Example usage for /complete and /reset endpoints\n",
    "def complete_endpoint(user_query: str):\n",
    "    result = rerank_and_generate_response(user_query)\n",
    "    print(result)\n",
    "\n",
    "def reset_endpoint():\n",
    "    reset_status = reset_conversation()\n",
    "    print(reset_status)\n",
    "\n",
    "# Main function to simulate endpoint behavior\n",
    "def main(input_data):\n",
    "    # Check if the input is asking for a reset\n",
    "    if \"reset\" in input_data and input_data[\"reset\"] == 1:\n",
    "        reset_endpoint()  # Call reset endpoint when requested\n",
    "    else:\n",
    "        user_query = input_data.get(\"question\", \"\")\n",
    "        if user_query:\n",
    "            complete_endpoint(user_query)\n",
    "\n",
    "# Run the main function with input to demonstrate the endpoints\n",
    "if __name__ == \"__main__\":\n",
    "    # Simulating input for the reset case\n",
    "    input_data_reset = {\"reset\": 1}\n",
    "    \n",
    "    # Simulating input for the complete case\n",
    "    input_data_complete = {\n",
    "        \"question\": \"How does CUDA manage references to user objects when a cudaGraphExec_t is destroyed without being synchronized?\"\n",
    "    }\n",
    "\n",
    "    # Test reset functionality\n",
    "    main(input_data_reset)\n",
    "\n",
    "    # Test complete functionality\n",
    "    main(input_data_complete)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "65ef6d5d-ae7a-4db1-890c-86425a0c2163",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/cleanlab/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/cleanlab/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/sensitive_data_detection/flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/sensitive_data_detection/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/autoalign/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/autoalign/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/gotitai/flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/gotitai/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/llama_guard/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/llama_guard/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/content_safety/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/content_safety/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/hallucination/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/hallucination/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/jailbreak_detection/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/jailbreak_detection/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/patronusai/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/patronusai/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/factchecking/align_score/flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/factchecking/align_score/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/self_check/facts/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/self_check/facts/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/self_check/input_check/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/self_check/input_check/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/self_check/output_check/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/self_check/output_check/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/activefence/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/activefence/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/gcp_moderate_text/flows.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.co\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Initializing action dispatcher\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file core.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added create_event to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file retrieve_relevant_chunks.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added retrieve_relevant_chunks to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file math.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added wolfram alpha request to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file action_dispatcher.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file summarize_document.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added summarize_document to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file generation.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file base.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file filter_secrets.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file utils.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file generation.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file safetools.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added call cleanlab api to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added detect_sensitive_data to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added mask_sensitive_data to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added autoalign_factcheck_output_api to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added autoalign_input_api to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added autoalign_output_api to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added call gotitai truthchecker api to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added llama_guard_check_input to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added llama_guard_check_output to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added content_safety_check_input to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added content_safety_check_output to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added self_check_hallucination to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added jailbreak_detection_heuristics to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added patronus_lynx_check_output_hallucination to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added alignscore_check_facts to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added alignscore request to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added self_check_facts to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added self_check_facts to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added self_check_input to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added self_check_output to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added call activefence api to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added call gcpnlp api to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Registered Actions :: ['alignscore request', 'alignscore_check_facts', 'autoalign_factcheck_output_api', 'autoalign_input_api', 'autoalign_output_api', 'call activefence api', 'call cleanlab api', 'call gcpnlp api', 'call gotitai truthchecker api', 'content_safety_check_input', 'content_safety_check_output', 'create_event', 'detect_sensitive_data', 'jailbreak_detection_heuristics', 'llama_guard_check_input', 'llama_guard_check_output', 'mask_sensitive_data', 'patronus_lynx_check_output_hallucination', 'retrieve_relevant_chunks', 'self_check_facts', 'self_check_hallucination', 'self_check_input', 'self_check_output', 'summarize_document', 'wolfram alpha request']\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Action dispatcher initialized\n",
      "DEBUG:asyncio:Using selector: EpollSelector\n",
      "DEBUG:asyncio:Using selector: EpollSelector\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 0.0.0.0:11022\n",
      "DEBUG:urllib3.connectionpool:http://0.0.0.0:11022 \"POST /v1/embeddings HTTP/11\" 200 19393\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): localhost:11737\n",
      "DEBUG:urllib3.connectionpool:http://localhost:11737 \"POST /v1/ranking HTTP/11\" 200 134\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Processing event: {'type': 'UtteranceBotActionFinished', 'uid': 'b6ed77e8-cb84-4a24-b8e0-6b8042fab08e', 'event_created_at': '2024-10-10T11:56:37.230463+00:00', 'source_uid': 'NeMoGuardrails', 'final_script': \"\\n    You are an assistant that answers queries using CUDA-related knowledge.\\n    Based on the following relevant documents, answer the user's query.\\n    \\n    Relevant Documents (Top 3): \\n    ∕∕Async launch has access to the user objects\\ncudaGraphExecDestroy(graphExec);\\n∕∕Launch is not synchronized; the release\\n∕∕will be deferred if needed\\ncudaStreamSynchronize(0);\\n∕∕After the launch is synchronized, the remaining\\n∕∕reference is released and the destructor will\\n∕∕execute. Note this happens asynchronously.\\n∕∕If the destructor callback had signaled a synchronization object, it would\\n∕∕be safe to wait on it at this point.\\n∕∕Async launch has access to the user objects\\ncudaGraphExecDestroy(graphExec);\\n∕∕Launch is not synchronized; the release\\n∕∕will be deferred if needed\\ncudaStreamSynchronize(0);\\n∕∕After the launch is synchronized, the remaining\\n∕∕reference is released and the destructor will\\n∕∕execute. Note this happens asynchronously.\\n∕∕If the destructor callback had signaled a synchronization object, it would\\n∕∕be safe to wait on it at this point.\\n∕∕Async launch has access to the user objects\\ncudaGraphExecDestroy(graphExec);\\n∕∕Launch is not synchronized; the release\\n∕∕will be deferred if needed\\ncudaStreamSynchronize(0);\\n∕∕After the launch is synchronized, the remaining\\n∕∕reference is released and the destructor will\\n∕∕execute. Note this happens asynchronously.\\n∕∕If the de  # Ensuring the context doesn't exceed 1200 tokens\\n\\n    User Query: How does CUDA manage references to user objects when a cudaGraphExec_t is destroyed without being synchronized?\\n    \\n    Answer (Max 750 tokens):\\n    \", 'is_success': True, 'action_uid': '4e995531-80f5-4a2c-907e-fb9e19410cee', 'action_info_modality': 'bot_speech', 'action_info_modality_policy': 'replace', 'action_finished_at': '2024-10-10T11:56:37.230469+00:00'}\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Event :: UtteranceBotActionFinished {'uid': 'b6ed77e8-cb84-4a24-b8e0-6b8042fab08e', 'event_created_at': '2024-10-10T11:56:37.230463+00:00', 'source_uid': 'NeMoGuardrails', 'final_script': \"\\n    You are an assistant that answers queries using CUDA-related knowledge.\\n    Based on the following relevant documents, answer the user's query.\\n    \\n    Relevant Documents (Top 3): \\n    ∕∕Async launch has access to the user objects\\ncudaGraphExecDestroy(graphExec);\\n∕∕Launch is not synchronized; the release\\n∕∕will be deferred if needed\\ncudaStreamSynchronize(0);\\n∕∕After the launch is synchronized, the remaining\\n∕∕reference is released and the destructor will\\n∕∕execute. Note this happens asynchronously.\\n∕∕If the destructor callback had signaled a synchronization object, it would\\n∕∕be safe to wait on it at this point.\\n∕∕Async launch has access to the user objects\\ncudaGraphExecDestroy(graphExec);\\n∕∕Launch is not synchronized; the release\\n∕∕will be deferred if needed\\ncudaStreamSynchronize(0);\\n∕∕After the launch is synchronized, the remaining\\n∕∕reference is released and the destructor will\\n∕∕execute. Note this happens asynchronously.\\n∕∕If the destructor callback had signaled a synchronization object, it would\\n∕∕be safe to wait on it at this point.\\n∕∕Async launch has access to the user objects\\ncudaGraphExecDestroy(graphExec);\\n∕∕Launch is not synchronized; the release\\n∕∕will be deferred if needed\\ncudaStreamSynchronize(0);\\n∕∕After the launch is synchronized, the remaining\\n∕∕reference is released and the destructor will\\n∕∕execute. Note this happens asynchronously.\\n∕∕If the de  # Ensuring the context doesn't exceed 1200 tokens\\n\\n    User Query: How does CUDA manage references to user objects when a cudaGraphExec_t is destroyed without being synchronized?\\n    \\n    Answer (Max 750 tokens):\\n    \", 'is_success': True, 'action_uid': '4e995531-80f5-4a2c-907e-fb9e19410cee', 'action_info_modality': 'bot_speech', 'action_info_modality_policy': 'replace', 'action_finished_at': '2024-10-10T11:56:37.230469+00:00'}\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Processing event: {'type': 'StartInternalSystemAction', 'uid': '025b675d-fc4c-4bba-a76c-0457829ff7be', 'event_created_at': '2024-10-10T11:56:37.231484+00:00', 'source_uid': 'NeMoGuardrails', 'action_name': 'generate_user_intent', 'action_params': {}, 'action_result_key': None, 'action_uid': '4b463a0a-76c4-4378-9ed5-d2a7010ca6a4', 'is_system_action': True}\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Event :: StartInternalSystemAction {'uid': '025b675d-fc4c-4bba-a76c-0457829ff7be', 'event_created_at': '2024-10-10T11:56:37.231484+00:00', 'source_uid': 'NeMoGuardrails', 'action_name': 'generate_user_intent', 'action_params': {}, 'action_result_key': None, 'action_uid': '4b463a0a-76c4-4378-9ed5-d2a7010ca6a4', 'is_system_action': True}\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Executing action :: generate_user_intent\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Executing registered action: generate_user_intent\n",
      "INFO:nemoguardrails.logging.callbacks:Invocation Params :: {'_type': 'chat-nvidia-ai-playground', 'stop': ['User:']}\n",
      "INFO:nemoguardrails.logging.callbacks:Prompt Messages :: \n",
      "[cyan]System[/]\n",
      "Below is a conversation between a user and an AI assistant specialized in CUDA programming-based tasks such as code analysis, code comprehension, debugging, and precise query answering.\n",
      "The assistant is knowledgeable about CUDA programming, its documentation, and best practices.\n",
      "If the assistant does not know the answer to a question, it will try to find relevant information and let the user know it doesn't have the complete answer.\n",
      "Please keep in mind the following restrictions:\n",
      "  - answer: The response shouldn’t have more than 750 tokens.\n",
      "  - context: thhe context shall not exceed more than 1200 tokens if do manage it by not taking uncomplete token. The context is to be generated by relevant document and if turncated dont use that token.\n",
      "\n",
      "[cyan]User[/]\n",
      "How does CUDA manage references to user objects when a cudaGraphExec_t is destroyed without being synchronized?\n",
      "[cyan]Bot[/]\n",
      "\n",
      "    You are an assistant that answers queries using CUDA-related knowledge.\n",
      "    Based on the following relevant documents, answer the user's query.\n",
      "    \n",
      "    Relevant Documents (Top 3): \n",
      "    ∕∕Async launch has access to the user objects\n",
      "cudaGraphExecDestroy(graphExec);\n",
      "∕∕Launch is not synchronized; the release\n",
      "∕∕will be deferred if needed\n",
      "cudaStreamSynchronize(0);\n",
      "∕∕After the launch is synchronized, the remaining\n",
      "∕∕reference is released and the destructor will\n",
      "∕∕execute. Note this happens asynchronously.\n",
      "∕∕If the destructor callback had signaled a synchronization object, it would\n",
      "∕∕be safe to wait on it at this point.\n",
      "∕∕Async launch has access to the user objects\n",
      "cudaGraphExecDestroy(graphExec);\n",
      "∕∕Launch is not synchronized; the release\n",
      "∕∕will be deferred if needed\n",
      "cudaStreamSynchronize(0);\n",
      "∕∕After the launch is synchronized, the remaining\n",
      "∕∕reference is released and the destructor will\n",
      "∕∕execute. Note this happens asynchronously.\n",
      "∕∕If the destructor callback had signaled a synchronization object, it would\n",
      "∕∕be safe to wait on it at this point.\n",
      "∕∕Async launch has access to the user objects\n",
      "cudaGraphExecDestroy(graphExec);\n",
      "∕∕Launch is not synchronized; the release\n",
      "∕∕will be deferred if needed\n",
      "cudaStreamSynchronize(0);\n",
      "∕∕After the launch is synchronized, the remaining\n",
      "∕∕reference is released and the destructor will\n",
      "∕∕execute. Note this happens asynchronously.\n",
      "∕∕If the de  # Ensuring the context doesn't exceed 1200 tokens\n",
      "\n",
      "    User Query: How does CUDA manage references to user objects when a cudaGraphExec_t is destroyed without being synchronized?\n",
      "    \n",
      "    Answer (Max 750 tokens):\n",
      "    \n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 0.0.0.0:8000\n",
      "DEBUG:urllib3.connectionpool:http://0.0.0.0:8000 \"POST /v1/chat/completions HTTP/11\" 200 1263\n",
      "INFO:nemoguardrails.logging.callbacks:Completion :: When a `cudaGraphExec_t` is destroyed without being synchronized, CUDA manages references to user objects by deferring the release of the object's memory until the launch is synchronized. This is done to prevent the object from being destroyed while it is still being accessed by the launch.\n",
      "\n",
      "In CUDA 11.7 and later versions, the `cudaGraphExecDestroy` function does not synchronize the launch, but it does ensure that the object's memory is released after the launch is completed. \n",
      "\n",
      "This is achieved by using a synchronization mechanism that guarantees that the destructor will be executed after the launch has finished executing. This ensures that user objects are not accessed after the `cudaGraphExec_t` object is destroyed.\n",
      "\n",
      "It's worth noting that this behavior may change in future CUDA versions, and developers should consult the relevant documentation for the version they are using for the most up-to-date information.\n",
      "INFO:nemoguardrails.logging.callbacks:Output Stats :: {'role': 'assistant', 'content': \"When a `cudaGraphExec_t` is destroyed without being synchronized, CUDA manages references to user objects by deferring the release of the object's memory until the launch is synchronized. This is done to prevent the object from being destroyed while it is still being accessed by the launch.\\n\\nIn CUDA 11.7 and later versions, the `cudaGraphExecDestroy` function does not synchronize the launch, but it does ensure that the object's memory is released after the launch is completed. \\n\\nThis is achieved by using a synchronization mechanism that guarantees that the destructor will be executed after the launch has finished executing. This ensures that user objects are not accessed after the `cudaGraphExec_t` object is destroyed.\\n\\nIt's worth noting that this behavior may change in future CUDA versions, and developers should consult the relevant documentation for the version they are using for the most up-to-date information.\", 'token_usage': {'prompt_tokens': 598, 'total_tokens': 774, 'completion_tokens': 176}, 'finish_reason': 'stop', 'model_name': 'meta/llama-3.1-8b-instruct'}\n",
      "INFO:nemoguardrails.logging.callbacks:--- :: LLM call took 2.14 seconds\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Processing event: {'type': 'BotMessage', 'uid': '15c8ac00-9860-43cb-aa50-62843646703a', 'event_created_at': '2024-10-10T11:56:39.378948+00:00', 'source_uid': 'NeMoGuardrails', 'text': \"When a `cudaGraphExec_t` is destroyed without being synchronized, CUDA manages references to user objects by deferring the release of the object's memory until the launch is synchronized. This is done to prevent the object from being destroyed while it is still being accessed by the launch.\\n\\nIn CUDA 11.7 and later versions, the `cudaGraphExecDestroy` function does not synchronize the launch, but it does ensure that the object's memory is released after the launch is completed. \\n\\nThis is achieved by using a synchronization mechanism that guarantees that the destructor will be executed after the launch has finished executing. This ensures that user objects are not accessed after the `cudaGraphExec_t` object is destroyed.\\n\\nIt's worth noting that this behavior may change in future CUDA versions, and developers should consult the relevant documentation for the version they are using for the most up-to-date information.\"}\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Event :: BotMessage {'uid': '15c8ac00-9860-43cb-aa50-62843646703a', 'event_created_at': '2024-10-10T11:56:39.378948+00:00', 'source_uid': 'NeMoGuardrails', 'text': \"When a `cudaGraphExec_t` is destroyed without being synchronized, CUDA manages references to user objects by deferring the release of the object's memory until the launch is synchronized. This is done to prevent the object from being destroyed while it is still being accessed by the launch.\\n\\nIn CUDA 11.7 and later versions, the `cudaGraphExecDestroy` function does not synchronize the launch, but it does ensure that the object's memory is released after the launch is completed. \\n\\nThis is achieved by using a synchronization mechanism that guarantees that the destructor will be executed after the launch has finished executing. This ensures that user objects are not accessed after the `cudaGraphExec_t` object is destroyed.\\n\\nIt's worth noting that this behavior may change in future CUDA versions, and developers should consult the relevant documentation for the version they are using for the most up-to-date information.\"}\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Processing event: {'type': 'StartInternalSystemAction', 'uid': '0919fbc0-d657-4a56-a23e-dfdb7d885289', 'event_created_at': '2024-10-10T11:56:39.380075+00:00', 'source_uid': 'NeMoGuardrails', 'action_name': 'create_event', 'action_params': {'event': {'_type': 'StartUtteranceBotAction', 'script': '$bot_message'}}, 'action_result_key': None, 'action_uid': '36940aa5-19bd-4433-bde3-192b963d22fa', 'is_system_action': True}\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Event :: StartInternalSystemAction {'uid': '0919fbc0-d657-4a56-a23e-dfdb7d885289', 'event_created_at': '2024-10-10T11:56:39.380075+00:00', 'source_uid': 'NeMoGuardrails', 'action_name': 'create_event', 'action_params': {'event': {'_type': 'StartUtteranceBotAction', 'script': '$bot_message'}}, 'action_result_key': None, 'action_uid': '36940aa5-19bd-4433-bde3-192b963d22fa', 'is_system_action': True}\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Executing action :: create_event\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Executing registered action: create_event\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Processing event: {'type': 'StartUtteranceBotAction', 'uid': 'b79052c0-39c5-47b5-a385-179afdcd7489', 'event_created_at': '2024-10-10T11:56:39.381183+00:00', 'source_uid': 'NeMoGuardrails', 'script': \"When a `cudaGraphExec_t` is destroyed without being synchronized, CUDA manages references to user objects by deferring the release of the object's memory until the launch is synchronized. This is done to prevent the object from being destroyed while it is still being accessed by the launch.\\n\\nIn CUDA 11.7 and later versions, the `cudaGraphExecDestroy` function does not synchronize the launch, but it does ensure that the object's memory is released after the launch is completed. \\n\\nThis is achieved by using a synchronization mechanism that guarantees that the destructor will be executed after the launch has finished executing. This ensures that user objects are not accessed after the `cudaGraphExec_t` object is destroyed.\\n\\nIt's worth noting that this behavior may change in future CUDA versions, and developers should consult the relevant documentation for the version they are using for the most up-to-date information.\", 'action_info_modality': 'bot_speech', 'action_info_modality_policy': 'replace', 'action_uid': 'cb5d3c0a-5831-47e8-b870-c9366318ce52'}\n",
      "INFO:nemoguardrails.colang.v1_0.runtime.runtime:Event :: StartUtteranceBotAction {'uid': 'b79052c0-39c5-47b5-a385-179afdcd7489', 'event_created_at': '2024-10-10T11:56:39.381183+00:00', 'source_uid': 'NeMoGuardrails', 'script': \"When a `cudaGraphExec_t` is destroyed without being synchronized, CUDA manages references to user objects by deferring the release of the object's memory until the launch is synchronized. This is done to prevent the object from being destroyed while it is still being accessed by the launch.\\n\\nIn CUDA 11.7 and later versions, the `cudaGraphExecDestroy` function does not synchronize the launch, but it does ensure that the object's memory is released after the launch is completed. \\n\\nThis is achieved by using a synchronization mechanism that guarantees that the destructor will be executed after the launch has finished executing. This ensures that user objects are not accessed after the `cudaGraphExec_t` object is destroyed.\\n\\nIt's worth noting that this behavior may change in future CUDA versions, and developers should consult the relevant documentation for the version they are using for the most up-to-date information.\", 'action_info_modality': 'bot_speech', 'action_info_modality_policy': 'replace', 'action_uid': 'cb5d3c0a-5831-47e8-b870-c9366318ce52'}\n",
      "INFO:nemoguardrails.rails.llm.llmrails:--- :: Total processing took 2.15 seconds. LLM Stats: 1 total calls, 2.14 total time, 774 total tokens, 598 total prompt tokens, 176 total completion tokens, [2.14] as latencies\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/cleanlab/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/cleanlab/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/sensitive_data_detection/flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/sensitive_data_detection/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/autoalign/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/autoalign/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/gotitai/flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/gotitai/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/llama_guard/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/llama_guard/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/content_safety/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/content_safety/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/hallucination/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/hallucination/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/jailbreak_detection/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/jailbreak_detection/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/patronusai/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/patronusai/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/factchecking/align_score/flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/factchecking/align_score/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/self_check/facts/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/self_check/facts/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/self_check/input_check/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/self_check/input_check/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/self_check/output_check/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/self_check/output_check/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/activefence/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/activefence/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/gcp_moderate_text/flows.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.co\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Initializing action dispatcher\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file core.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added create_event to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file retrieve_relevant_chunks.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added retrieve_relevant_chunks to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file math.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added wolfram alpha request to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file action_dispatcher.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file summarize_document.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added summarize_document to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file generation.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file base.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file filter_secrets.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file utils.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file generation.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file safetools.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added call cleanlab api to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added detect_sensitive_data to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added mask_sensitive_data to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added autoalign_factcheck_output_api to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added autoalign_input_api to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added autoalign_output_api to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added call gotitai truthchecker api to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added llama_guard_check_input to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added llama_guard_check_output to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added content_safety_check_input to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added content_safety_check_output to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added self_check_hallucination to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added jailbreak_detection_heuristics to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added patronus_lynx_check_output_hallucination to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added alignscore_check_facts to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added alignscore request to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added self_check_facts to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added self_check_facts to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added self_check_input to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added self_check_output to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added call activefence api to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added call gcpnlp api to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Registered Actions :: ['alignscore request', 'alignscore_check_facts', 'autoalign_factcheck_output_api', 'autoalign_input_api', 'autoalign_output_api', 'call activefence api', 'call cleanlab api', 'call gcpnlp api', 'call gotitai truthchecker api', 'content_safety_check_input', 'content_safety_check_output', 'create_event', 'detect_sensitive_data', 'jailbreak_detection_heuristics', 'llama_guard_check_input', 'llama_guard_check_output', 'mask_sensitive_data', 'patronus_lynx_check_output_hallucination', 'retrieve_relevant_chunks', 'self_check_facts', 'self_check_hallucination', 'self_check_input', 'self_check_output', 'summarize_document', 'wolfram alpha request']\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Action dispatcher initialized\n",
      "DEBUG:asyncio:Using selector: EpollSelector\n",
      "DEBUG:asyncio:Using selector: EpollSelector\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer': \"When a `cudaGraphExec_t` is destroyed without being synchronized, CUDA manages references to user objects by deferring the release of the object's memory until the launch is synchronized. This is done to prevent the object from being destroyed while it is still being accessed by the launch.\\n\\nIn CUDA 11.7 and later versions, the `cudaGraphExecDestroy` function does not synchronize the launch, but it does ensure that the object's memory is released after the launch is completed. \\n\\nThis is achieved by using a synchronization mechanism that guarantees that the destructor will be executed after the launch has finished executing. This ensures that user objects are not accessed after the `cudaGraphExec_t` object is destroyed.\\n\\nIt's worth noting th\", 'contexts': '∕∕Async launch has access to the user objects\\ncudaGraphExecDestroy(graphExec);\\n∕∕Launch is not synchronized; the release\\n∕∕will be deferred if needed\\ncudaStreamSynchronize(0);\\n∕∕After the launch is synchronized, the remaining\\n∕∕reference is released and the destructor will\\n∕∕execute. Note this happens asynchronously.\\n∕∕If the destructor callback had signaled a synchronization object, it would\\n∕∕be safe to wait on it at this point.\\n∕∕Async launch has access to the user objects\\ncudaGraphExecDestroy(graphExec);\\n∕∕Launch is not synchronized; the release\\n∕∕will be deferred if needed\\ncudaStreamSynchronize(0);\\n∕∕After the launch is synchronized, the remaining\\n∕∕reference is released and the destructor will\\n∕∕execute. Note this happens asynchronously.\\n∕∕If the destructor callback had signaled a synchronization object, it would\\n∕∕be safe to wait on it at this point.\\n∕∕Async launch has access to the user objects\\ncudaGraphExecDestroy(graphExec);\\n∕∕Launch is not synchronized; the release\\n∕∕will be deferred if needed\\ncudaStreamSynchronize(0);\\n∕∕After the launch is synchronized, the remaining\\n∕∕reference is released and the destructor will\\n∕∕execute. Note this happens asynchronously.\\n∕∕If the de'}\n",
      "{'status': 'Conversation reset successfully.'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain_nvidia_ai_endpoints import NVIDIARerank\n",
    "from nemoguardrails import LLMRails, RailsConfig\n",
    "\n",
    "# Initialize the reranker (NVIDIA reranker)\n",
    "compressor = NVIDIARerank(model=\"nvidia/nv-rerankqa-mistral-4b-v3\", base_url=\"http://localhost:11737/v1\")\n",
    "\n",
    "# Define the Contextual Compression Retriever\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=docsearch.as_retriever()  # Ensure 'docsearch' is defined earlier in your code\n",
    ")\n",
    "\n",
    "# Initialize NeMo Guardrails\n",
    "config = RailsConfig.from_path(\"./config\")  # Make sure config is properly set up\n",
    "rails = LLMRails(config)\n",
    "\n",
    "# Function to rerank query results and generate a response for the /complete endpoint\n",
    "def rerank_and_generate_response(user_query: str):\n",
    "    # Perform reranking using NVIDIA reranker\n",
    "    documents = compression_retriever.get_relevant_documents(user_query)\n",
    "    context_str = \"\\n\".join([doc.page_content for doc in documents[:3]])  # Get top 3 documents\n",
    "\n",
    "    # Generate a prompt for the assistant using the reranked documents\n",
    "    prompt = f\"\"\"\n",
    "    You are an assistant that answers queries using CUDA-related knowledge.\n",
    "    Based on the following relevant documents, answer the user's query.\n",
    "    \n",
    "    Relevant Documents (Top 3): \n",
    "    {context_str[:1200]}  # Ensuring the context doesn't exceed 1200 tokens\n",
    "\n",
    "    User Query: {user_query}\n",
    "    \n",
    "    Answer (Max 750 tokens):\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate response using NeMo Guardrails\n",
    "    response = rails.generate(messages=[\n",
    "        {\"role\": \"user\", \"content\": user_query},\n",
    "        {\"role\": \"assistant\", \"content\": prompt}\n",
    "    ])\n",
    "\n",
    "    # Return the assistant's response and the context used\n",
    "    return {\n",
    "        \"answer\": response['content'][:750],  # Ensuring answer doesn't exceed 750 tokens\n",
    "        \"contexts\": context_str[:1200]  # Ensuring contexts don't exceed 1200 tokens\n",
    "    }\n",
    "\n",
    "# Function to reset the session for the /reset endpoint by reinitializing the LLMRails object\n",
    "def reset_conversation():\n",
    "    global rails  # Use global to reset the rails object\n",
    "    rails = LLMRails(config)  # Reinitialize the LLMRails to simulate session reset\n",
    "    return {\"status\": \"Conversation reset successfully.\"}\n",
    "\n",
    "# Example usage for /complete and /reset endpoints\n",
    "def complete_endpoint(user_query: str):\n",
    "    result = rerank_and_generate_response(user_query)\n",
    "    print(result)\n",
    "\n",
    "def reset_endpoint():\n",
    "    reset_status = reset_conversation()\n",
    "    print(reset_status)\n",
    "\n",
    "# Main function to demonstrate the endpoints\n",
    "def main():\n",
    "    # Simulate the /complete endpoint\n",
    "    user_query = \"How does CUDA manage references to user objects when a cudaGraphExec_t is destroyed without being synchronized?\"\n",
    "    complete_endpoint(user_query)\n",
    "\n",
    "    # Simulate the /reset endpoint\n",
    "    reset_endpoint()\n",
    "\n",
    "# Run the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "26b3a6ff-d324-45d2-ba9b-c97fb5d84705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please enter your CUDA-related question:  explain cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected Intent: cuda_explanation\n",
      "Response: CUDA unified memory allows seamless data access across CPUs and GPUs.\n"
     ]
    }
   ],
   "source": [
    "# Mock of user intents\n",
    "def detect_user_intent(user_query):\n",
    "    \"\"\"\n",
    "    A function to detect the user intent based on the query.\n",
    "    This mock function returns the intent based on keywords in the user query.\n",
    "    \"\"\"\n",
    "    if \"generate code\" in user_query.lower() or \"generate\" in user_query.lower():\n",
    "        return \"code_generation\"\n",
    "    elif \"debug\" in user_query.lower() or \"crash\" in user_query.lower():\n",
    "        return \"code_debugging\"\n",
    "    elif \"what is\" in user_query.lower() or \"explain\" in user_query.lower():\n",
    "        return \"cuda_explanation\"\n",
    "    else:\n",
    "        return \"general_question\"\n",
    "\n",
    "# Mock response generation function for each intent\n",
    "def generate_response_for_intent(user_query, intent):\n",
    "    if intent == \"code_generation\":\n",
    "        return generate_cuda_code(user_query)\n",
    "    elif intent == \"code_debugging\":\n",
    "        return debug_cuda_code(user_query)\n",
    "    elif intent == \"cuda_explanation\":\n",
    "        return explain_cuda_concept(user_query)\n",
    "    elif intent == \"general_question\":\n",
    "        return answer_general_question(user_query)\n",
    "    else:\n",
    "        return \"Sorry, I couldn't understand your query.\"\n",
    "\n",
    "# Mock functions for handling each intent\n",
    "def generate_cuda_code(user_query):\n",
    "    return \"Here’s a sample CUDA code based on your query.\"\n",
    "\n",
    "def debug_cuda_code(user_query):\n",
    "    return \"Based on your description, here's a possible issue and solution for debugging.\"\n",
    "\n",
    "def explain_cuda_concept(user_query):\n",
    "    return \"CUDA unified memory allows seamless data access across CPUs and GPUs.\"\n",
    "\n",
    "def answer_general_question(user_query):\n",
    "    return \"CUDA stands for Compute Unified Device Architecture, a parallel computing platform and API model by NVIDIA.\"\n",
    "\n",
    "# Main function to test user intent detection and response generation\n",
    "def main():\n",
    "    # Simulate a user query\n",
    "    user_query = input(\"Please enter your CUDA-related question: \")\n",
    "    \n",
    "    # Step 1: Detect the user's intent\n",
    "    detected_intent = detect_user_intent(user_query)\n",
    "    print(f\"Detected Intent: {detected_intent}\")\n",
    "    \n",
    "    # Step 2: Generate the appropriate response based on the detected intent\n",
    "    response = generate_response_for_intent(user_query, detected_intent)\n",
    "    print(f\"Response: {response}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "8bc8d28c-b978-4aae-bc0d-a36b1701f94a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/cleanlab/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/cleanlab/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/sensitive_data_detection/flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/sensitive_data_detection/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/autoalign/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/autoalign/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/gotitai/flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/gotitai/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/llama_guard/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/llama_guard/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/content_safety/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/content_safety/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/hallucination/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/hallucination/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/jailbreak_detection/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/jailbreak_detection/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/patronusai/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/patronusai/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/factchecking/align_score/flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/factchecking/align_score/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/self_check/facts/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/self_check/facts/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/self_check/input_check/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/self_check/input_check/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/self_check/output_check/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/self_check/output_check/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/activefence/flows.v1.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.v1.co\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/activefence/flows.co\n",
      "DEBUG:nemoguardrails.colang:Skipping parsing of flows.co because it is not a v1.0 file.\n",
      "DEBUG:nemoguardrails.rails.llm.llmrails:Loading file: /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/nemoguardrails/rails/llm/../../library/gcp_moderate_text/flows.co\n",
      "DEBUG:nemoguardrails.colang.v1_0.lang.parser:Found markdown content in flows.co\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Initializing action dispatcher\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file core.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added create_event to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file retrieve_relevant_chunks.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added retrieve_relevant_chunks to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file math.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added wolfram alpha request to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file action_dispatcher.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file summarize_document.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added summarize_document to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file generation.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file base.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file filter_secrets.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file utils.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file generation.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file safetools.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added call cleanlab api to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added detect_sensitive_data to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added mask_sensitive_data to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added autoalign_factcheck_output_api to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added autoalign_input_api to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added autoalign_output_api to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added call gotitai truthchecker api to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added llama_guard_check_input to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added llama_guard_check_output to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added content_safety_check_input to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added content_safety_check_output to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added self_check_hallucination to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added jailbreak_detection_heuristics to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added patronus_lynx_check_output_hallucination to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added alignscore_check_facts to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added alignscore request to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added self_check_facts to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added self_check_facts to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added self_check_input to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added self_check_output to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added call activefence api to actions\n",
      "DEBUG:nemoguardrails.actions.action_dispatcher:Analyzing file actions.py\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Added call gcpnlp api to actions\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Registered Actions :: ['alignscore request', 'alignscore_check_facts', 'autoalign_factcheck_output_api', 'autoalign_input_api', 'autoalign_output_api', 'call activefence api', 'call cleanlab api', 'call gcpnlp api', 'call gotitai truthchecker api', 'content_safety_check_input', 'content_safety_check_output', 'create_event', 'detect_sensitive_data', 'jailbreak_detection_heuristics', 'llama_guard_check_input', 'llama_guard_check_output', 'mask_sensitive_data', 'patronus_lynx_check_output_hallucination', 'retrieve_relevant_chunks', 'self_check_facts', 'self_check_hallucination', 'self_check_input', 'self_check_output', 'summarize_document', 'wolfram alpha request']\n",
      "INFO:nemoguardrails.actions.action_dispatcher:Action dispatcher initialized\n",
      "DEBUG:asyncio:Using selector: EpollSelector\n",
      "DEBUG:asyncio:Using selector: EpollSelector\n",
      "2024-10-11 01:27:14.165 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-11 01:27:14.165 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-11 01:27:14.165 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-11 01:27:14.166 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-11 01:27:14.166 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-11 01:27:14.166 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-11 01:27:14.167 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-11 01:27:14.167 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-11 01:27:14.167 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-11 01:27:14.167 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-11 01:27:14.168 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-11 01:27:14.168 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-11 01:27:14.168 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-11 01:27:14.169 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-11 01:27:14.169 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-11 01:27:14.169 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-11 01:27:14.169 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-11 01:27:14.170 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain_nvidia_ai_endpoints import NVIDIARerank\n",
    "from nemoguardrails import LLMRails, RailsConfig\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Initialize the reranker (NVIDIA reranker)\n",
    "compressor = NVIDIARerank(model=\"nvidia/nv-rerankqa-mistral-4b-v3\", base_url=\"http://localhost:11737/v1\")\n",
    "\n",
    "# Define the Contextual Compression Retriever\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=docsearch.as_retriever()  # Ensure 'docsearch' is defined earlier in your code\n",
    ")\n",
    "\n",
    "# Initialize NeMo Guardrails\n",
    "config = RailsConfig.from_path(\"./config\")\n",
    "rails = LLMRails(config)\n",
    "\n",
    "# Function to rerank query results and generate a response for the /complete endpoint\n",
    "def rerank_and_generate_response(user_query: str):\n",
    "    # Perform reranking using NVIDIA reranker\n",
    "    documents = compression_retriever.get_relevant_documents(user_query)\n",
    "    context_str = \"\\n\".join([doc.page_content for doc in documents[:3]])  # Get top 3 documents\n",
    "\n",
    "    # Generate a prompt for the assistant using the reranked documents\n",
    "    prompt = f\"\"\"\n",
    "    You are an assistant that answers queries using CUDA-related knowledge.\n",
    "    Based on the following relevant documents, answer the user's query.\n",
    "    \n",
    "    Relevant Documents (Top 3): \n",
    "    {context_str[:1200]}  # Ensuring the context doesn't exceed 1200 tokens\n",
    "\n",
    "    User Query: {user_query}\n",
    "    \n",
    "    Answer (Max 750 tokens):\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate response using NeMo Guardrails\n",
    "    response = rails.generate(messages=[\n",
    "        {\"role\": \"user\", \"content\": user_query},\n",
    "        {\"role\": \"assistant\", \"content\": prompt}\n",
    "    ])\n",
    "\n",
    "    # Return the assistant's response and the context used\n",
    "    return {\n",
    "        \"answer\": response['content'][:750],  # Ensuring answer doesn't exceed 750 tokens\n",
    "        \"contexts\": context_str[:1200]  # Ensuring contexts don't exceed 1200 tokens\n",
    "    }\n",
    "\n",
    "# Function to reset the session for the /reset endpoint by reinitializing the LLMRails object\n",
    "def reset_conversation():\n",
    "    global rails  # Use global to reset the rails object\n",
    "    rails = LLMRails(config)  # Reinitialize the LLMRails to simulate session reset\n",
    "    return {\"status\": \"Conversation reset successfully.\"}\n",
    "\n",
    "# Streamlit UI\n",
    "st.title(\"CUDA Query Assistant\")\n",
    "\n",
    "# User input for query\n",
    "user_query = st.text_input(\"Enter your CUDA-related query:\")\n",
    "\n",
    "# Submit button to query the assistant\n",
    "if st.button(\"Submit Query\"):\n",
    "    if user_query:\n",
    "        result = rerank_and_generate_response(user_query)\n",
    "        st.subheader(\"Answer:\")\n",
    "        st.write(result[\"answer\"])\n",
    "        \n",
    "        st.subheader(\"Contexts:\")\n",
    "        st.write(result[\"contexts\"])\n",
    "    else:\n",
    "        st.warning(\"Please enter a query.\")\n",
    "\n",
    "# Button to reset the conversation\n",
    "if st.button(\"Reset Conversation\"):\n",
    "    reset_status = reset_conversation()\n",
    "    st.success(reset_status[\"status\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "9e0facc1-80d5-4867-82ce-99bf18c5bba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting streamlit\n",
      "  Downloading streamlit-1.39.0-py2.py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting altair<6,>=4.0 (from streamlit)\n",
      "  Downloading altair-5.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting blinker<2,>=1.0.0 (from streamlit)\n",
      "  Downloading blinker-1.8.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting cachetools<6,>=4.0 (from streamlit)\n",
      "  Downloading cachetools-5.5.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: click<9,>=7.0 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from streamlit) (8.1.7)\n",
      "Requirement already satisfied: numpy<3,>=1.20 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from streamlit) (1.26.4)\n",
      "Requirement already satisfied: packaging<25,>=20 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from streamlit) (24.1)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from streamlit) (2.2.3)\n",
      "Requirement already satisfied: pillow<11,>=7.1.0 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from streamlit) (10.4.0)\n",
      "Requirement already satisfied: protobuf<6,>=3.20 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from streamlit) (5.28.2)\n",
      "Requirement already satisfied: pyarrow>=7.0 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from streamlit) (17.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from streamlit) (2.32.3)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from streamlit) (13.9.2)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from streamlit) (8.5.0)\n",
      "Collecting toml<2,>=0.10.1 (from streamlit)\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from streamlit) (4.12.2)\n",
      "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
      "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
      "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from streamlit) (6.4.1)\n",
      "Requirement already satisfied: watchdog<6,>=2.1.5 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from streamlit) (5.0.3)\n",
      "Requirement already satisfied: jinja2 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
      "Collecting narwhals>=1.5.2 (from altair<6,>=4.0->streamlit)\n",
      "  Downloading narwhals-1.9.2-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from requests<3,>=2.27->streamlit) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from requests<3,>=2.27->streamlit) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from requests<3,>=2.27->streamlit) (2024.7.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.16.0)\n",
      "Downloading streamlit-1.39.0-py2.py3-none-any.whl (8.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading altair-5.4.1-py3-none-any.whl (658 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m658.1/658.1 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading blinker-1.8.2-py3-none-any.whl (9.5 kB)\n",
      "Downloading cachetools-5.5.0-py3-none-any.whl (9.5 kB)\n",
      "Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
      "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "Downloading narwhals-1.9.2-py3-none-any.whl (185 kB)\n",
      "Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: toml, smmap, narwhals, cachetools, blinker, pydeck, gitdb, gitpython, altair, streamlit\n",
      "Successfully installed altair-5.4.1 blinker-1.8.2 cachetools-5.5.0 gitdb-4.0.11 gitpython-3.1.43 narwhals-1.9.2 pydeck-0.9.1 smmap-5.0.1 streamlit-1.39.0 toml-0.10.2\n"
     ]
    }
   ],
   "source": [
    "!pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "3de8785b-9618-46db-b789-39cfa0d03620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: streamlit run [OPTIONS] TARGET [ARGS]...\n",
      "Try 'streamlit run --help' for help.\n",
      "\n",
      "Error: Invalid value: File does not exist: UI.py\n"
     ]
    }
   ],
   "source": [
    "! streamlit run UI.py --server.port 9552 --server.address 0.0.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "a7326b42-772a-44ea-9dfe-71898bfb3a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
      "\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:9553\u001b[0m\n",
      "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://10.184.92.71:9553\u001b[0m\n",
      "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://72.25.68.5:9553\u001b[0m\n",
      "\u001b[0m\n",
      "^C\n",
      "\u001b[34m  Stopping...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! streamlit run /mnt/lustre/hackathons/hack_teams/hack_team_16/workspace/Jishnu/config/UI.py --server.port 9553 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a2c40aa-a8ce-436d-9033-b55f9e1899c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES\n"
     ]
    }
   ],
   "source": [
    "!docker ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b5ea49-a148-4e83-92e4-4a38012c111a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
