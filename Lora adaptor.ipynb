{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b2316be0-5e46-4c1c-a9ba-32877212e2d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your NVIDIA API key:  ········\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "if not os.environ.get(\"NVIDIA_API_KEY\", \"\").startswith(\"nvapi-\"):\n",
    "    nvapi_key = getpass.getpass(\"Enter your NVIDIA API key: \")\n",
    "    assert nvapi_key.startswith(\"nvapi-\"), f\"{nvapi_key[:5]}... is not a valid key\"\n",
    "    os.environ[\"NVIDIA_API_KEY\"] = nvapi_key\n",
    "    os.environ[\"NGC_API_KEY\"] = nvapi_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aee29a07-5c61-4ba9-8755-4092996ba447",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING! Your password will be stored unencrypted in /home/gsh-3atzc7/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n"
     ]
    }
   ],
   "source": [
    "! echo -e \"$NGC_API_KEY\" | docker login nvcr.io --username '$oauthtoken' --password-stdin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "74399b22-8f49-4017-8fde-49a360d72da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create loras directory\n",
    "!mkdir -p loras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dde0092-5721-486b-b091-a3bf015aba95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b592097-d03e-412d-a923-61c91157bc78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"ajsbsd/nvidia-qa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "275fe702-a4e4-49a9-ad70-ba54335e81ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds[\"train\"].train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06e317c2-0142-4236-b574-ba8bc9c037a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ****************************************************************\n",
      "{'Unnamed: 0': 1209, 'question': 'How does the nvJitLink library improve upon the previous JIT LTO implementation in CUDA 11.4?', 'answer': 'The nvJitLink library introduced in CUDA Toolkit 12.0 improves upon the previous CUDA 11.4 implementation of JIT LTO. It offers a more streamlined approach by eliminating the dependency on the CUDA driver and providing compatibility guarantees through the CUDA Toolkit.'}\n",
      "****************************************************************\n",
      "\n",
      " ****************************************************************\n",
      "{'Unnamed: 0': 259, 'question': 'What difficulty has been associated with understanding compiler heuristics on inlining?', 'answer': 'Understanding compiler heuristics on inlining has been difficult without heavy post-processing of assembly output.'}\n",
      "****************************************************************\n",
      "\n",
      " ****************************************************************\n",
      "{'Unnamed: 0': 6732, 'question': 'What is the benefit of using NVIDIA GPUs in high-performance computing (HPC)?', 'answer': 'NVIDIA GPUs are known for their parallel processing capabilities, making them ideal for accelerating scientific simulations and data-intensive tasks in HPC.'}\n",
      "****************************************************************\n",
      "\n",
      " ****************************************************************\n",
      "{'Unnamed: 0': 3116, 'question': 'What is the purpose of the Thrust library in CUDA 7?', 'answer': 'The Thrust library in CUDA 7 provides efficient and composable parallel algorithms that operate on vector containers. It brings a familiar abstraction layer similar to the C++ Standard Template Library to the realm of parallel computing.'}\n",
      "****************************************************************\n",
      "\n",
      " ****************************************************************\n",
      "{'Unnamed: 0': 3519, 'question': 'What is the crucial factor when using JIT LTO with the nvJitLink library?', 'answer': 'To maintain compatibility, developers must ensure that the version of the nvJitLink library on the target system matches the toolkit version of NVCC or NVRTC.'}\n",
      "****************************************************************\n"
     ]
    }
   ],
   "source": [
    "for sample in ds['train'].select(range(5)):\n",
    "    print(f\"\\n {'*' * 64}\\n{sample}\\n{'*' * 64}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79b4747b-de13-4000-8d64-ff25f3d75f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langdetect\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: six in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from langdetect) (1.16.0)\n",
      "Building wheels for collected packages: langdetect\n",
      "  Building wheel for langdetect (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993227 sha256=4603535347a903f0bd04e834d461ff948e5fa8659c395400b9b0f6d957908e9f\n",
      "  Stored in directory: /home/gsh-3atzc7/.cache/pip/wheels/d1/c1/d9/7e068de779d863bc8f8fc9467d85e25cfe47fa5051fff1a1bb\n",
      "Successfully built langdetect\n",
      "Installing collected packages: langdetect\n",
      "Successfully installed langdetect-1.0.9\n"
     ]
    }
   ],
   "source": [
    "!pip install langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d275e6a9-2cfb-4915-b8e7-ba287a83c487",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "\n",
    "def remove_nonEnglish_rows(ds):\n",
    "    # Initialize an empty list to store rows detected as English\n",
    "    new_ds = []\n",
    "    \n",
    "    # Initialize a list to store indices of rows that cause issues (corner cases)\n",
    "    corner_case = []\n",
    "    \n",
    "    # Iterate through each row in the dataset's 'text' column\n",
    "    for i, row in enumerate(ds['question']):\n",
    "        try:\n",
    "            # Detect the language of the text\n",
    "            if detect(str(row)) == 'en':\n",
    "                # If the language is English, add the row to new_ds\n",
    "                new_ds.append(row)\n",
    "        except:\n",
    "            # If an exception occurs, add the index to corner_case\n",
    "            corner_case.append(i)\n",
    "    \n",
    "    # Return the list of English rows and the indices of corner cases\n",
    "    return new_ds, corner_case\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b9f85fd-5af8-4163-95d3-3aca368b7dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of training samples:  5650\n"
     ]
    }
   ],
   "source": [
    "\n",
    "filter_train_samples,cc_train = remove_nonEnglish_rows(ds['train'])\n",
    "\n",
    "print(\"Count of training samples: \",len(filter_train_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d8b51d4-ddd8-453a-a0ee-feece61f256e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of testing samples:  1413\n"
     ]
    }
   ],
   "source": [
    "filter_test_samples,cc_test = remove_nonEnglish_rows(ds['test'])\n",
    "print(\"Count of testing samples: \",len(filter_test_samples))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c840d98-fd5b-4ed0-a88c-606784b1481d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save English text samples\n",
    "import json\n",
    "def save_jsonl(ds,filename):\n",
    "    with open(f\"data/{filename}.jsonl\", \"w\") as write_file:\n",
    "            json.dump(ds, write_file, indent=4)\n",
    "            print(\"dataset saved in jsonl format ....\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c82ccbb-acfd-4d2c-aa12-92e260b2e1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_to_template(example):\n",
    "    conversation_text = example['text']\n",
    "    segments = conversation_text.split(\"###\")[1:]\n",
    "    \n",
    "\n",
    "    for idx,segment in enumerate(segments):\n",
    "        if idx%2==0:\n",
    "            segments[idx] = segment.replace('Human:',\"<|start_header_id|>user<|end_header_id|>\") + \"<|eot_id|>\"\n",
    "        else:\n",
    "            segments[idx] = segment.replace('Assistant:',\"<|start_header_id|>assistant<|end_header_id|>\") + \"<|eot_id|>\"\n",
    "    \n",
    "    \n",
    "\n",
    "    segments = [\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are a helpful assistant<|eot_id|>\"] + segments\n",
    "\n",
    "    return {'text': ''.join(segments)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86e90830-73de-4cd8-8c57-8b3e19b02a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir -p data\n",
    "! mkdir -p data/filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84f0c070-52c8-4f76-b916-d2083b72a10e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset saved in jsonl format ....\n",
      "dataset saved in jsonl format ....\n"
     ]
    }
   ],
   "source": [
    "# set file names  \n",
    "save_train_filename = 'filtered/train'\n",
    "save_test_filename = 'filtered/test'\n",
    "\n",
    "# save file\n",
    "save_jsonl(filter_train_samples, save_train_filename)\n",
    "save_jsonl(filter_test_samples, save_test_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f592fc3b-067c-483f-87c0-3972c66526f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce496414-174e-4426-a396-e2d9e9dbf876",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 5650 examples [00:00, 128151.73 examples/s]\n",
      "Generating test split: 1413 examples [00:00, 34353.63 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('data/filtered/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed44f625-d4db-4ef7-be39-7cd93e4926d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 5650/5650 [00:00<00:00, 19244.69 examples/s]\n",
      "Map: 100%|██████████| 1413/1413 [00:00<00:00, 9158.93 examples/s]\n"
     ]
    }
   ],
   "source": [
    "template_dataset = dataset.map(transform_to_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16696989-a6b7-4ab0-bf7c-04434c173a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 5650/5650 [00:00<00:00, 1035743.78 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1413/1413 [00:00<00:00, 439948.89 examples/s]\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p data/ds_preprocess\n",
    "template_dataset.save_to_disk('data/ds_preprocess/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f45fbd-0e91-4a9e-83fd-00a7ccfb75b9",
   "metadata": {},
   "source": [
    "<h3>Training</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c733d1d4-e332-42cd-a73d-da9b0313f7ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (2.0.0)\n",
      "Requirement already satisfied: filelock in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from torch) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from torch) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from torch) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from torch) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from torch) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from torch) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from torch) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from torch) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from torch) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from torch) (2.0.0)\n",
      "Requirement already satisfied: setuptools in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (69.5.1)\n",
      "Requirement already satisfied: wheel in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.43.0)\n",
      "Requirement already satisfied: cmake in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from triton==2.0.0->torch) (3.30.4)\n",
      "Requirement already satisfied: lit in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from triton==2.0.0->torch) (18.1.8)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f9a5cac1-6414-4292-9cee-9f8c2a93f429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In some cases where you have access to limited computing resources, you might have to uncomment os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:64\" if you run into not enough memory issue \n",
    "\n",
    "import os\n",
    "import torch\n",
    "import json\n",
    "import re\n",
    "\n",
    "from peft import LoraConfig, PeftModel\n",
    "from trl import SFTTrainer\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from langdetect import detect\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "\n",
    "# os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:64\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34deb95-6a69-4488-ba1d-fa0771bbc04b",
   "metadata": {},
   "source": [
    "Setting up the important paths for loading and saving important artifacts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72196a3c-e80f-42bb-8951-a3e53931a6e3",
   "metadata": {},
   "source": [
    "Llama-3 family of models are open source but require an access request approval. For the bootcamp environment, the weights have already been converted to huggingface compatible format and stored at a shared location for quicker access for the participants. \n",
    "\n",
    "In case of running the material on your own environment, please request access for Llama models from [here](https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct) and generate your HuggingFace user access token from this [link](https://huggingface.co/settings/tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "091c7be5-61f2-4e57-a0d7-fa006fcd6285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize path to the base model \n",
    "# base_model = \"meta-llama/Meta-Llama-3-8B-Instruct\" # Use this while running the material in your own standalone environment.\n",
    "\n",
    "base_model = \"/raid/tmp/docker-container-storage-2072/overlay2\" # shared model weight location\n",
    "\n",
    "# set the path to the dataset template\n",
    "data_path = \"data/ds_preprocess/train\"\n",
    "# set the path to the dataset template\n",
    "eval_path = \"data/ds_preprocess/test\"\n",
    "\n",
    "# load the transformed dataset\n",
    "dataset = load_from_disk(data_path)\n",
    "eval_dataset = load_from_disk(eval_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "502b67a6-67dc-4ddf-a976-504137b92f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client:\n",
      " Version:    24.0.7\n",
      " Context:    default\n",
      " Debug Mode: false\n",
      "\n",
      "Server:\n",
      " Containers: 6\n",
      "  Running: 3\n",
      "  Paused: 0\n",
      "  Stopped: 3\n",
      " Images: 3\n",
      " Server Version: 24.0.7\n",
      " Storage Driver: overlay2\n",
      "  Backing Filesystem: xfs\n",
      "  Supports d_type: true\n",
      "  Using metacopy: false\n",
      "  Native Overlay Diff: false\n",
      "  userxattr: true\n",
      " Logging Driver: json-file\n",
      " Cgroup Driver: none\n",
      " Cgroup Version: 1\n",
      " Plugins:\n",
      "  Volume: local\n",
      "  Network: bridge host ipvlan macvlan null overlay\n",
      "  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog\n",
      " Swarm: inactive\n",
      " Runtimes: io.containerd.runc.v2 runc\n",
      " Default Runtime: runc\n",
      " Init Binary: docker-init\n",
      " containerd version: 091922f03c2762540fd057fba91260237ff86acb\n",
      " runc version: v1.1.9-0-gccaecfc\n",
      " init version: de40ad0\n",
      " Security Options:\n",
      "  seccomp\n",
      "   Profile: builtin\n",
      "  rootless\n",
      " Kernel Version: 5.15.0-1029-nvidia\n",
      " Operating System: Ubuntu 22.04.2 LTS\n",
      " OSType: linux\n",
      " Architecture: x86_64\n",
      " CPUs: 256\n",
      " Total Memory: 1.968TiB\n",
      " Name: dgx01\n",
      " ID: 8c29f74a-22f3-4387-9c08-d30551f47ca7\n",
      " Docker Root Dir: /raid/tmp/docker-container-storage-2072\n",
      " Debug Mode: false\n",
      " Experimental: true\n",
      " Insecure Registries:\n",
      "  127.0.0.0/8\n",
      " Live Restore Enabled: false\n",
      " Product License: Community Engine\n",
      "\n",
      "WARNING: Running in rootless-mode without cgroups. To enable cgroups in rootless-mode, you need to boot the system in cgroup v2 mode.\n"
     ]
    }
   ],
   "source": [
    "!docker info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7c09c3bf-f32d-4321-ba7d-cadd4208df63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed for standalone run\n",
    "token='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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "51acdb73-e49a-469a-8d92-f5698b93737b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (4.45.1)\n",
      "Requirement already satisfied: filelock in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from transformers) (0.25.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from transformers) (0.20.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from requests->transformers) (2024.7.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3b3ccdbf-e3c0-4278-92af-a5340fb383be",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A configuraton of type rag cannot be instantiated because both `question_encoder` and `generator` sub-configurations were not passed, only {'attn_implementation': None}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mAutoTokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                                          \u001b[49m\u001b[38;5;66;43;03m# token=token,\u001b[39;49;00m\n\u001b[1;32m      3\u001b[0m \u001b[43m                                          \u001b[49m\u001b[38;5;66;43;03m# trust_remote_code=True\u001b[39;49;00m\n\u001b[1;32m      4\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/nim_env/lib/python3.9/site-packages/transformers/models/auto/tokenization_auto.py:864\u001b[0m, in \u001b[0;36mAutoTokenizer.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    862\u001b[0m         config \u001b[38;5;241m=\u001b[39m AutoConfig\u001b[38;5;241m.\u001b[39mfor_model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig_dict)\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 864\u001b[0m         config \u001b[38;5;241m=\u001b[39m \u001b[43mAutoConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    867\u001b[0m config_tokenizer_class \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mtokenizer_class\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(config, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutoTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mauto_map:\n",
      "File \u001b[0;32m~/.conda/envs/nim_env/lib/python3.9/site-packages/transformers/models/auto/configuration_auto.py:1036\u001b[0m, in \u001b[0;36mAutoConfig.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m   1034\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m pattern \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(CONFIG_MAPPING\u001b[38;5;241m.\u001b[39mkeys(), key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m, reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m   1035\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m pattern \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(pretrained_model_name_or_path):\n\u001b[0;32m-> 1036\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mCONFIG_MAPPING\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43munused_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1038\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1039\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized model in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1040\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould have a `model_type` key in its \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCONFIG_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, or contain one of the following strings \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1041\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min its name: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(CONFIG_MAPPING\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1042\u001b[0m )\n",
      "File \u001b[0;32m~/.conda/envs/nim_env/lib/python3.9/site-packages/transformers/configuration_utils.py:711\u001b[0m, in \u001b[0;36mPretrainedConfig.from_dict\u001b[0;34m(cls, config_dict, **kwargs)\u001b[0m\n\u001b[1;32m    708\u001b[0m \u001b[38;5;66;03m# We remove it from kwargs so that it does not appear in `return_unused_kwargs`.\u001b[39;00m\n\u001b[1;32m    709\u001b[0m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattn_implementation\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattn_implementation\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 711\u001b[0m config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(config, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpruned_heads\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    714\u001b[0m     config\u001b[38;5;241m.\u001b[39mpruned_heads \u001b[38;5;241m=\u001b[39m {\u001b[38;5;28mint\u001b[39m(key): value \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mpruned_heads\u001b[38;5;241m.\u001b[39mitems()}\n",
      "File \u001b[0;32m~/.conda/envs/nim_env/lib/python3.9/site-packages/transformers/models/rag/configuration_rag.py:128\u001b[0m, in \u001b[0;36mRagConfig.__init__\u001b[0;34m(self, vocab_size, is_encoder_decoder, prefix, bos_token_id, pad_token_id, eos_token_id, decoder_start_token_id, title_sep, doc_sep, n_docs, max_combined_length, retrieval_vector_size, retrieval_batch_size, dataset, dataset_split, index_name, index_path, passages_path, use_dummy_dataset, reduce_loss, label_smoothing, do_deduplication, exclude_bos_score, do_marginalize, output_retrieved, use_cache, forced_eos_token_id, dataset_revision, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    117\u001b[0m     bos_token_id\u001b[38;5;241m=\u001b[39mbos_token_id,\n\u001b[1;32m    118\u001b[0m     pad_token_id\u001b[38;5;241m=\u001b[39mpad_token_id,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    126\u001b[0m )\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion_encoder\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[0;32m--> 128\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    129\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA configuraton of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m cannot be instantiated because \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    130\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mboth `question_encoder` and `generator` sub-configurations were not passed, only \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    131\u001b[0m     )\n\u001b[1;32m    132\u001b[0m question_encoder_config \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion_encoder\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    133\u001b[0m question_encoder_model_type \u001b[38;5;241m=\u001b[39m question_encoder_config\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: A configuraton of type rag cannot be instantiated because both `question_encoder` and `generator` sub-configurations were not passed, only {'attn_implementation': None}"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(base_model,\n",
    "                                          # token=token,\n",
    "                                          # trust_remote_code=True\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b4f37363-be70-4683-8ffd-2c690896722b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'DPRQuestionEncoderTokenizer'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'DPRQuestionEncoderTokenizerFast'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'BartTokenizer'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'BartTokenizerFast'.\n"
     ]
    }
   ],
   "source": [
    "from transformers import RagTokenizer\n",
    "\n",
    "# Load the RAG tokenizer with specified models\n",
    "tokenizer = RagTokenizer.from_pretrained(\n",
    "    \"facebook/rag-token-nq\",  # Specify a valid RAG model name\n",
    "    use_auth_token=token  # Include token if required for private models\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "351304fc-96cb-433e-9822-667a4259460b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/transformers/models/bart/configuration_bart.py:176: UserWarning: Please make sure the config includes `forced_bos_token_id=0` in future versions. The config can simply be saved and uploaded again to be fixed.\n",
      "  warnings.warn(\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'DPRQuestionEncoderTokenizer'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'DPRQuestionEncoderTokenizerFast'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'BartTokenizer'.\n",
      "/home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'BartTokenizerFast'.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nRagRetriever requires the faiss library but it was not found in your environment. Checkout the instructions on the\ninstallation page of its repo: https://github.com/facebookresearch/faiss/blob/master/INSTALL.md and follow the ones\nthat match your environment. Please note that you may need to restart your runtime after installation.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m generator_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacebook/bart-large\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Load the RAG retriever\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m retriever \u001b[38;5;241m=\u001b[39m \u001b[43mRagRetriever\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfacebook/rag-token-nq\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexact\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Choose the index type\u001b[39;49;00m\n\u001b[1;32m     14\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Instantiate the RAG model\u001b[39;00m\n\u001b[1;32m     17\u001b[0m model \u001b[38;5;241m=\u001b[39m RagTokenForGeneration\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacebook/rag-token-nq\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     19\u001b[0m     retriever\u001b[38;5;241m=\u001b[39mretriever,\n\u001b[1;32m     20\u001b[0m     question_encoder\u001b[38;5;241m=\u001b[39mquestion_encoder_model,\n\u001b[1;32m     21\u001b[0m     generator\u001b[38;5;241m=\u001b[39mgenerator_model,\n\u001b[1;32m     22\u001b[0m )\n",
      "File \u001b[0;32m~/.conda/envs/nim_env/lib/python3.9/site-packages/transformers/models/rag/retrieval_rag.py:442\u001b[0m, in \u001b[0;36mRagRetriever.from_pretrained\u001b[0;34m(cls, retriever_name_or_path, indexed_dataset, **kwargs)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_pretrained\u001b[39m(\u001b[38;5;28mcls\u001b[39m, retriever_name_or_path, indexed_dataset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 442\u001b[0m     \u001b[43mrequires_backends\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdatasets\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfaiss\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    443\u001b[0m     config \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m RagConfig\u001b[38;5;241m.\u001b[39mfrom_pretrained(retriever_name_or_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    444\u001b[0m     rag_tokenizer \u001b[38;5;241m=\u001b[39m RagTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(retriever_name_or_path, config\u001b[38;5;241m=\u001b[39mconfig)\n",
      "File \u001b[0;32m~/.conda/envs/nim_env/lib/python3.9/site-packages/transformers/utils/import_utils.py:1625\u001b[0m, in \u001b[0;36mrequires_backends\u001b[0;34m(obj, backends)\u001b[0m\n\u001b[1;32m   1623\u001b[0m failed \u001b[38;5;241m=\u001b[39m [msg\u001b[38;5;241m.\u001b[39mformat(name) \u001b[38;5;28;01mfor\u001b[39;00m available, msg \u001b[38;5;129;01min\u001b[39;00m checks \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m available()]\n\u001b[1;32m   1624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m failed:\n\u001b[0;32m-> 1625\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(failed))\n",
      "\u001b[0;31mImportError\u001b[0m: \nRagRetriever requires the faiss library but it was not found in your environment. Checkout the instructions on the\ninstallation page of its repo: https://github.com/facebookresearch/faiss/blob/master/INSTALL.md and follow the ones\nthat match your environment. Please note that you may need to restart your runtime after installation.\n"
     ]
    }
   ],
   "source": [
    "from transformers import RagTokenizer, RagRetriever, RagTokenForGeneration\n",
    "\n",
    "# Load the tokenizer for RAG\n",
    "tokenizer = RagTokenizer.from_pretrained(\"facebook/rag-token-nq\")\n",
    "\n",
    "# Load the question encoder and generator configurations\n",
    "question_encoder_model = \"facebook/dpr-question_encoder-single-nq-base\"\n",
    "generator_model = \"facebook/bart-large\"\n",
    "\n",
    "# Load the RAG retriever\n",
    "retriever = RagRetriever.from_pretrained(\n",
    "    \"facebook/rag-token-nq\",\n",
    "    index_name=\"exact\",  # Choose the index type\n",
    ")\n",
    "\n",
    "# Instantiate the RAG model\n",
    "model = RagTokenForGeneration.from_pretrained(\n",
    "    \"facebook/rag-token-nq\",\n",
    "    retriever=retriever,\n",
    "    question_encoder=question_encoder_model,\n",
    "    generator=generator_model,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d2a7a584-3afe-4384-b0b8-35021424cf2e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RagTokenizer' object has no attribute 'eos_token'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tokenizer\u001b[38;5;241m.\u001b[39mpad_token \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token\u001b[49m\n\u001b[1;32m      2\u001b[0m tokenizer\u001b[38;5;241m.\u001b[39mpadding_side \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'RagTokenizer' object has no attribute 'eos_token'"
     ]
    }
   ],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "46f30d8d-a71f-47d7-938e-fd5f3e8c37a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir -p model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c991ff6c-ca5b-448c-86db-cab807393d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_params = TrainingArguments(\n",
    "    output_dir=\"model/results\",             # Directory to save the model results\n",
    "    num_train_epochs=2,                     # Number of training epochs\n",
    "    per_device_train_batch_size=5,          # Batch size per device during training\n",
    "    gradient_accumulation_steps=4,          # Number of steps to accumulate gradients\n",
    "    group_by_length=True,                   # Group sequences of similar lengths together\n",
    "    save_steps=100,                         # Save model checkpoint every 100 steps\n",
    "    logging_steps=25,                       # Log metrics every 25 steps\n",
    "    learning_rate=2e-4,                     # Initial learning rate\n",
    "    weight_decay=0.001,                     # Weight decay to apply (L2 regularization)\n",
    "    fp16=False,                             # Use 16-bit precision (half-precision) during training\n",
    "    bf16=False,                             # Use bfloat16 precision\n",
    "    max_grad_norm=0.3,                      # Maximum gradient norm (for gradient clipping)\n",
    "    max_steps=-1,                           # Total number of training steps (-1 means no limit)\n",
    "    warmup_ratio=0.03,                      # Ratio of steps to perform learning rate warmup\n",
    "    optim=\"paged_adamw_32bit\",              # Optimizer to use (32-bit AdamW with paged memory)\n",
    "    lr_scheduler_type=\"constant\",           # Learning rate scheduler type (constant)\n",
    "    report_to=\"tensorboard\"                 # Reporting tool (TensorBoard in this case)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "543712c2-e7cd-46ac-bf59-968d71d3fd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_params = LoraConfig(\n",
    "    lora_alpha=16,                # Alpha parameter for Lora scaling\n",
    "    lora_dropout=0.1,             # Dropout rate for Lora layers\n",
    "    r=64,                         # Rank of the Lora matrices\n",
    "    bias=\"none\",                  # Type of bias to apply (none in this case)\n",
    "    task_type=\"CAUSAL_LM\",        # Type of task (Causal Language Modeling in this case)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f8b430a5-5ee9-4960-8a7f-c212ddda826f",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_use_double_quant=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6f3d148e-0176-4484-b079-174ef7331c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: torch in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from bitsandbytes) (2.0.0)\n",
      "Requirement already satisfied: numpy in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from bitsandbytes) (1.26.4)\n",
      "Requirement already satisfied: filelock in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from torch->bitsandbytes) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from torch->bitsandbytes) (4.12.2)\n",
      "Requirement already satisfied: sympy in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from torch->bitsandbytes) (1.13.3)\n",
      "Requirement already satisfied: networkx in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from torch->bitsandbytes) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from torch->bitsandbytes) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from torch->bitsandbytes) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from torch->bitsandbytes) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from torch->bitsandbytes) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from torch->bitsandbytes) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from torch->bitsandbytes) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from torch->bitsandbytes) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from torch->bitsandbytes) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from torch->bitsandbytes) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from torch->bitsandbytes) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from torch->bitsandbytes) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from torch->bitsandbytes) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from torch->bitsandbytes) (2.0.0)\n",
      "Requirement already satisfied: setuptools in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->bitsandbytes) (69.5.1)\n",
      "Requirement already satisfied: wheel in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->bitsandbytes) (0.43.0)\n",
      "Requirement already satisfied: cmake in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from triton==2.0.0->torch->bitsandbytes) (3.30.4)\n",
      "Requirement already satisfied: lit in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from triton==2.0.0->torch->bitsandbytes) (18.1.8)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from jinja2->torch->bitsandbytes) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/gsh-3atzc7/.conda/envs/nim_env/lib/python3.9/site-packages (from sympy->torch->bitsandbytes) (1.3.0)\n",
      "Downloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl (122.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.4/122.4 MB\u001b[0m \u001b[31m112.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: bitsandbytes\n",
      "Successfully installed bitsandbytes-0.44.1\n"
     ]
    }
   ],
   "source": [
    "!pip install bitsandbytes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2732cdb6-5b30-40d1-8e76-d52c1be0b168",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A configuraton of type rag cannot be instantiated because both `question_encoder` and `generator` sub-configurations were not passed, only {'attn_implementation': None}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquantization_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquant_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# token=token\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m      8\u001b[0m model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpretraining_tp \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/nim_env/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py:526\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquantization_config\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    524\u001b[0m     _ \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquantization_config\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 526\u001b[0m config, kwargs \u001b[38;5;241m=\u001b[39m \u001b[43mAutoConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_unused_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcode_revision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcode_revision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    532\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    534\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;66;03m# if torch_dtype=auto was passed here, ensure to pass it on\u001b[39;00m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs_orig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch_dtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.conda/envs/nim_env/lib/python3.9/site-packages/transformers/models/auto/configuration_auto.py:1036\u001b[0m, in \u001b[0;36mAutoConfig.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m   1034\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m pattern \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(CONFIG_MAPPING\u001b[38;5;241m.\u001b[39mkeys(), key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m, reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m   1035\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m pattern \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(pretrained_model_name_or_path):\n\u001b[0;32m-> 1036\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mCONFIG_MAPPING\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43munused_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1038\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1039\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized model in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1040\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould have a `model_type` key in its \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCONFIG_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, or contain one of the following strings \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1041\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min its name: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(CONFIG_MAPPING\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1042\u001b[0m )\n",
      "File \u001b[0;32m~/.conda/envs/nim_env/lib/python3.9/site-packages/transformers/configuration_utils.py:711\u001b[0m, in \u001b[0;36mPretrainedConfig.from_dict\u001b[0;34m(cls, config_dict, **kwargs)\u001b[0m\n\u001b[1;32m    708\u001b[0m \u001b[38;5;66;03m# We remove it from kwargs so that it does not appear in `return_unused_kwargs`.\u001b[39;00m\n\u001b[1;32m    709\u001b[0m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattn_implementation\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattn_implementation\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 711\u001b[0m config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(config, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpruned_heads\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    714\u001b[0m     config\u001b[38;5;241m.\u001b[39mpruned_heads \u001b[38;5;241m=\u001b[39m {\u001b[38;5;28mint\u001b[39m(key): value \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mpruned_heads\u001b[38;5;241m.\u001b[39mitems()}\n",
      "File \u001b[0;32m~/.conda/envs/nim_env/lib/python3.9/site-packages/transformers/models/rag/configuration_rag.py:128\u001b[0m, in \u001b[0;36mRagConfig.__init__\u001b[0;34m(self, vocab_size, is_encoder_decoder, prefix, bos_token_id, pad_token_id, eos_token_id, decoder_start_token_id, title_sep, doc_sep, n_docs, max_combined_length, retrieval_vector_size, retrieval_batch_size, dataset, dataset_split, index_name, index_path, passages_path, use_dummy_dataset, reduce_loss, label_smoothing, do_deduplication, exclude_bos_score, do_marginalize, output_retrieved, use_cache, forced_eos_token_id, dataset_revision, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    117\u001b[0m     bos_token_id\u001b[38;5;241m=\u001b[39mbos_token_id,\n\u001b[1;32m    118\u001b[0m     pad_token_id\u001b[38;5;241m=\u001b[39mpad_token_id,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    126\u001b[0m )\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion_encoder\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[0;32m--> 128\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    129\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA configuraton of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m cannot be instantiated because \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    130\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mboth `question_encoder` and `generator` sub-configurations were not passed, only \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    131\u001b[0m     )\n\u001b[1;32m    132\u001b[0m question_encoder_config \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion_encoder\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    133\u001b[0m question_encoder_model_type \u001b[38;5;241m=\u001b[39m question_encoder_config\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: A configuraton of type rag cannot be instantiated because both `question_encoder` and `generator` sub-configurations were not passed, only {'attn_implementation': None}"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model,\n",
    "    quantization_config=quant_config,\n",
    "    device_map={\"\": 0},\n",
    "    # token=token\n",
    ")\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3068a333-b514-4ae4-9c4b-fe15b3d165a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
